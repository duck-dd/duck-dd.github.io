[{"content":"需要深度用到MCMF了，但是摸了摸自己的脑门，脑子里没有公式和演算，只剩几个概念了。 记录一下我从使用的角度理解MCMF问题(东拼西凑)的过程；某些定理的推导，或者复杂度的计算原理，不会深扒；顺便说个感悟，在feed如此丰富的今天，我们还是应该时刻锻炼传统手艺，保留信息检索、过滤、沉淀的能力，否则可能会越走越远(挺简单个问题一开始看偏了太难理解了)。\nMCMF概念 Minimum Cost Maximum Flow(最小费用最大流)，满足流量约束前提下，找到源点到汇点的最大流，并使总运输费用最小，数学模型如下：\n有向图 G=(V,E)，每条边 e=(u,v) 包含容量 c(e) 和单位流量费用 w(e)；\n求源点 s 到汇点 t 的最大流，且总费用 ∑w(e)⋅f(e) 最小，其中 f(e) 为边 e 上的流量\n在解析MCMF之前，我们先一起了解一下他的前身，最大流问题和最小费用流问题。\n最大流问题 最大流问题是：在一个有向网络中，找到从源点（流量的起点）到汇点（流量的终点）的最大可行流量，同时满足每条边的容量限制；该问题是上世纪五十年代提出的，提出后Lester Ford和Delbert Fulkerson很快给出了解法，也是最大流后续一切发展的理论基础：Ford-Fulkerson算法。\n第一印象 简单描述，有向有权图，起点s，终点t，我们要寻找s-\u0026gt;t的最大的流量。 那么朴素的第一印象来看，暴力呗，BFS把所有s-\u0026gt;t路径集合P全部记录下来，然后逐条路径遍历P，每一条路径都跑满(路径上最小容量边)，同时更新涉及的边的容量值(这里可能还需要维护一个边-\u0026gt;剩余容量)，结束后得到一个总的流量值。 提出这个方案后，我们第一时间就会有做简单优化的想法，最朴素的想法就是，对于s的所有出边都满，或者t的所有入边都满的情况下，是可以快速退出的；有了快速退出这个想法后，继续思考，P的遍历顺序是对退出速度有影响的，初始状态下所有边没有消耗，P中的所有路径按大小排序，从大到小的顺序排序，大点干早点散(每次选择一条路径并记录开销后，也可以对P剩余的路径重排序，只不过开销比较大)，这样感觉上可以更快结束。 好了，聪明的你，在10s以内经历了上述的思考过程，但你眉头一皱，发现问题并不如此简单，简单的想法并不能确保能找到最大流，例如如下的情况：\n图1 blocking-flow(黑色数字=容量,红色数字=流量) 如图1左(黑色数字=容量,红色数字=流量)，流量=4后，无法再找到路径可通过流量了，但是如图1右，最大流其实是5；这里引入一个概念，阻塞流，即将所有的路径都阻塞了，无法再新增流量；显而易见，最大流是阻塞流，但阻塞流未必是最大流。 结合这个具体的例子，我们反过来思考为什么我们上面一起想出来的朴素的方法无法确保能够找到最大流呢？我们就结合这一个具体的简单的例子来分析，把整个图1左的中间部分完全忽略，我们只关注起点s以及他的出边，终点t以及他的入边，我们碰到了这样一个情况，我们选定了s的左出边以及t的右入边并且把它们两个给跑满了，而s的右出边和t的左入边他们两个虽然还有容量但是却无法互连(即我们忽略的图的中间的部分没办法把它们连接起来)，而图1右中，t的右入边跑满的流量不仅仅来自于s的左出边，还有s的右出边；ok, you got it! 简单总结，我们的朴素的暴力解法存在的问题是，会存在不合理的路径规划，他会把若干个瓶颈边放到一条路径里，导致多个瓶颈被同时耗尽。当然了，这是我们最通俗的理解，未必描述的是准确的。\n那么如何修正能够确保准确的找到最大流呢？\n再继续暴力的把P的所有排序都跑一遍，复杂度不太现实(感兴趣可以算算复杂度) 前面提到问题在于某一些路径的选取不合理，它可能同时触发了多个瓶颈(它本可以少触发一些瓶颈) 我们避免使用到不合理的路径？那对路径打分？结合实时的 residual graph(残量图，余量图，残量网络 等)，对剩余的路径打分，路径消耗掉的边(消耗掉边就是指一条边跑满)越少分越高？也不合理，每一条边价值并不是相等的，例如跨海大桥，这一条边甚至就是整个图的瓶颈；那我们从点入手？每个点都有流入边和流出边，流入和流出在每个点是相等的(s t除外)，我们尽量让每个点的流入流出比接近于他的容量的入出比，并对路径的所有点做加权后作为评分？说实话我不知道这个想法合理不合理，但是只要是想要依赖residual graph来建立评分机制，那么随着迭代次数提升，每次都要更新评分，复杂度应该都是不可接受的 那么换个思路，我们不在避免使用到不合理路径上下功夫，我们能不能做到随时撤销之前的不合理路径？这样我们就可以大胆的随便搞，一边搞一边修正直至结束；恭喜你，你跟Lester Ford和Delbert Fulkerson可能想到一块去了 Ford-Fulkerson 一句话描述Ford-Fulkerson算法，就是在建立residual graph时，除了更新每条边的残余容量，还会对已经产生的流量建立反向边，下一轮迭代时，反向边也可以使用。 从物理意义上，反向边一开始是没有的，对正向边开销后才会有反向边(容量等于正向边的开销值)，这没有问题；反向边产生开销时，实际效果类似于水流对冲，本来正向走3个水流，反向再走一个水流，其实最终的效果就等于这条水管(边)正向走了2个水流，解释的通，看来可以理解。 但是回到上面我们自己的思考，我们(或者可能只是我)愚蠢的脑袋里想的是要对之前的路径做撤销，当我们在某一轮迭代中使用到了一条反向边时，我们相当于对曾经使用到这条边的某一条路径撤销了一个流量，是这样吗？(如果是这样那就不应该仅是这一条反向边要做开销了，而是应该找到一条路径) 不是的，还是用图1左举例，他的residual graph如下：\n图2 图1左部的residual-graph 图2中，我们可以继续找到这样一条路径s-\u0026gt;v2-\u0026gt;v4-\u0026gt;v1-\u0026gt;v3-\u0026gt;t 流量=1，其中v4-\u0026gt;v1 流量=1这一段是我们选中的反向边(我们只对这一条边做了\u0026quot;撤销\u0026quot;)，可以看到，经过这一次修正后，我们实际的路径选择就跟图1右的最大流一致了，眼前的事实证明Ford-Fulkerson算法是正确的。 那我们尝试解答一下我们刚才产生的那个疑惑，当我们使用了一条反向边的时候，我们究竟在做什么?我是这样理解这个问题的，在residual graph中，如果我们在一条路径中使用到了一条反向边，那么说明一个问题，在最初的原图中，分别存在s\u0026mdash;\u0026gt;t的这样两条路径，分别包含了这条边的两个端点，我们可以把这个图抽象成一个H型，这条边就是中间的横杠，当我们开销这条边的反向边时，实际是在调整H型的两条竖线之间的流量分配方式(即合理规划使用H的左上 左下 右上 右下四部分)，以使得整个H通过的流量最大。\nFord-Fulkerson优化 Edmonds-Karp 每次迭代选取路径时，把residual graph当作无权图寻找最短路径，价值是证明了这里复杂度降低了，证明过程自求多福吧\nDinic(Dinitz) 每次迭代时，按照residual graph中将各个节点与起点s的距离将图分层，只保留 s到第一层 第一层到第二层 \u0026hellip; 的边，构造出level graph，然后在level graph中寻找阻塞流，而后更新residual graph(同样是记录反向边)，迭代迭代迭代\u0026hellip;\nMinimum Cut(S-T Cut, 最小割) 最小割定义 在一个带权有向图（通常为流量网络）中，割(Cut)是将顶点集V划分为两个不相交子集S和T（即S ∪ T = V，S ∩ T = ∅）的分割方式，其中源点s ∈ S，汇点t ∈ T. 割的容量定义为从子集S指向子集T的所有边的总容量(不包含反向边)，记为c(S, T). 最小割则是所有可能的割中，容量最小的那个割；一个网络可能存在多个最小割，但它们的容量相等(==最大流)。\n最大流最小割定理 在任何流量网络中，从源点到汇点的最大流值等于最小割的容量.\n要理解这个定理，还是结合物理意义最直观；我们这样想，流量一定是从s流向t的，我们把整个图抽象成一整根粗细不均的水管，那么每一个割，就是组成这个水管的一个个截面，那么那个最小的截面，就是这根水管的容量；为什么一个割是一个截面呢？因为割的性质就是把整个图完全切成了S和T（S ∪ T = V, S ∩ T = ∅, s ∈ S, t ∈ T ），就像在水管上切了一刀，切出了一个平面。\n寻找最小割 先求最大流：通过最大流算法（如Dinic、Edmonds-Karp等）计算从源点s到汇点t的最大流f 利用残量网络确定割集：在最大流对应的残量网络中，从源点s出发，通过所有 “剩余容量大于0” 的边可到达的顶点构成集合S，其余顶点构成集合T(t ∈ T)，则 (S, T) 为最小割。 为啥这样找？最终的残量网络中，那些完全被跑满的边，就是被割断的边，所以起点s还能触达的部分，就是割完以后S的部分，剩下的能触达t的部分，就是T。\n最小费用流问题 在满足流量需求的前提下，使网络中传输流量的总费用最低。\n网络模型 最小费用流问题基于一个带权有向图G=(V, E)，其中：V为顶点集（包含源点s和汇点t）；E为边集，每条边(u, v)具有两个属性：容量c(u, v)：该边可传输的最大流量；单位费用w(u, v)：通过该边传输 1 单位流量的费用（可正可负，但需避免负权环影响可行性）。\n核心需求 给定一个流量需求F（需从源点s传输到汇点t的总流量），找到一个可行流f，使得：\n流量满足：总流量 f 总 = F （若F等于最大流，则问题退化为最小费用最大流）； 费用最小：总费用 cost = ∑ ( u , v ) ∈ E f ( u , v ) × w ( u , v ) 最小。 Successive Shortest Paths（连续最短增广路算法） 每次从残量网络中寻找从s到t的费用最小的增广路径，沿该路径增广尽可能多的流量，重复直到满足流量F或无法增广。\n步骤：\n初始化流f为 0，总费用为 在残量网络中，用最短路径算法（如 SPFA、Dijkstra + 势函数）寻找s到t的最小费用路 计算该路径的最大可增广流量（路径上的最小残量容量 沿路径增广流量，更新残量网络和总费 重复步骤 2-4，直到总流量达到F或无增广路径（此时F不可行） 还有很多算法，此处不赘述。\n再来看MCMF 现在就好理解了，我们按照Ford-Fulkerson一定能够找到最大流，但是每次选择 增广路(继续扩大流量的起点到终点的路径) 时，结合最短路(带权)，寻找费用(权重)最小的那条路拉满，直至无法找到新的增广路为止。\n思考：每次都是贪心寻找最小费用增广路，能够确保最终找到的一定是最小费用吗？\n","permalink":"https://duck-dd.github.io/posts/mcmf/","summary":"\u003cp\u003e需要深度用到MCMF了，但是摸了摸自己的脑门，脑子里没有公式和演算，只剩几个概念了。\n记录一下我从使用的角度理解MCMF问题(东拼西凑)的过程；某些定理的推导，或者复杂度的计算原理，不会深扒；顺便说个感悟，在feed如此丰富的今天，我们还是应该时刻锻炼传统手艺，保留信息检索、过滤、沉淀的能力，否则可能会越走越远(挺简单个问题一开始看偏了太难理解了)。\u003c/p\u003e\n\u003ch1 id=\"mcmf概念\"\u003eMCMF概念\u003c/h1\u003e\n\u003cp\u003eMinimum Cost Maximum Flow(最小费用最大流)，满足流量约束前提下，找到源点到汇点的最大流，并使总运输费用最小，数学模型如下：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e有向图 G=(V,E)，每条边 e=(u,v) 包含容量 c(e) 和单位流量费用 w(e)；\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e求源点 s 到汇点 t 的最大流，且总费用 ∑w(e)⋅f(e) 最小，其中 f(e) 为边 e 上的流量\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e在解析MCMF之前，我们先一起了解一下他的前身，最大流问题和最小费用流问题。\u003c/p\u003e\n\u003ch1 id=\"最大流问题\"\u003e最大流问题\u003c/h1\u003e\n\u003cp\u003e最大流问题是：在一个有向网络中，找到从源点（流量的起点）到汇点（流量的终点）的最大可行流量，同时满足每条边的容量限制；该问题是上世纪五十年代提出的，提出后Lester Ford和Delbert Fulkerson很快给出了解法，也是最大流后续一切发展的理论基础：\u003ccode\u003eFord-Fulkerson\u003c/code\u003e算法。\u003c/p\u003e\n\u003ch2 id=\"第一印象\"\u003e第一印象\u003c/h2\u003e\n\u003cp\u003e简单描述，有向有权图，起点\u003ccode\u003es\u003c/code\u003e，终点\u003ccode\u003et\u003c/code\u003e，我们要寻找\u003ccode\u003es-\u0026gt;t\u003c/code\u003e的最大的流量。\n那么朴素的第一印象来看，暴力呗，BFS把所有\u003ccode\u003es-\u0026gt;t\u003c/code\u003e路径集合\u003ccode\u003eP\u003c/code\u003e全部记录下来，然后逐条路径遍历\u003ccode\u003eP\u003c/code\u003e，每一条路径都跑满(路径上最小容量边)，同时更新涉及的边的容量值(这里可能还需要维护一个\u003ccode\u003e边-\u0026gt;剩余容量\u003c/code\u003e)，结束后得到一个总的流量值。\n提出这个方案后，我们第一时间就会有做简单优化的想法，最朴素的想法就是，对于\u003ccode\u003es\u003c/code\u003e的所有出边都满，或者\u003ccode\u003et\u003c/code\u003e的所有入边都满的情况下，是可以快速退出的；有了快速退出这个想法后，继续思考，\u003ccode\u003eP\u003c/code\u003e的遍历顺序是对退出速度有影响的，初始状态下所有边没有消耗，\u003ccode\u003eP\u003c/code\u003e中的所有路径按大小排序，从大到小的顺序排序，大点干早点散(每次选择一条路径并记录开销后，也可以对\u003ccode\u003eP\u003c/code\u003e剩余的路径重排序，只不过开销比较大)，这样感觉上可以更快结束。\n好了，聪明的你，在10s以内经历了上述的思考过程，但你眉头一皱，发现问题并不如此简单，简单的想法并不能确保能找到最大流，例如如下的情况：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图1 blocking-flow(黑色数字=容量,红色数字=流量)\" loading=\"lazy\" src=\"/images/mcmf/mcmf-1.png\"\u003e\u003c/p\u003e\n\u003ccenter\u003e图1 blocking-flow(黑色数字=容量,红色数字=流量)\u003c/center\u003e\n\u003cp\u003e如图1左(黑色数字=容量,红色数字=流量)，流量=4后，无法再找到路径可通过流量了，但是如图1右，最大流其实是5；这里引入一个概念，\u003ccode\u003e阻塞流\u003c/code\u003e，即将所有的路径都阻塞了，无法再新增流量；显而易见，最大流是阻塞流，但阻塞流未必是最大流。\n结合这个具体的例子，我们反过来思考为什么我们上面一起想出来的朴素的方法无法确保能够找到最大流呢？我们就结合这一个具体的简单的例子来分析，把整个图1左的中间部分完全忽略，我们只关注起点\u003ccode\u003es\u003c/code\u003e以及他的出边，终点\u003ccode\u003et\u003c/code\u003e以及他的入边，我们碰到了这样一个情况，我们选定了\u003ccode\u003es\u003c/code\u003e的左出边以及\u003ccode\u003et\u003c/code\u003e的右入边并且把它们两个给跑满了，而\u003ccode\u003es\u003c/code\u003e的右出边和\u003ccode\u003et\u003c/code\u003e的左入边他们两个虽然还有容量但是却无法互连(即我们忽略的图的中间的部分没办法把它们连接起来)，而图1右中，\u003ccode\u003et\u003c/code\u003e的右入边跑满的流量不仅仅来自于\u003ccode\u003es\u003c/code\u003e的左出边，还有\u003ccode\u003es\u003c/code\u003e的右出边；ok, you got it! 简单总结，我们的朴素的暴力解法存在的问题是，会存在不合理的路径规划，他会把若干个瓶颈边放到一条路径里，导致多个瓶颈被同时耗尽。当然了，这是我们最通俗的理解，未必描述的是准确的。\u003c/p\u003e\n\u003cp\u003e那么如何修正能够确保准确的找到最大流呢？\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e再继续暴力的把\u003ccode\u003eP\u003c/code\u003e的所有排序都跑一遍，复杂度不太现实(感兴趣可以算算复杂度)\u003c/li\u003e\n\u003cli\u003e前面提到问题在于某一些路径的选取不合理，它可能同时触发了多个瓶颈(它本可以少触发一些瓶颈)\n\u003cul\u003e\n\u003cli\u003e我们避免使用到不合理的路径？那对路径打分？结合实时的 \u003ccode\u003eresidual graph(残量图，余量图，残量网络 等)\u003c/code\u003e，对剩余的路径打分，路径消耗掉的边(消耗掉边就是指一条边跑满)越少分越高？也不合理，每一条边价值并不是相等的，例如跨海大桥，这一条边甚至就是整个图的瓶颈；那我们从点入手？每个点都有流入边和流出边，流入和流出在每个点是相等的(\u003ccode\u003es\u003c/code\u003e \u003ccode\u003et\u003c/code\u003e除外)，我们尽量让每个点的流入流出比接近于他的容量的入出比，并对路径的所有点做加权后作为评分？说实话我不知道这个想法合理不合理，但是只要是想要依赖\u003ccode\u003eresidual graph\u003c/code\u003e来建立评分机制，那么随着迭代次数提升，每次都要更新评分，复杂度应该都是不可接受的\u003c/li\u003e\n\u003cli\u003e那么换个思路，我们不在避免使用到不合理路径上下功夫，我们能不能做到随时撤销之前的不合理路径？这样我们就可以大胆的随便搞，一边搞一边修正直至结束；恭喜你，你跟Lester Ford和Delbert Fulkerson可能想到一块去了\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"ford-fulkerson\"\u003eFord-Fulkerson\u003c/h2\u003e\n\u003cp\u003e一句话描述\u003ccode\u003eFord-Fulkerson\u003c/code\u003e算法，就是在建立\u003ccode\u003eresidual graph\u003c/code\u003e时，除了更新每条边的残余容量，还会对已经产生的流量建立反向边，下一轮迭代时，反向边也可以使用。\n从物理意义上，反向边一开始是没有的，对正向边开销后才会有反向边(容量等于正向边的开销值)，这没有问题；反向边产生开销时，实际效果类似于水流对冲，本来正向走3个水流，反向再走一个水流，其实最终的效果就等于这条水管(边)正向走了2个水流，解释的通，看来可以理解。\n但是回到上面我们自己的思考，我们(或者可能只是我)愚蠢的脑袋里想的是要对之前的路径做撤销，当我们在某一轮迭代中使用到了一条反向边时，我们相当于对曾经使用到这条边的某一条路径撤销了一个流量，是这样吗？(如果是这样那就不应该仅是这一条反向边要做开销了，而是应该找到一条路径)\n不是的，还是用图1左举例，他的\u003ccode\u003eresidual graph\u003c/code\u003e如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"图2 图1左的residual graph\" loading=\"lazy\" src=\"/images/mcmf/mcmf-2.png\"\u003e\u003c/p\u003e\n\u003ccenter\u003e图2 图1左部的residual-graph\u003c/center\u003e\n\u003cp\u003e图2中，我们可以继续找到这样一条路径\u003ccode\u003es-\u0026gt;v2-\u0026gt;v4-\u0026gt;v1-\u0026gt;v3-\u0026gt;t 流量=1\u003c/code\u003e，其中\u003ccode\u003ev4-\u0026gt;v1 流量=1\u003c/code\u003e这一段是我们选中的反向边(我们只对这一条边做了\u0026quot;撤销\u0026quot;)，可以看到，经过这一次修正后，我们实际的路径选择就跟图1右的最大流一致了，眼前的事实证明\u003ccode\u003eFord-Fulkerson\u003c/code\u003e算法是正确的。\n那我们尝试解答一下我们刚才产生的那个疑惑，当我们使用了一条反向边的时候，我们究竟在做什么?我是这样理解这个问题的，在\u003ccode\u003eresidual graph\u003c/code\u003e中，如果我们在一条路径中使用到了一条反向边，那么说明一个问题，在最初的原图中，分别存在\u003ccode\u003es\u003c/code\u003e\u0026mdash;\u0026gt;\u003ccode\u003et\u003c/code\u003e的这样两条路径，分别包含了这条边的两个端点，我们可以把这个图抽象成一个\u003ccode\u003eH\u003c/code\u003e型，这条边就是中间的横杠，当我们开销这条边的反向边时，实际是在调整\u003ccode\u003eH\u003c/code\u003e型的两条竖线之间的流量分配方式(即合理规划使用\u003ccode\u003eH\u003c/code\u003e的左上 左下 右上 右下四部分)，以使得整个\u003ccode\u003eH\u003c/code\u003e通过的流量最大。\u003c/p\u003e","title":"MCMF from scratch"},{"content":"最短路径问题 寻找有向图中两个顶点之间的路径，使得 路径最短 或 路径上各边的权重之和最小\n1 无权图最短路径 所有边权重相同，最短路径退化为寻找两点间边数最少的路径，BFS搞定。\n2 单源最短路径(SSSP, Single-Source Shortest Paths) 2.1 Dijkstra(堆优化) 限制：边权非负 思路：基于已经确定的最短路径，逐步贪心获得源点到所有节点的最短路径 步骤 初始化： 源点s的距离为0，源点s一步可达的节点距离记为单边的权重，其他节点距离为无穷大(∞) 所有节点标记为未访问 循环处理： 从未访问节点中选择距离最小的节点u，标记为已访问 对u的每个邻接节点v，进行 松弛操作: if distance[v] \u0026gt; distance[u] + weight(u, v): distance[v] = distance[u] + weight(u, v) predecessor[v] = u # 记录路径 终止条件：所有节点均被访问，或未访问节点的最小距离为 ∞（表示源点无法到达剩余节点） 优化：使用优先队列(最小堆)维护未访问节点，每次提取最小距离节点的时间为O(logV) 记录路径：通过记录前驱节点可以完整还原最短路径，若存在多条最短路径(距离相同但路径不同)，会记录其中一条(具体取决于节点的访问顺序，例如堆优化中相同距离节点的出堆顺序) 算法正确性理解：未访问节点中排序最靠前的(距离最小的)节点，是基于所有已访问节点推算出来的最近的点，如果再绕行其他节点，那么一定比当前距离更远；相反，如果不是未访问节点里距离最小的点，可能通过其他未访问节点绕行更优，所以每次迭代可以标记这一个点 2.2 Bellman-Ford 限制：边权可以为负，但不能有从源点可达的负权环(否则最短路径无意义，长度可无限小) 思路：通过 松弛操作 逐步逼近从源点到所有其他顶点的最短路径；松弛操作指的是：对于每条边(u, v)，若从源点到u的距离 dist[u]加上边权w(u, v)小于当前到v的距离dist[v]，则更新dist[v] 步骤 初始化：源点距离dist[source] = 0，其他顶点距离dist[v] = ∞ 弛操作：对图中所有边进行n-1轮松弛（n为顶点数）；因为最短路径最多包含n-1条边(否则存在环，若为正权环可忽略，负权环则无法求解) 检测负权环：第n次松弛时，若仍能更新距离，则说明存在从源点可达的负权环 优化：下面的SPFA 算法正确性理解：n个节点，那么起点到终点路径最长就是 1-\u0026gt;2-\u0026gt;3-\u0026gt;...-\u0026gt;n 最多有n-1跳(边)，否则的话就是有环了(如果是正环，绕行是更差的解，如果是负环，最短路径无解)，算法迭代x轮，那么x跳能到达的节点的最短路径都会被优化完成，所以经过n-1轮迭代，最长的路径也能被优化完成了；如何理解这句话呢，假设一个点距离起点有1条边和3条边两条路径，那么经过三轮迭代，这两条路径之间一定会做PK，择优就会完成 2.3 SPFA, Shortest Path Faster Algorithm SPFA其实只是Bellman-Ford的筛选优化，本质相同\n思路：利用队列减少不必要的松弛操作，只有当一个顶点的距离被更新时，其邻接点才可能需要松弛，因此仅将更新过的顶点加入队列等待处理 优化本质：Bellman-Ford每次迭代都会遍历所有边，而SPFA只遍历 \u0026ldquo;可能需要更新\u0026rdquo; 的边，减少冗余操作 步骤 初始化：源点距离dist[source] = 0，其他顶点dist[v] = ∞；队列初始加入源点，标记顶点是否在队列中（避免重复入队） 队列处理： 取出队首顶点 u，遍历其所有邻接边 (u, v)。 若 dist[u] + w(u, v) \u0026lt; dist[v]，则更新 dist[v] 若 v 不在队列中，则将其入队，并标记；若已在队列中，可跳过（或优化为 “若距离减少较多，可提前入队”） 检测负权环：记录每个顶点入队次数，若某顶点入队次数 ≥ n，则存在负权环（因为正常最短路径最多 n-1 条边，入队次数不会超过 n-1） 3 所有点对最短路径 3.1 Floyd 用于求解图中 所有顶点对之间最短路径 的动态规划算法，适用于带权图（包括有向图和无向图），且能处理负权边（无法处理负环）\n思路 Floyd 算法通过 \u0026ldquo;中间顶点\u0026rdquo; 逐步优化最短路径，具体来说，对于图中任意两个顶点i和j，算法考虑 \u0026ldquo;是否经过顶点k\u0026rdquo; 来更新 i -\u0026gt; j 的最短路径： 若 i -\u0026gt; k -\u0026gt; j 的路径比当前已知的 i -\u0026gt; j 路径更短，则更新最短路径长度 这里的 k 从所有顶点中依次选取，作为 \u0026ldquo;中间顶点\u0026rdquo; 进行尝试 步骤(图的顶点数为n，用邻接矩阵dist存储最短路径长度，其中dist[i][j]表示从顶点i到顶点j的最短路径长度) 初始 若i = j，则dist[i][j] = 0 若顶点i和j直接相连，且边权为w，则dist[i][j] = w 若顶点i和j不直接相连，则dist[i][j] = ∞(无穷大) 三重循环更新邻接矩阵 外层循环：枚举中间顶点k（从 0 到 n-1） 中层循环：枚举起点i（从 0 到 n-1） 内层循环：枚举终点j（从 0 到 n-1） 更新规则：对于每个 i, j, k，判断是否通过k能缩短路径：dist[i][j] = min(dist[i][j],dist[i][k] + dist[k][j]) 记录路径：再开一个邻接矩阵，记录i j最短路径的绕行节点k，如果节点k存在，还需要递归查找 i -\u0026gt; k k -\u0026gt; j的绕行节点，直至找到完整路径 算法正确性理解：如图1，第一次绕行节点1,对比了i -\u0026gt; j和i -\u0026gt; 1 -\u0026gt; j，第二次再加入对比节点2，由于是基于上一次结果计算，因此其实不仅对比了路径i -\u0026gt; 2 -\u0026gt; j，也对比了i -\u0026gt; 1 -\u0026gt; 2 -\u0026gt; j和i -\u0026gt; 2 -\u0026gt; 1 -\u0026gt; j，以此类推，所有路径全排列都参与了对比，因此是正确的 图1 floyd迭代过程 3.2 Johnson 解决带权有向图中所有节点对之间最短路径问题，尤其适用于图中 存在负权边但无负环 的场景;结合了 Bellman-Ford 和 Dijkstra 算法的优势，既保证了正确性又提高了效率\n注意一个问题，势函数优化后负环还是负环，势函数只能消除负边但是负环无法消除\n思路 预处理：通过 Bellman-Ford 算法引入虚拟节点，计算势函数（势能值），消除原图中的负权边 优化：利用势函数重新计算每条边的权重，使得所有边权非负 高效计算：对每个节点运行 Dijkstra 算法，得到所有节点对之间的最短路径 步骤 添加虚拟节点：在原图中添加一个虚拟节点（例如节点 0），并从该节点向所有其他节点连接一条权重为 0 的边 运行 Bellman-Ford：以虚拟节点为源点，使用 Bellman-Ford 算法计算到所有节点的最短路径，得到势函数 h[v] 重赋权边：对每条边 (u, v)，将其权重调整为 w'(u, v) = w(u, v) + h[u] - h[v]，确保所有边权非负 运行 Dijkstra：移除虚拟节点，对每个节点作为源点，运行 Dijkstra 算法计算最短路径 还原路径权重：将 Dijkstra 得到的路径权重通过公式 d(u, v) = d'(u, v) - h[u] + h[v] 还原为原图中的真实权重 ","permalink":"https://duck-dd.github.io/posts/shortest-path/","summary":"\u003ch1 id=\"最短路径问题\"\u003e最短路径问题\u003c/h1\u003e\n\u003cp\u003e寻找有向图中两个顶点之间的路径，使得 \u003ccode\u003e路径最短\u003c/code\u003e 或 \u003ccode\u003e路径上各边的权重之和最小\u003c/code\u003e\u003c/p\u003e\n\u003ch2 id=\"1-无权图最短路径\"\u003e1 无权图最短路径\u003c/h2\u003e\n\u003cp\u003e所有边权重相同，最短路径退化为寻找两点间边数最少的路径，\u003ccode\u003eBFS\u003c/code\u003e搞定。\u003c/p\u003e\n\u003ch2 id=\"2-单源最短路径sssp-single-source-shortest-paths\"\u003e2 单源最短路径(SSSP, Single-Source Shortest Paths)\u003c/h2\u003e\n\u003ch3 id=\"21-dijkstra堆优化\"\u003e2.1 Dijkstra(堆优化)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e限制：边权非负\u003c/li\u003e\n\u003cli\u003e思路：基于已经确定的最短路径，逐步贪心获得源点到所有节点的最短路径\u003c/li\u003e\n\u003cli\u003e步骤\n\u003cul\u003e\n\u003cli\u003e初始化：\n\u003cul\u003e\n\u003cli\u003e源点\u003ccode\u003es\u003c/code\u003e的距离为0，源点\u003ccode\u003es\u003c/code\u003e一步可达的节点距离记为单边的权重，其他节点距离为无穷大(∞)\u003c/li\u003e\n\u003cli\u003e所有节点标记为未访问\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e循环处理：\n\u003cul\u003e\n\u003cli\u003e从未访问节点中选择距离最小的节点\u003ccode\u003eu\u003c/code\u003e，标记为已访问\u003c/li\u003e\n\u003cli\u003e对\u003ccode\u003eu\u003c/code\u003e的每个邻接节点\u003ccode\u003ev\u003c/code\u003e，进行 \u003cstrong\u003e松弛操作\u003c/strong\u003e:\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eif distance[v] \u0026gt; distance[u] + weight(u, v):\n    distance[v] = distance[u] + weight(u, v)\n    predecessor[v] = u  # 记录路径\n\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e终止条件：所有节点均被访问，或未访问节点的最小距离为 ∞（表示源点无法到达剩余节点）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e优化：使用优先队列(最小堆)维护未访问节点，每次提取最小距离节点的时间为\u003ccode\u003eO(logV)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e记录路径：通过记录\u003ccode\u003e前驱节点\u003c/code\u003e可以完整还原最短路径，若存在多条最短路径(距离相同但路径不同)，会记录其中一条(具体取决于节点的访问顺序，例如堆优化中相同距离节点的出堆顺序)\u003c/li\u003e\n\u003cli\u003e算法正确性理解：未访问节点中排序最靠前的(距离最小的)节点，是基于所有已访问节点推算出来的最近的点，如果再绕行其他节点，那么一定比当前距离更远；相反，如果不是未访问节点里距离最小的点，可能通过其他未访问节点绕行更优，所以每次迭代可以标记这一个点\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"22-bellman-ford\"\u003e2.2 Bellman-Ford\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e限制：边权可以为负，但不能有从源点可达的负权环(否则最短路径无意义，长度可无限小)\u003c/li\u003e\n\u003cli\u003e思路：通过 \u003cstrong\u003e松弛操作\u003c/strong\u003e 逐步逼近从源点到所有其他顶点的最短路径；松弛操作指的是：对于每条边\u003ccode\u003e(u, v)\u003c/code\u003e，若从源点到\u003ccode\u003eu\u003c/code\u003e的距离 \u003ccode\u003edist[u]\u003c/code\u003e加上边权\u003ccode\u003ew(u, v)\u003c/code\u003e小于当前到\u003ccode\u003ev\u003c/code\u003e的距离\u003ccode\u003edist[v]\u003c/code\u003e，则更新\u003ccode\u003edist[v]\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e步骤\n\u003cul\u003e\n\u003cli\u003e初始化：源点距离\u003ccode\u003edist[source] = 0\u003c/code\u003e，其他顶点距离\u003ccode\u003edist[v] = ∞\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e弛操作：对图中所有边进行\u003ccode\u003en-1\u003c/code\u003e轮松弛（\u003ccode\u003en\u003c/code\u003e为顶点数）；因为最短路径最多包含\u003ccode\u003en-1\u003c/code\u003e条边(否则存在环，若为正权环可忽略，负权环则无法求解)\u003c/li\u003e\n\u003cli\u003e检测负权环：第\u003ccode\u003en\u003c/code\u003e次松弛时，若仍能更新距离，则说明存在从源点可达的负权环\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e优化：下面的SPFA\u003c/li\u003e\n\u003cli\u003e算法正确性理解：\u003ccode\u003en\u003c/code\u003e个节点，那么起点到终点路径最长就是 \u003ccode\u003e1-\u0026gt;2-\u0026gt;3-\u0026gt;...-\u0026gt;n\u003c/code\u003e 最多有\u003ccode\u003en-1\u003c/code\u003e跳(边)，否则的话就是有环了(如果是正环，绕行是更差的解，如果是负环，最短路径无解)，算法迭代\u003ccode\u003ex\u003c/code\u003e轮，那么\u003ccode\u003ex\u003c/code\u003e跳能到达的节点的最短路径都会被优化完成，所以经过\u003ccode\u003en-1\u003c/code\u003e轮迭代，最长的路径也能被优化完成了；如何理解这句话呢，假设一个点距离起点有1条边和3条边两条路径，那么经过三轮迭代，这两条路径之间一定会做PK，择优就会完成\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-spfa-shortest-path-faster-algorithm\"\u003e2.3 SPFA, Shortest Path Faster Algorithm\u003c/h3\u003e\n\u003cp\u003eSPFA其实只是Bellman-Ford的筛选优化，本质相同\u003c/p\u003e","title":"The Shortest Path"},{"content":"说明：\n持续更新(标题含TODO关键字的小节，都会以topic开始，后续会持续完善topic)。记录内容是一些对我而言：\n小的骚操作(可能有些tricky) 容易理解偏差的点 冷门的点(没啥用的点) Golang代码执行顺序 没有并发，一个顺序逻辑，CPU真正执行指令不一定与编码顺序完全一致，Go的编译器会做优化，前提是会解决依赖逻辑，看起来是“顺序执行”这一假设。\n了解更多可查看Golang内存模型规范。\ninternal包 internal包，只能被和internal目录有同一个父目录的包所导入。 例如，net/http/internal/chunked内部包只能被net/http/httputil或net/http包导入，但是不能被net/url包导入。不过net/url包却可以导入net/http/httputil包。\n变量交换 i, j = j, i // 交换 i 和 j 的值 for循环有其他识别break的关键字 for循环内有其他识别break的关键字时，其他关键字内的break会被其识别而不会跳出for，以下用select举例，switch同理。\nfor { select { case \u0026lt;-sigChan: // exit for break default: // do something } } 以上break并不能退出for循环，可以使用标签或goto解决：\n// 1 标签 FOR: for { select { case \u0026lt;-sigChan: // exit for break FOR default: // do something } } ---------------------------- // 2 goto for { select { case \u0026lt;-sigChan: // exit for goto ENDFOR default: // do something } } ENDFOR: 读取stdin(刷题别再因为stdin踩坑了喂) fmt包内 Scan系列 SScan系列 Fscan系列如下：\n系列 无后缀 f后缀 ln后缀 Scan系列 Scan() Scanf() Scanln Sscan系列 Sscan() Sscanf() Sscanln() Fscan系列 Fscan() Fscanf() Fscanln() 将换行符当空格处理 根据给定的format读取 遇到换行符停止 他们的定义：\nfunc Scan(a ...interface{}) (n int, err error) func Scanf(format string, a ...interface{}) (n int, err error) func Scanln(a ...interface{}) (n int, err error) func Sscan(str string, a ...interface{}) (n int, err error) func Sscanf(str string, format string, a ...interface{}) (n int, err error) func Sscanln(str string, a ...interface{}) (n int, err error) func Fscan(r io.Reader, a ...interface{}) (n int, err error) func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error) func Fscanln(r io.Reader, a ...interface{}) (n int, err error) 从定义可见，Scanln(其他同理)直接读取一行然后结束，但是从函数入参...interface{}就能知道，你需要明确的知道这一行空格会分隔出多少个你需要的值；可是平时做题最多的场景，一般是每一行有多少个值是个变量，需要先将一行按string读入，然后strings.Fields()直接获得一个[]string再慢慢处理。所以你应该这样做：\n// each line in stdin corresponding to a string in lines lines := make([]string, 0, anExpectedCap) scanner := bufio.NewScanner(os.Stdin) for scanner.Scan() { line := scanner.Text() lines = append(lines, line) } PS: 命令行 ctrl+d == EOF，结束输入。\n初始化顺序 任意文件可以有多个init函数用来做初始化工作。 Golang包初始化顺序为 全局变量\u0026gt;init函数。 全局变量初始化顺序由他们之间的依赖关系决定(所以全局变量、type等的声明可忽略顺序)，无依赖关系时按声明顺序执行。 init函数的初始化顺序按init()函数声明顺序执行。\nfunc init(){ ... } func init(){ ... } func main(){ ... } // 复杂的初始化工作除了可以用init()函数解决外，还可以使用匿名函数 var ComplexTable [][]int = func()([][]int){ ... ... ... }() *指针 = 表达式 \u0026ldquo;*指针 = 表达式\u0026rdquo; 形式可以直接修改指针指向的变量的值：\nx := 1 p := \u0026amp;x // p, of type *int, points to x fmt.Println(*p) // \u0026#34;1\u0026#34; *p = 2 // equivalent to x = 2 fmt.Println(*p) // \u0026#34;2\u0026#34; fmt.Println(x) // \u0026#34;2\u0026#34; ,与} 使用逗号处理多item（函数参数，结构体成员等）时，结束的 )或} 可以跟在最后一行，也可以另起一行，当另起一行时，为避免编译器行尾自动补充分号导致编译错误，应在末尾的参数后显示插入逗号。\nfunc tt(a,b,c string)(){ ... } tt( \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, ) == tt( \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;) ------------------------------------------------------------- type TT struct{ A string B string C string } tt := TT{ A: \u0026#34;a\u0026#34;, B: \u0026#34;b\u0026#34;, C: \u0026#34;c\u0026#34;, } == tt := TT{ A: \u0026#34;a\u0026#34;, B: \u0026#34;b\u0026#34;, C: \u0026#34;c\u0026#34;} map查找、类型断言、通道接收 的返回值 map查找\u0026amp;类型断言\u0026amp;通道接收，既可以返回两个值，也可以返回一个值。\nv, ok = m[key] // map lookup v, ok = x.(T) // type assertion v, ok = \u0026lt;-ch // channel receive v = m[key] // map查找，失败时返回零值 v = x.(T) // type断言，失败时panic异常 v = \u0026lt;-ch // 管道接收，失败时返回零值（阻塞不算是失败） 支持中文名称，默认不导出 Golang支持中文变量和类型名，对于中文汉字，Unicode标志都作为小写字母处理，因此中文的命名默认不能导出。\ntype 测试人员 struct { name string age int } func main(){ 测试人员_某某某 := \u0026amp;测试人员{\u0026#34;test\u0026#34;, 1} fmt.Printf(\u0026#34;%v,%T,%+v\\n\u0026#34;, 测试人员_某某某, 测试人员_某某某, 测试人员_某某某) // 输出：\u0026amp;{test 1},*main.测试人员,\u0026amp;{name:test age:1} } 包注释写法 一个包通常只有一个源文件有包注释，如果有多个包注释，目前的文档工具会根据源文件名的先后顺序将它们链接为一个包注释；如果某个包注释很大，通常会放到一个独立的doc.go文件中。\n{}包含的部分为一个句法块，可以显示的使用{}做 作用域 隔离：\nfunc main(){ tmp := 10 { tmp2 := 20 fmt.Println(tmp, tmp2) } fmt.Println(tmp) // can not recognize tmp2 here } if而不是if+else Go语言的习惯是在if中处理错误然后直接返回，这样可以确保正常执行的语句不需要代码缩进：\n// right res,err := doSomething() if err != nil{ printErr(err) } res.DoSomething() // wrong if res,err := doSomething(); err != nil{ printErr(err) } else { // res.DoSomething() 应该在主执行逻辑中，不建议缩进 res.DoSomething() } 格式化输出的[n]副词 fmt包Printf函数格式化字符串包含多个%参数时将会包含对应相同数量的额外操作数，但是%之后添加[n]副词告诉Printf函数再次使用第n个操作数。\nfmt.Printf(\u0026#34;%d, %d\\n\u0026#34;, 1, 2) // 1, 2 fmt.Printf(\u0026#34;%d, %[1]d\\n\u0026#34;, 1) // 1, 1 \u0026ldquo;变量\u0026rdquo; 和 \u0026ldquo;值\u0026rdquo; 老罗语录： 要区分变量和值有个很简单的方法就是对它取地址，看看编译器会不会报错。 变量就是有地址的值。 值没有地址，值不能放在等式的左边。\n查看数字的二进制 fmt.Println(strconv.FormatInt(int64(123), 2)) // \u0026#34;1111011\u0026#34; fmt.Printf(\u0026#34;%b\u0026#34;, 123) // \u0026#34;1111011\u0026#34; 创建slice 创建长度和容量都是100的string slice的简洁方法：\n// 正常 testSlice := make([]string, 100, 100) // 简洁版 testSlice := []string{99: \u0026#34;\u0026#34;} slice切割 当使用[:]切割int数组创建slice时，slice底层数组共用原数组，新slice的cap为切割起始位置至原数组末尾；因此，修改切割出的slice内元素时，将同时修改原数组，且修改slice的len以外cap以内的值时，也同时修改原数组：\ntestArray := [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11} cutTestArray := testArray[5:9] fmt.Println(cutTestArray, len(cutTestArray), cap(cutTestArray)) // [5 6 7 8] 4 7 cutTestArray[0] = 50 fmt.Println(cutTestArray, testArray) // [50 6 7 8] [0 1 2 3 4 50 6 7 8 9 10 11] cutTestArray = append(cutTestArray, 90) fmt.Println(cutTestArray, testArray) // [50 6 7 8 90] [0 1 2 3 4 50 6 7 8 90 10 11] 使用[:]切割字符串时，获得一个字符串且发生一次拷贝：\ntestStr := \u0026#34;hello world\u0026#34; cutTestStr := testStr[6:] // var cutTestStr string = testStr[6:] fmt.Println(testStr, \u0026amp;testStr, cutTestStr, \u0026amp;cutTestStr) // hello world 0xc000010240 world 0xc000010250 \u0026hellip; in Golang Golang \u0026hellip;(3 dots) 用法: 参考 3 dots in Go\nslice操作考虑内存 给定一个string slice，去除其中\u0026quot;\u0026ldquo;项：\n// 你可能想这么写： func filterEmptyStr(input []string) []string { ret := make([]string, 0) for _, item := range input { if item != \u0026#34;\u0026#34; { ret = append(ret, item) } } return ret } // 再想想，为了避免发生扩容拷贝，你可能会这么写： func filterEmptyStr(input []string) []string { ret := make([]string, 0, len(input)) for _, item := range input { if item != \u0026#34;\u0026#34; { ret = append(ret, item) } } return ret } // 其实，可以共用底层数据结构，这么写（问题是，输入的[]string被修改了）： // nonempty returns a slice holding only the non-empty strings. // The underlying array is modified during the call. func nonempty(strings []string) []string { i := 0 for _, s := range strings { if s != \u0026#34;\u0026#34; { strings[i] = s i++ } } return strings[:i] } // 再思考下，共用底层结构也可以这么写： func nonempty2(strings []string) []string { out := strings[:0] // zero-length slice of original for _, s := range strings { if s != \u0026#34;\u0026#34; { out = append(out, s) } } return out } set (Golang没有set类型) Go语言中并没有提供一个set类型，但是map中的key也是不相同的，可以用map实现类似set的功能。 通常使用map[string]bool创建一个string的set，但是bool占一字节，如需更加节省空间，可以使用map[string]struct{}, struct{}大小为0：\nseen := make(map[string]struct{}) // set of strings // ... if _, ok := seen[s]; !ok { seen[s] = struct{}{} // ...first time seeing s... } 构造struct建议声明字段名 尽量不要使用如下方法初始化结构体：\ntype Point struct{ X, Y int } p := Point{1, 2} // 建议： p := Point{ X: 1, Y: 2, } 因为这对结构体的成员顺序有强依赖，当结构体做调整时，将导致编译不通过。（有利有弊，个人认为，这样可以避免结构体增加字段时，忘记为新增字段做初始化）\njson.MarshalIndent json.MarshalIndent函数将产生整齐缩进的输出，该函数有两个额外的字符串参数用于表示每一行输出的前缀和每一个层级的缩进：\ntype JsonTest struct { Item1 string Item2 string } jt1 := JsonTest{\u0026#34;item1\u0026#34;, \u0026#34;item2\u0026#34;} msg, _ := json.Marshal(jt1) msgIndent, _ := json.MarshalIndent(jt1, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;) fmt.Println(string(msg)) fmt.Println(string(msgIndent)) --------------------------------------------------- output: {\u0026#34;Item1\u0026#34;:\u0026#34;item1\u0026#34;,\u0026#34;Item2\u0026#34;:\u0026#34;item2\u0026#34;} { \u0026#34;Item1\u0026#34;: \u0026#34;item1\u0026#34;, \u0026#34;Item2\u0026#34;: \u0026#34;item2\u0026#34; } \u0026ldquo;函数值\u0026quot;使用前先判空 当使用“函数值”作为函数参数时，函数内部调用传入的函数值时记得先判空，函数值零值为nil，直接调用nil的函数值会引发panic。\n扩展来看，引用类型，能够与nil做==判断的，使用前都应该判空。\n捕获迭代变量 for循环(尤其需要在for循环内开goroutine)时，使用循环变量之前需要先将循环变量赋值给循环体内的一个局部变量，如下例。\n问题的原因在于循环变量的作用域。在下面的例子中，for循环语句引入了新的词法块，循环变量name\u0026amp;age在这个词法块中被声明。在该循环中生成的所有函数值都共享相同的循环变量。需要注意，函数值中记录的是循环变量的内存地址，而不是循环变量某一时刻的值。以name为例，后续的迭代会不断更新name的值，当最终printer操作执行时，for循环已完成，name中存储的值等于最后一次迭代的值。这意味着，每次printer的调用输出的都是相同的最后那一个名字。\n为了解决这个问题，可以引入一个与循环变量同名的局部变量，作为循环变量的副本。\n// wrong, output: /* Pike 13 Pike 13 */ var printers []func() name2Age := map[string]string{\u0026#34;Rob\u0026#34;: \u0026#34;12\u0026#34;, \u0026#34;Pike\u0026#34;: \u0026#34;13\u0026#34;} for name, age := range name2Age { printers = append(printers, func() { fmt.Println(name, age) }) } for _, printer := range printers { printer() } -------------------------------------------------------------- // right, output: /* Rob 12 Pike 13 */ var printers []func() name2Age := map[string]string{\u0026#34;Rob\u0026#34;: \u0026#34;12\u0026#34;, \u0026#34;Pike\u0026#34;: \u0026#34;13\u0026#34;} for name, age := range name2Age { name := name age := age printers = append(printers, func() { fmt.Println(name, age) }) } for _, printer := range printers { printer() } --------------------------------------------------------------- // 下面两个例子的输出是一致的，因为fmt.Println()在每次循环内部即时调用 // 1 name2Age := map[string]string{\u0026#34;Rob\u0026#34;: \u0026#34;12\u0026#34;, \u0026#34;Pike\u0026#34;: \u0026#34;13\u0026#34;} for name, age := range name2Age { fmt.Println(name, age) } // 2 name2Age := map[string]string{\u0026#34;Rob\u0026#34;: \u0026#34;12\u0026#34;, \u0026#34;Pike\u0026#34;: \u0026#34;13\u0026#34;} for name, age := range name2Age { name := name age := age fmt.Println(name, age) } defer 被延迟执行的匿名函数可以修改函数返回给调用者的返回值：\nfunc add(x int) (result int) { defer func() { result += x }() return x + x } fmt.Println(add(4)) // \u0026#34;12\u0026#34; // 如果是参数那么将无法成功修改返回值: func add(x int) (result int) { defer func(result int) { result += x }(result) return x + x } fmt.Println(add(4)) // \u0026#34;8\u0026#34; 这里首先必须显示声明了返回值，以下方法不能成功修改返回值：\nfunc add(x int) int { result := x + x defer func() { result += x }() return result } fmt.Println(add(4)) // \u0026#34;8\u0026#34; 这是为什么呢？看下面例子，显示声明的返回值，defer中直接修改时，其实修改的是同一个地址，所以能够成功修改返回值。但是在上面的例子中，defer修改的仅仅是函数内的局部变量，而函数在return时将该局部变量拷贝到了调用栈的返回值中，所以defer修改局部变量成功，但是并不会体现在返回值上。\n上面的例子能说明defer的执行时机是返回值返回给调用者之后吗？ 不能，其实defer的执行时机是return之后，且返回值返回给调用方之前，看下面的例子，也正是因为defer执行在返回值真正返回给调用方之前，所以才能成功修改返回值。\nfunc add(x int) (result int) { fmt.Println(\u0026#34;addr of result in add: \u0026#34;, \u0026amp;result) defer func() { fmt.Println(\u0026#34;addr of result in defer: \u0026#34;, \u0026amp;result) result += x }() return x + x } fmt.Println(add(4)) // \u0026#34;12\u0026#34; ------------------------------------------------------ output: addr of result in add: 0xc00009e018 addr of result in defer: 0xc00009e018 12 为了证明 “defer执行在return之后，且返回值返回给调用方之前”，可以看下面的例子，可以看到调用方获得返回值紧跟defer完成以后。 因此啊，defer里面逻辑写不好，也会严重影响性能啊，如果是一些可并发的逻辑，可以defer里开新的goroutine去搞。\nfunc add(x int) (result int) { defer func() { fmt.Println(\u0026#34;defer start \u0026#34;, time.Now()) time.Sleep(time.Second) result += x fmt.Println(time.Now(), \u0026#34;result value in defer: \u0026#34;, result) time.Sleep(10 * time.Second) fmt.Println(\u0026#34;defer end \u0026#34;, time.Now()) }() return x + x } x := add(4) fmt.Println(\u0026#34;caller time: \u0026#34;, time.Now(), \u0026#34;caller got: \u0026#34;, x) ------------------------------------------------------ output: defer start 2021-07-23 15:19:35.264078 +0800 CST m=+0.000999863 2021-07-23 15:19:36.265726 +0800 CST m=+1.002653773 result value in defer: 12 defer end 2021-07-23 15:19:46.270896 +0800 CST m=+11.007876743 caller time: 2021-07-23 15:19:46.270939 +0800 CST m=+11.007920326 caller got: 12 循环体中的defer 在循环体中的defer语句需要特别注意，因为只有在函数执行完毕后，这些被延迟的函数才会执行。下面的代码会导致系统的文件描述符耗尽，因为在所有文件都被处理之前，没有文件会被关闭：\nfor _, filename := range filenames { f, err := os.Open(filename) if err != nil { return err } defer f.Close() // NOTE: risky; could run out of file descriptors // ...process f… } 方法接收者(类型or其指针)一致性 如果某个struct有一个指针作为接收器的方法，那么该struct的所有方法都必须有一个指针接收器，即使并不需要。 换句话说，一个struct T，他的方法集要么都是func(t *T)DoSomething(){}，要么都是func (t T)DoSomething(){}。 Why？ 我的理解，保持类型方法集的一致性，能够规范化某个类型的拷贝行为，即该类型的拷贝是否是安全的。 举个例子，看下面，A的加减法都不会影响接收者，B的加减法都会影响接收者，可能适用于不同的场景，但是C，加法不会影响接收者，但是减法会影响接收者，这让人很懵逼。\ntype A struct{Item int} func (a A)Add(s int){ a.Item += s } func (a A)Subtrace(s int){ a.Item -= s } ////// type B struct{Item int} func (b *B)Add(s int){ b.Item += s } func (b *B)Subtrace(s int){ b.Item -= s } ////// type C struct{Item int} func (c C)Add(s int){ c.Item += s } func (c *C)Subtrace(s int){ c.Item -= s } 引用类型作为参数 函数参数是引用类型时，虽然仍可修改相同的底层数据，但是引用本身却是一份拷贝，当函数内修改引用本身时不会影响原值（比如赋值nil，或将引用指向其他对象）。 方法表达式中，接收者是表达式函数的第一个参数，所以该说明同样适用于方法；类型方法其接收者是类型的拷贝，类型指针方法其接收者是拷贝出的一份指向该类型的指针。\nfunc clearMap(input map[string]bool) { input = nil } func main() { tm := map[string]bool{\u0026#34;test\u0026#34;: true, \u0026#34;test1\u0026#34;: true} fmt.Println(tm) clearMap(tm) fmt.Println(tm) } ------------------------------------------------------- output: map[test:true test1:true] map[test:true test1:true] 内嵌使匿名struct拥有方法 Golang方法的接收者只能是命名类型或者其指针，但是由于内嵌这一特性，匿名struct也有手段可以拥有方法：\n// 两个包级别变量实现缓存 var ( mu sync.Mutex // guards mapping mapping = make(map[string]string) ) func Lookup(key string) string { mu.Lock() v := mapping[key] mu.Unlock() return v } ------------------------------------------------- // 匿名struct存储在变量cache中，并且具备其内嵌struct Mutex的所有方法 var cache = struct { sync.Mutex mapping map[string]string }{ mapping: make(map[string]string), } func Lookup(key string) string { cache.Lock() v := cache.mapping[key] cache.Unlock() return v } 方法表达式使用场景 当你根据一个变量来决定调用同一个类型的哪个函数时，方法表达式就显得很有用了。你可以根据选择来调用接收器各不相同的方法：\ntype Point struct{ X, Y float64 } func (p Point) Add(q Point) Point { return Point{p.X + q.X, p.Y + q.Y} } func (p Point) Sub(q Point) Point { return Point{p.X - q.X, p.Y - q.Y} } type Path []Point func (path Path) TranslateBy(offset Point, add bool) { var op func(p, q Point) Point if add { op = Point.Add } else { op = Point.Sub } for i := range path { // Call either path[i].Add(offset) or path[i].Sub(offset). path[i] = op(path[i], offset) } } bit数组 Go语言里的集合一般会用map[T]bool这种形式来表示，T代表元素类型。集合用map类型来表示虽然非常灵活，但我们可以以一种更好的形式来表示它。例如在数据流分析领域，集合元素通常是一个非负整数，集合会包含很多元素，并且集合会经常进行并集、交集操作，这种情况下，bit数组会比map表现更加理想。(再补充一个例子，比如我们执行一个http下载任务，把文件按照16kb一块划分为很多块，需要有一个全局变量来标识哪些块下载完成了，这种时候也需要用到bit数组)。 一个bit数组通常会用一个无符号数或者称之为“字”的slice来表示，每一个元素的每一位都表示集合里的一个值。当集合的第i位被设置时，我们才说这个集合包含元素i：\n// An IntSet is a set of small non-negative integers. // Its zero value represents the empty set. type IntSet struct { words []uint64 } // Has reports whether the set contains the non-negative value x. func (s *IntSet) Has(x int) bool { word, bit := x/64, uint(x%64) return word \u0026lt; len(s.words) \u0026amp;\u0026amp; s.words[word]\u0026amp;(1\u0026lt;\u0026lt;bit) != 0 } // Add adds the non-negative value x to the set. func (s *IntSet) Add(x int) { word, bit := x/64, uint(x%64) for word \u0026gt;= len(s.words) { s.words = append(s.words, 0) } s.words[word] |= 1 \u0026lt;\u0026lt; bit } // UnionWith sets s to the union of s and t. func (s *IntSet) UnionWith(t *IntSet) { for i, tword := range t.words { if i \u0026lt; len(s.words) { s.words[i] |= tword } else { s.words = append(s.words, tword) } } } // String returns the set as a string of the form \u0026#34;{1 2 3}\u0026#34;. func (s *IntSet) String() string { var buf bytes.Buffer buf.WriteByte(\u0026#39;{\u0026#39;) for i, word := range s.words { if word == 0 { continue } for j := 0; j \u0026lt; 64; j++ { if word\u0026amp;(1\u0026lt;\u0026lt;uint(j)) != 0 { if buf.Len() \u0026gt; len(\u0026#34;{\u0026#34;) { buf.WriteByte(\u0026#39; \u0026#39;) } fmt.Fprintf(\u0026amp;buf, \u0026#34;%d\u0026#34;, 64*i+j) } } } buf.WriteByte(\u0026#39;}\u0026#39;) return buf.String() } 接口命名 Golang接口命名一般\u0026quot;er\u0026quot;结尾，例如：Loser。 er的含义一般都是什么什么人，是一个类，而这个类一般有一些典型的行为，例如程序员，Coder:\ntype Coder interface { WriteBug() SloveBug() } 如果是组合的接口，一般这样：\n// 和结构内嵌相似，我们可以用这种方式以一个简写命名一个接口，而不用声明它所有的方法 type ReadWriter interface { Reader Writer } 接口赋值接口 var w io.Writer var rwc io.ReadWriteCloser w = rwc // OK: io.ReadWriteCloser has Write method rwc = w // compile error: io.Writer lacks Close method 实现接口 若某类型指针接收者的方法实现了接口，那么该类型的指针实现了接口，但是该类型变量并没有：\ntype InterfaceTest interface { Read(string) Write() string } type interfaceTestImpl struct { Name string } func (i *interfaceTestImpl) Read(name string) { i.Name = name } func (i *interfaceTestImpl) Write() string { return i.Name } var it InterfaceTest iti := interfaceTestImpl{\u0026#34;name\u0026#34;} it = iti // Cannot use \u0026#39;iti\u0026#39; (type interfaceTestImpl) as type testpac.InterfaceTest Type does not implement \u0026#39;testpac.InterfaceTest\u0026#39; as \u0026#39;Read\u0026#39; method has a pointer receiver it = \u0026amp;iti // ok 编译期检查接口的实现 // *bytes.Buffer must satisfy io.Writer var _ io.Writer = (*bytes.Buffer)(nil) 突破Golang的导出限制 参考鸟窝：突破限制,访问其它Go package中的私有函数\n此外，reflect可以访问其他struct的私有成员变量(只能访问不能修改)。\n//go:xxx 参考：//go:xxx 是什么？\n两个接口值的比较可能会panic 接口值可以使用==和!＝来进行比较。两个接口值相等仅当它们都是nil值，或者它们的动态类型相同并且动态值也根据这个动态类型的==操作相等。因为接口值是可比较的，所以它们可以用在map的键或者作为switch语句的操作数。 然而，如果两个接口值的动态类型相同，但是这个动态类型是不可比较的（比如切片），将它们进行比较就会失败并且panic:\nvar x interface{} = []int{1, 2, 3} fmt.Println(x == x) // panic: comparing uncomparable type []int 考虑到这点，接口类型是非常与众不同的。其它类型要么是安全的可比较类型（如基本类型和指针）要么是完全不可比较的类型（如切片，映射类型，和函数），但是在比较接口值或者包含了接口值的聚合类型时，必须要意识到潜在的panic。同样的风险也存在于使用接口作为map的键或者switch的操作数。只能比较非常确定它们的动态值是可比较类型的接口值。\n一个包含nil指针的接口不是nil接口 一个不包含任何值的nil接口值和一个刚好包含nil指针的接口值是不同的。 例：\nconst debug = true func main() { var buf *bytes.Buffer if debug { buf = new(bytes.Buffer) // enable collection of output } f(buf) // NOTE: subtly incorrect! if debug { // ...use buf... } } // If out is non-nil, output will be written to it. func f(out io.Writer) { // ...do something... if out != nil { out.Write([]byte(\u0026#34;done!\\n\u0026#34;)) } } 当debug变量设置为true时，main函数会将f函数的输出收集到一个bytes.Buffer类型中。我们可能会预计当把变量debug设置为false时可以禁止对输出的收集，但是实际上在out.Write方法调用时程序发生了panic：\nif out != nil { out.Write([]byte(\u0026#34;done!\\n\u0026#34;)) // panic: nil pointer dereference } 当main函数调用函数f时，它给f函数的out参数赋了一个*bytes.Buffer的空指针，所以out的动态值是nil。然而，它的动态类型是*bytes.Buffer，意思就是out变量是一个包含空指针值的非空接口，所以防御性检查out!=nil的结果依然是true。 动态分配机制依然决定(*bytes.Buffer).Write的方法会被调用，但是这次的接收者的值是nil。对于一些如*os.File的类型，nil是一个有效的接收者，但是*bytes.Buffer类型不在这些种类中。这个方法会被调用，但是当它尝试去获取缓冲区时会发生panic。]\n问题在于尽管一个nil的*bytes.Buffer指针有实现这个接口的方法，它也不满足这个接口具体的行为上的要求。特别是这个调用违反了(*bytes.Buffer).Write方法的接收者非空的隐含先觉条件，所以将nil指针赋给这个接口是错误的。解决方案就是将main函数中的变量buf的类型改为io.Writer，因此可以避免一开始就将一个不完整的值赋值给这个接口：\nvar buf io.Writer if debug { buf = new(bytes.Buffer) // enable collection of output } f(buf) // OK 通过断言询问行为(询问一个接口的\u0026quot;动态类型\u0026quot;是否具备某些接口定义外的行为) 看例子：\nfunc writeHeader(w io.Writer, contentType string) error { if _, err := w.Write([]byte(\u0026#34;Content-Type: \u0026#34;)); err != nil { return err } if _, err := w.Write([]byte(contentType)); err != nil { return err } // ... } io.Writer接口有方法func Write([]byte)(int, error)，但是这里做[]byte(string)的类型转换会引入开销：分配内存并拷贝。新分配的这块空间除了向io.Writer内写入就没有其他作用了，那么如果是在高并发场景这个操作可能会成为性能瓶颈，如何优化呢？\nio.Writer接口告诉我们关于w持有的具体类型的唯一东西：就是可以向它写入字节切片。查看net/http包源码，可以看到在这个程序中的w变量持有的动态类型也有一个允许字符串高效写入的WriteString方法(许多满足io.Writer接口的重要类型都有WriteString方法，包括*bytes.Buffer，*os.File和*bufio.Writer)。如何使用WriteString方法避免[]byte(string)类型转换的拷贝呢：\n// writeString writes s to w. // If w has a WriteString method, it is invoked instead of w.Write. func writeString(w io.Writer, s string) (n int, err error) { type stringWriter interface { WriteString(string) (n int, err error) } if sw, ok := w.(stringWriter); ok { return sw.WriteString(s) // avoid a copy } return w.Write([]byte(s)) // allocate temporary copy } func writeHeader(w io.Writer, contentType string) error { if _, err := writeString(w, \u0026#34;Content-Type: \u0026#34;); err != nil { return err } if _, err := writeString(w, contentType); err != nil { return err } // ... } 关于接口 当设计一个新的包时，新手Go程序员总是先创建一套接口，然后再定义一些满足它们的具体类型。这种方式的结果就是有很多的接口，它们中的每一个仅只有一个实现。不要再这么做了。这种接口是不必要的抽象；它们也有一个运行时损耗。可以使用导出机制来限制一个类型的方法或一个结构体的字段是否在包外可见。接口只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要。\n当一个接口只被一个单一的具体类型实现时有一个例外，就是由于它的依赖，这个具体类型不能和这个接口存在在一个相同的包中。这种情况下，一个接口是解耦这两个包的一个好方式。\n因为在Go语言中只有当两个或更多的类型实现一个接口时才使用接口，它们必定会从任意特定的实现细节中抽象出来。结果就是有更少和更简单方法的更小的接口（经常和io.Writer或 fmt.Stringer一样只有一个）。当新的类型出现时，小的接口更容易满足。对于接口设计的一个好的标准就是 ask only for what you need（只考虑你需要的东西）\nfmt.Printf + \\r 实现动态输出 \\r == 返回行首，覆盖之前的文字，可以实现动态滚动输出\nfor _, r := range `-\\|/` { fmt.Printf(\u0026#34;\\r%c\u0026#34;, r) time.Sleep(100 * time.Millisecond) } ---------------------------- output: -转圈圈 happens before 在讨论并发编程时，当我们说x事件在y事件之前发生（happens before），我们并不是说x事件在时间上比y时间更早；我们要表达的意思是要保证在此之前的事件都已经完成了，例如在此之前的更新某些变量的操作已经完成，可以放心依赖这些已完成的事件。\n所以为啥不叫 happened and done before\u0026hellip;\nchannel 与 (for range, select case) 无论是有缓存还是无缓存，可以for range持续从channel获取值：\nfor i := range someChan { println(i) } 对于无缓存channel, for range读取后且channel关闭，则循环结束。 对于有缓存channel, 即使channel关闭，for range也会继续读取直到读取完毕。 总结：for range监听channel，结束条件为 channel关闭且channel内容读取完毕。\nselect和switch语句稍微有点相似，也会有几个case和最后的default选择分支。每一个case代表一个通信操作（在某个channel上进行发送或者接收），并且会包含一些语句组成的一个语句块。一个接收表达式可能只包含接收表达式自身或者包含在一个简短的变量声明中:\nselect { case \u0026lt;-ch1: // ... case x := \u0026lt;-ch2: // ...use x... case ch3 \u0026lt;- y: // ... default: // ... } select特性：\n如果某个case代码块准备好发送或接收，执行对应内容 如果多个(\u0026gt;1)case代码块准备好发送或接收，随机选取一个并执行对应内容 如果所有case代码块都没有准备好 无default，等待 有default，执行default select{}永远等待 一个没有任何case的select语句写作select{}，会永远地等待下去。\nselect 与 time.After time.After函数会立即返回一个channel，并起一个新的goroutine在经过特定的时间后向该channel发送一个独立的值。下面的select语句包含了一个超时保护：\nselect { case \u0026lt;-time.After(10 * time.Second): // 超时时间10s，若超时什么都不做，退出select case \u0026lt;-aSigChan: doSomething() } ... select的一个骚操作 ch := make(chan int, 1) for i := 0; i \u0026lt; 10; i++ { select { case x := \u0026lt;-ch: fmt.Println(x) // \u0026#34;0\u0026#34; \u0026#34;2\u0026#34; \u0026#34;4\u0026#34; \u0026#34;6\u0026#34; \u0026#34;8\u0026#34; case ch \u0026lt;- i: } } 轮询channel 下面的select语句会在abort channel中有值时，从其中接收值；无值时什么都不做。这是一个非阻塞的接收操作；反复地做这样的操作叫做“轮询channel”。\nselect { case \u0026lt;-abort: fmt.Printf(\u0026#34;Launch aborted!\\n\u0026#34;) return default: // do nothing } time.Tick time.Tick通常用作定时器：\nfunc main() { tick := time.Tick(time.Second) for { \u0026lt;-tick fmt.Println(\u0026#34;hello\u0026#34;) } } 以上例子每秒输出一个hello，但是time.Tick如果像下面这样使用：\ntick := time.Tick(time.Second) select { case \u0026lt;-tick: // do something case \u0026lt;-aChanSig: // do something } 当select逻辑执行完毕后，tick的goroutine仍然存活着，周期性的尝试向tick中发送值，导致goroutine泄露。 只有当程序整个生命周期都需要时才适合使用time.Tick。否则的话，可以这样用：\nticker := time.NewTicker(1 * time.Second) \u0026lt;-ticker.C // receive from the ticker\u0026#39;s channel ticker.Stop() // cause the ticker\u0026#39;s goroutine to terminate 单方向channel 例如：\nchan\u0026lt;- int:只发送 \u0026lt;-chan int:只接收 通常一个函数参数的channel，参数输入(in)是一个只接受的channel，结果输出(out)是一个只发送的channel：\nfunc doSomeCalc(in \u0026lt;-chan int, out chan\u0026lt;- int){ for input := range in{ out \u0026lt;- calc(input) } } 对一个只接收的channel调用close是一个编译错误。\nmake(chan int) 和 make(chan int, 1) 的区别 test := make(chan int)无缓存，无接收时，test \u0026lt;- 1阻塞。 test := make(chan int, 1)带缓存，容量1，无接收时，test \u0026lt;- 1不阻塞。\n如何判断channel关闭 a := make(chan int) // a没有关闭，以下语句会阻塞，直到a有值输入，intV==值，ok==true intV, ok := \u0026lt;-a --------------------------------------------------------- a := make(chan int) close(a) // a关闭，以下语句不会阻塞，intV==0(int零值)，ok==false intV, ok := \u0026lt;-a 避免将一个channel用在唯一一个goroutine中 无缓存channel当然不能只在同一个goroutine使用，这必然会导致该goroutine阻塞。 有缓存的channel可以用在一个goroutine中，可以作队列用，但是不建议这样使用。 channel和goroutine的调度器机制是紧密相连的，如果没有其他goroutine从channel接收，发送者——或许是整个程序——将会面临永远阻塞的风险。\n带缓存channel的竞速 下面例子并发地向三个镜像站点发出请求，三个镜像站点分散在不同的地理位置。它们分别将收到的响应发送到带缓存channel，最后接收者只接收第一个收到的响应，也就是最快的那个响应。因此mirroredQuery函数可能在另外两个响应慢的镜像站点响应之前就返回了结果。 多个goroutines并发地向同一个channel发送数据，或从同一个channel接收数据都是常见的用法。\nfunc mirroredQuery() string { responses := make(chan string, 3) go func() { responses \u0026lt;- request(\u0026#34;asia.gopl.io\u0026#34;) }() go func() { responses \u0026lt;- request(\u0026#34;europe.gopl.io\u0026#34;) }() go func() { responses \u0026lt;- request(\u0026#34;americas.gopl.io\u0026#34;) }() return \u0026lt;-responses // return the quickest response } func request(hostname string) (response string) { /* ... */ } 上面的竞速和下面有什么区别呢？下面的竞速使用了无缓存的channel，两个比较慢的goroutine将因为channel无人接收而永远卡住，并且不会被自动回收，从而导致goroutine泄漏。\nfunc mirroredQuery() string { responses := make(chan string) go func() { responses \u0026lt;- request(\u0026#34;asia.gopl.io\u0026#34;) }() go func() { responses \u0026lt;- request(\u0026#34;europe.gopl.io\u0026#34;) }() go func() { responses \u0026lt;- request(\u0026#34;americas.gopl.io\u0026#34;) }() return \u0026lt;-responses // return the quickest response } func request(hostname string) (response string) { /* ... */ } pipeline(串联channels) channels也可以用于将多个goroutine连接在一起，一个Channel的输出作为下一个Channel的输入。这种串联的Channels就是所谓的管道（pipeline），见下例和图：\nfunc main() { naturals := make(chan int) squares := make(chan int) // Counter go func() { for x := 0; x \u0026lt; 100; x++ { naturals \u0026lt;- x } close(naturals) }() // Squarer go func() { for x := range naturals { squares \u0026lt;- x * x } close(squares) }() // Printer (in main goroutine) for x := range squares { fmt.Println(x) } } counter是一个计数器，用于生成0、1、2、……形式的整数序列，然后通过channel将该整数序列发送给squarer求平方，squarer将平方结果通过第二个channel发送给printer。\n并发的非阻塞缓存(内包含重复抑制概念) 场景：缓存函数的返回结果，这样在对函数进行调用的时候，我们就只需要一次计算，之后只要返回计算的结果就可以了。 需求：并发安全，且避免对整个缓存加锁而导致所有操作都去争一个锁。\n函数例程：\n// 进行HTTP GET请求并且获取http响应body, 开销大, 应避免在不必要的时候反复调用 func httpGetBody(url string) (interface{}, error) { resp, err := http.Get(url) if err != nil { return nil, err } defer resp.Body.Close() return ioutil.ReadAll(resp.Body) } 缓存实现：\n// Package memo provides a concurrency-unsafe // memoization of a function of type Func. package memo // A Memo caches the results of calling a Func. type Memo struct { f Func cache map[string]result } // Func is the type of the function to memoize. type Func func(key string) (interface{}, error) type result struct { value interface{} err error } func New(f Func) *Memo { return \u0026amp;Memo{f: f, cache: make(map[string]result)} } // NOTE: not concurrency-safe! func (memo *Memo) Get(key string) (interface{}, error) { res, ok := memo.cache[key] if !ok { res.value, res.err = memo.f(key) memo.cache[key] = res } return res.value, res.err } 顺序的测试缓存：\nm := memo.New(httpGetBody) for url := range incomingURLs() { start := time.Now() value, err := m.Get(url) if err != nil { log.Print(err) } fmt.Printf(\u0026#34;%s, %s, %d bytes\\n\u0026#34;, url, time.Since(start), len(value.([]byte))) } ------------------------------------------------ output: https://golang.org, 175.026418ms, 7537 bytes https://godoc.org, 172.686825ms, 6878 bytes https://play.golang.org, 115.762377ms, 5767 bytes http://gopl.io, 749.887242ms, 2856 bytes https://golang.org, 721ns, 7537 bytes https://godoc.org, 152ns, 6878 bytes https://play.golang.org, 205ns, 5767 bytes http://gopl.io, 326ns, 2856 bytes 那么如果像下面这样并发的测试缓存，由于Get函数不是concurrency-safe，所有会有数据竞争。\nm := memo.New(httpGetBody) var n sync.WaitGroup for url := range incomingURLs() { n.Add(1) go func(url string) { start := time.Now() value, err := m.Get(url) if err != nil { log.Print(err) } fmt.Printf(\u0026#34;%s, %s, %d bytes\\n\u0026#34;, url, time.Since(start), len(value.([]byte))) n.Done() }(url) } n.Wait() 使用-race来观察数据竞争会看到：\n... WARNING: DATA RACE Write by goroutine 36: runtime.mapassign1() ~/go/src/runtime/hashmap.go:411 +0x0 *** *** ... Previous write by goroutine 35: runtime.mapassign1() ~/go/src/runtime/hashmap.go:411 +0x0 *** *** ... Found 1 data race(s) 消除数据竞争最简单的方法就是加锁：\ntype Memo struct { f Func mu sync.Mutex // guards cache cache map[string]result } // Get is concurrency-safe. func (memo *Memo) Get(key string) (value interface{}, err error) { memo.mu.Lock() res, ok := memo.cache[key] if !ok { res.value, res.err = memo.f(key) memo.cache[key] = res } memo.mu.Unlock() return res.value, res.err } 但是加了这个锁，Get就将本来可以并行的I/O操作串行化了。\n怎么优化呢？上面Lock锁的范围太大了，考虑缩小临界区，下面的优化把开销最大的I/O操作从临界区分离出来，使得I/O操作可并发，但是，对于相同的key，memo.f(key)可能会重复执行。\nfunc (memo *Memo) Get(key string) (value interface{}, err error) { memo.mu.Lock() res, ok := memo.cache[key] memo.mu.Unlock() if !ok { res.value, res.err = memo.f(key) // Between the two critical sections, several goroutines // may race to compute f(key) and update the map. memo.mu.Lock() memo.cache[key] = res memo.mu.Unlock() } return res.value, res.err } 上述的重复工作是应该避免的，这也有个专业名词，叫duplicate suppression(重复抑制)。看下面的优化。获取互斥锁来保护共享变量cache map，查询map中是否存在指定条目，如果没有找到那么分配空间插入一个新条目，释放互斥锁。如果存在条目的话且其值没有写入完成(也就是有其它的goroutine在调用f这个慢函数)时，goroutine必须等待值ready之后才能读到条目的结果。而想知道是否ready的话，可以直接从ready channel中读取，由于这个读取操作在channel关闭之前一直是阻塞。 如果没有条目的话，需要向map中插入一个没有准备好的条目，当前正在调用的goroutine就需要负责调用慢函数、更新条目以及向其它所有goroutine广播条目已经ready可读的消息了。 条目中的e.res.value和e.res.err变量是在多个goroutine之间共享的。创建条目的goroutine同时也会设置条目的值，其它goroutine在收到\u0026quot;ready\u0026quot;的广播消息之后立刻会去读取条目的值。尽管会被多个goroutine同时访问，但却并不需要互斥锁。ready channel的关闭一定会发生在其它goroutine接收到广播事件之前，因此第一个goroutine对这些变量的写操作是一定发生在这些读操作之前的。不会发生数据竞争。 这样并发、不重复、无阻塞的cache就完成了。\ntype entry struct { res result ready chan struct{} // closed when res is ready } func New(f Func) *Memo { return \u0026amp;Memo{f: f, cache: make(map[string]*entry)} } type Memo struct { f Func mu sync.Mutex // guards cache cache map[string]*entry } func (memo *Memo) Get(key string) (value interface{}, err error) { memo.mu.Lock() e := memo.cache[key] if e == nil { // This is the first request for this key. // This goroutine becomes responsible for computing // the value and broadcasting the ready condition. e = \u0026amp;entry{ready: make(chan struct{})} memo.cache[key] = e memo.mu.Unlock() e.res.value, e.res.err = memo.f(key) close(e.ready) // broadcast ready condition } else { // This is a repeat request for this key. memo.mu.Unlock() \u0026lt;-e.ready // wait for ready condition } return e.res.value, e.res.err } 上面的例子使用互斥量来保护多个goroutine调用Get时的共享map变量。接下来使用monitor goroutine(把map变量限制在一个单独goroutine)方案再实现一遍，使用monitor goroutine是需要使用到消息。（即对比下共享内存通信和消息通信）\n// Func is the type of the function to memoize. type Func func(key string) (interface{}, error) // A result is the result of calling a Func. type result struct { value interface{} err error } type entry struct { res result ready chan struct{} // closed when res is ready } // A request is a message requesting that the Func be applied to key. type request struct { key string response chan\u0026lt;- result // the client wants a single result } type Memo struct{ requests chan request } // New returns a memoization of f. Clients must subsequently call Close. func New(f Func) *Memo { memo := \u0026amp;Memo{requests: make(chan request)} go memo.server(f) return memo } func (memo *Memo) Get(key string) (interface{}, error) { response := make(chan result) memo.requests \u0026lt;- request{key, response} res := \u0026lt;-response return res.value, res.err } func (memo *Memo) Close() { close(memo.requests) } func (memo *Memo) server(f Func) { cache := make(map[string]*entry) for req := range memo.requests { e := cache[req.key] if e == nil { // This is the first request for this key. e = \u0026amp;entry{ready: make(chan struct{})} cache[req.key] = e go e.call(f, req.key) // call f(key) } go e.deliver(req.response) } } func (e *entry) call(f Func, key string) { // Evaluate the function. e.res.value, e.res.err = f(key) // Broadcast the ready condition. close(e.ready) } func (e *entry) deliver(response chan\u0026lt;- result) { // Wait for the ready condition. \u0026lt;-e.ready // Send the result to the client. response \u0026lt;- e.res } context context翻译：\n上下文;语境;(事情发生的)背景，环境 上下文，按我个人通俗的理解，就是一段代码(线程、协程等调度单元)在CPU的寄存器状态集，运行代码就把这段状态加载到寄存器，切出代码就把寄存器的状态保存到缓存或内存。\ngo的context本质上也是goroutine间通信的工具，用于在多个goroutine之间共享消息。channel是goroutine之间传递消息的桥梁，当然也可以用来传递一个关闭信号(channel+select实现)，但是如果需要“广播”，可以使用close channel的方式发送一个“广播”信号；context其实就是帮助做了“广播”，其Done方法就是利用一个 \u0026lt;-chan struct{} 的关闭来实现“广播”效果；此外，context还能存储一些信息，用来在多个goroutine之间共享。\n关于context的几点说明：\n不要将 Context 塞到结构体里。直接将 Context 类型作为函数的第一参数，而且一般都命名为 ctx 不要向函数传入一个 nil 的 context，如果你实在不知道传什么，标准库给你准备好了一个 context：todo 不要把本应该作为函数参数的类型塞到 context 中，context 存储的应该是一些共同的数据，例如：登陆的 session、cookie 等 同一个 context 可能会被传递到多个 goroutine，但 context 是并发安全，所以没关系 几个关键函数：\n// Background returns a non-nil, empty Context. It is never canceled, has no // values, and has no deadline. It is typically used by the main function, // initialization, and tests, and as the top-level Context for incoming // requests. func Background() Context // TODO returns a non-nil, empty Context. Code should use context.TODO when // it\u0026#39;s unclear which Context to use or it is not yet available (because the // surrounding function has not yet been extended to accept a Context // parameter). func TODO() Context // 与共享信息有关的 WithValue // WithValue returns a copy of parent in which the value associated with key is // val. // // Use context Values only for request-scoped data that transits processes and // APIs, not for passing optional parameters to functions. // // The provided key must be comparable and should not be of type // string or any other built-in type to avoid collisions between // packages using context. Users of WithValue should define their own // types for keys. To avoid allocating when assigning to an // interface{}, context keys often have concrete type // struct{}. Alternatively, exported context key variables\u0026#39; static // type should be a pointer or interface. func WithValue(parent Context, key, val interface{}) Context // 与“广播”控制有关的 WithCancel WithDeadline WithTimeout // WithCancel returns a copy of parent with a new Done channel. The returned // context\u0026#39;s Done channel is closed when the returned cancel function is called // or when the parent context\u0026#39;s Done channel is closed, whichever happens first. // // Canceling this context releases resources associated with it, so code should // call cancel as soon as the operations running in this Context complete. func WithCancel(parent Context) (ctx Context, cancel CancelFunc) // WithDeadline returns a copy of the parent context with the deadline adjusted // to be no later than d. If the parent\u0026#39;s deadline is already earlier than d, // WithDeadline(parent, d) is semantically equivalent to parent. The returned // context\u0026#39;s Done channel is closed when the deadline expires, when the returned // cancel function is called, or when the parent context\u0026#39;s Done channel is // closed, whichever happens first. // // Canceling this context releases resources associated with it, so code should // call cancel as soon as the operations running in this Context complete. func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) // WithTimeout returns WithDeadline(parent, time.Now().Add(timeout)). func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) 从上面函数的定义可以看到，context的cancelFunc是与context一同分开返回的，context 本身并没有取消函数，这样做的原因是取消函数只能由外层函数调用，防止子节点 context 调用取消函数，从而严格控制信息的流向：由父节点 context 流向子节点 context。\n举个简单栗子：\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { background := context.Background() // input values values := map[string]string{ \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;: \u0026#34;value2\u0026#34;, } ctxWithValue, _ := context.WithCancel(background) for k, v := range values { ctxWithValue = context.WithValue(ctxWithValue, k, v) } // timeout: 10s, protect usage ctxWithTimeout, cancelFunc := context.WithTimeout(ctxWithValue, time.Second*10) goroutineCount := 10 for i := 0; i \u0026lt; goroutineCount; i++ { go func(ctx context.Context, index int) { count := 0 for { fmt.Println(\u0026#34;gouroutine index: \u0026#34;, index, \u0026#34; \u0026#34;, \u0026#34;count: \u0026#34;, count, \u0026#34; \u0026#34;, \u0026#34;key1: \u0026#34;, ctx.Value(\u0026#34;key1\u0026#34;)) count++ time.Sleep(time.Millisecond * 500) } }(ctxWithTimeout, i) } // sleep 3s, actually should do something time.Sleep(time.Second * 3) cancelFunc() } context可能不是很完美：\nctx放在函数第一个参数，导致代码中ctx泛滥 ctx创建子节点，底层实际是在链表中创建节点，链表的O(n)有些时候会降低效率 但是，context简便的解决了\u0026quot;cancelation\u0026quot;的问题。只能说任何东西都有两面吧。\natomic(TODO) topic1: atomic用法总结 原子操作是在执行中不能被中断的操作，通常由CPU芯片级能力来保证，并由操作系统提供调用，golang基于操作系统的能力，也提供了基于原子操作的支持。\natomic与mutex的区别：原子操作是能保证执行期间连续的，不会被中断；临界区只能保证访问共享数据是按顺序访问的，但不保证访问期间不会被切换context。\n*_test包 包net/url(例子)同路径可以再声明一个net/url_test包。包名的_test后缀告诉go test工具它应该建立一个额外的包来运行测试。 可以将这个外部测试包的导入路径视作是net/url_test会，但是实际上，它并不能被其他任何包导入。\n包内测试函数就可以测试逻辑，为啥还要搞外部测试包？ 外部测试包是一个独立的包，所以能够导入那些依赖待测代码本身的其他辅助包，包内的测试代码无法做到这点。 在设计层面，外部测试包是在所有它依赖的包的上层。 举个具体的例子，B包依赖的A包，A包在进行测试时，希望使用B包的功能，可是如果A直接importB，那么就发生了循环依赖，将导致编译报错。此时就可以在A内开一个A_test的外部测试包，这个测试包可以以一个第三方包的角色同时import A B，这样就可以测试了。\n别写脆弱的测试代码 避免脆弱测试代码的方法是只检测真正关心的属性。\n保持测试代码的简洁和内部结构的稳定。特别是对断言部分要有所选择。不要对字符串进行全字匹配，而是针对那些在项目的发展中是比较稳定不变的子串（很多时候值得花力气来编写一个从复杂输出中提取用于断言的必要信息的函数，虽然这可能会带来很多前期的工作，但是它可以帮助迅速及时修复因为项目演化而导致的不合逻辑的失败测试）。\ngo test 配合 go tool cover 查看单测覆盖情况(HTML) 关于go test, go tool cover可具体查看命令文档。\n实践：\n// 生成测试文件test-tmp.out // -coverprofile 通过在测试代码中插入生成钩子来统计覆盖率数据 // 在运行每个测试前，它将待测代码拷贝一份并做修改，在每个词法块都会设置一个布尔标志变量。当被修改后的被测试代码运行退出时，将统计日志数据写入输出文件，并打印一部分执行的语句的一个总结 // 如果只需要摘要，可以使用 -cover go test -covermode=count -coverprofile=test-tmp.out ./... // 浏览器html形式查看测试报告 go tool cover -html=test-tmp.out go test 与 性能分析 go test -cpuprofile=cpu.out // cpu go test -blockprofile=block.out // 阻塞：记录阻塞goroutine最久的操作 go test -memprofile=mem.out // 内存 使用reflect访问(仅访问无法修改)struct非导出成员 package testpac type ReflectTestStruct struct { Name string // export age int // not export } func (r *ReflectTestStruct) SetAge(age int) { r.age = age } ------------------------------------------- package main func main() { rts1 := testpac.ReflectTestStruct{ Name: \u0026#34;test1\u0026#34;, } rts1e := reflect.ValueOf(\u0026amp;rts1).Elem() rts1.SetAge(28) fmt.Println(\u0026#34;ReflectTestStruct.age: \u0026#34;, rts1e.FieldByName(\u0026#34;age\u0026#34;)) 高效的使用reflect(TODO) topic1: reflect用法总结 topic2: 分析反射导致性能下降的理论原因，关于reflect导致性能下滑有鸟窝的blog记载： Go Reflect 性能 topic3: 调研golang原生序列化/反序列化和几个其他实现的区别，看看大家的优化思路，和优化点适用的场景 topic4: 总结下反射使用过程中一些能减轻性能下滑的小tips(可能需要跑大量的benchmark测试各个反射函数的性能对比分析) 例如预先通过字段名或者方法名获取到对应的字段序号，使用Field(n)/Method(n)，而不是频繁使用FieldByName()/MethodByName() 首先，日常代码是不建议使用反射的。然后，使用反射必然会导致性能下降，但是还是能通过恰当的使用方法做到性能下滑少一些。\n内存对齐 例：\ntype demo1 struct { a int8 b int16 c int32 } type demo2 struct { a int8 c int32 b int16 } type demo3 struct { a int8 c int32 b int16 d int16 } func main() { fmt.Println(unsafe.Sizeof(demo1{})) // 8 fmt.Println(unsafe.Sizeof(demo2{})) // 12 fmt.Println(unsafe.Sizeof(demo3{})) // 12 } demo1:\na 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节 b 是第二个字段，对齐倍数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节 c 是第三个字段，对齐倍数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可 demo2:\na 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节 c 是第二个字段，对齐倍数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节 b 是第三个字段，对齐倍数为 2，从第 8 个位置开始占据 2 字节 最终，demo2 的对齐倍数由 c 的对齐倍数决定，也是 4，因此，demo2还要占据 2 字节 ，内存占用为 12 字节 demo3:\na 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节 c 是第二个字段，对齐倍数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节 b 是第三个字段，对齐倍数为 2，从第 8 个位置开始占据 2 字节 d 是第四个字段，对齐倍数为 2，从第 10 个位置开始占据 2 字节 空 struct{} 的内存对齐 空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是有一种情况除外：即当 struct{} 作为结构体最后一个字段时，需要内存对齐。因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）：\ntype demo3 struct { c int32 a struct{} } type demo4 struct { a struct{} c int32 } func main() { fmt.Println(unsafe.Sizeof(demo3{})) // 8 fmt.Println(unsafe.Sizeof(demo4{})) // 4 } Golang指针运算 Go的指针是不支持运算的，但是借助unsafe.Pointer和uintptr可以实现这个骚操作。\n类型 概念 持有对象(即指针不释放，其持有的对象GC无法回收) 指针运算 转换 * 普通的指针，传递对象的地址 可持有 不支持 与unsafe.Pointer相互转换 unsafe.Pointer 类似C的void*，可以包含任意类型变量的地址 可持有 不支持 与 *和uintptr 相互转换 uintptr 可以理解为一个纯数值?(字节长度与int一致，uintptr is an integer type that is large enough to hold the bit pattern of any pointer) 不可持有(GC 不把 uintptr 当指针，uintptr 类型的目标会被回收) 支持 与unsafe.Pointer相互转换 如上表，unsafe.Pointer 是桥梁，可以让任意类型的指针实现相互转换，也可以将任意类型的指针转换为 uintptr 进行指针运算。\n举个栗子：\npackage main ​ import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) ​ func main() { //定义一个长度为3的int8类型数组 a:=[3]int8{6,8,9} //取出数组第一个位置的地址 a_first_point:=\u0026amp;a[0] a_first_unsafe_point:=unsafe.Pointer(a_first_point) fmt.Println(\u0026#34;a[0]的地址为：\u0026#34;,a_first_unsafe_point) //指针只能一个字节字节取，int8占一个字节，所以看到值只加了1 fmt.Println(\u0026#34;a[1]的地址为：\u0026#34;,unsafe.Pointer(\u0026amp;a[1])) //把a_first_unsafe_point转成uintptr类型，就可以指针运算了 a_uintptr_first_unsafe_point:=uintptr(a_first_unsafe_point) //指针+1 表示到了数组的第二个位置 a_uintptr_first_unsafe_point++ fmt.Println(\u0026#34;a[0]位置指针自增1后，的指针位置：\u0026#34;,a_uintptr_first_unsafe_point) //打印出来可以看到跟\u0026amp;a[1]的地址是一样的 a_uintptr_second_unsafe_point:=unsafe.Pointer(a_uintptr_first_unsafe_point) fmt.Println(\u0026#34;a[0]位置指针自增1后，的指针位置，转成unsafe_Pointer类型：\u0026#34;,a_uintptr_second_unsafe_point) //将该指针转换成 *int8类型（因为它本身就是*int8类型） int8_point:=(*int8)(a_uintptr_second_unsafe_point) //解引用，得到指针对应的结果，就是数组的第二个值，8 fmt.Println(*int8_point) ​ } -------------------------- output: a[0]的地址为： 0xc000118000 a[1]的地址为： 0xc000118001 a[0]位置指针自增1后，的指针位置： 824634867713 a[0]位置指针自增1后，的指针位置，转成unsafe_Pointer类型： 0xc000118001 8 再举个正反栗：\n// right var x struct { a bool b int16 c []int } // 和 pb := \u0026amp;x.b 等价 pb := (*int16)(unsafe.Pointer( uintptr(unsafe.Pointer(\u0026amp;x)) + unsafe.Offsetof(x.b))) *pb = 42 fmt.Println(x.b) // \u0026#34;42\u0026#34; ------------------------------------ // wrong // NOTE: subtly incorrect! // 错误的原因是引入一个非指针的临时变量tmp，导致垃圾收集器无法正确识别这个是一个指向变量x的指针 // 当第二个语句执行时，变量x可能已经被转移，这时候临时变量tmp也就不再是现在的\u0026amp;x.b地址 // 第三个向之前无效地址空间的赋值语句将彻底摧毁整个程序 tmp := uintptr(unsafe.Pointer(\u0026amp;x)) + unsafe.Offsetof(x.b) pb := (*int16)(unsafe.Pointer(tmp)) *pb = 42 ------------------------------------ // 错误的原因是，并没有指针引用new新创建的变量，因此该语句执行完成之后， // 垃圾收集器有权马上回收其内存空间，所以返回的pT将是无效的地址 pT := uintptr(unsafe.Pointer(new(T))) 看了上面的例子，当从其他地方获取到了uintptr以后，为了避免GC回收其对应地址的变量，应该尽快将uintptr转化为unsafe.Pointer。\ncgo(TODO) topic1: cgo用法总结 cgo如果c代码在go文件同目录下的c文件内，必须go run .或者go build才能在编译阶段把.c文件编译进来，go run main.go不行\n错误处理 优先使用 errors.New 来创建错误变量，如果有格式化需求，可以使用 fmt.Errorf 在 fmt.Errorf 中使用 : %w 关键字来将一个错误 wrap 至其错误链中 使用 errors.Unwrap 来获得其错误链的上一个错误 使用 errors.Is 而非 == 来判定一个错误是否为特定错误(能够追溯错误链) 在错误链上获取特定种类的错误，使用 errors.As ","permalink":"https://duck-dd.github.io/posts/go-tips/","summary":"\u003cp\u003e说明：\u003c/p\u003e\n\u003cp\u003e持续更新(标题含TODO关键字的小节，都会以topic开始，后续会持续完善topic)。记录内容是一些对我而言：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e小的骚操作(可能有些tricky)\u003c/li\u003e\n\u003cli\u003e容易理解偏差的点\u003c/li\u003e\n\u003cli\u003e冷门的点(没啥用的点)\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"golang代码执行顺序\"\u003eGolang代码执行顺序\u003c/h2\u003e\n\u003cp\u003e没有并发，一个顺序逻辑，CPU真正执行指令不一定与编码顺序完全一致，Go的编译器会做优化，前提是会解决依赖逻辑，看起来是“顺序执行”这一假设。\u003c/p\u003e\n\u003cp\u003e了解更多可查看Golang内存模型规范。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"internal包\"\u003einternal包\u003c/h2\u003e\n\u003cp\u003einternal包，只能被和internal目录有同一个父目录的包所导入。\n例如，net/http/internal/chunked内部包只能被net/http/httputil或net/http包导入，但是不能被net/url包导入。不过net/url包却可以导入net/http/httputil包。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"变量交换\"\u003e变量交换\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ei, j = j, i // 交换 i 和 j 的值\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003ch2 id=\"for循环有其他识别break的关键字\"\u003efor循环有其他识别break的关键字\u003c/h2\u003e\n\u003cp\u003efor循环内有其他识别break的关键字时，其他关键字内的break会被其识别而不会跳出for，以下用select举例，switch同理。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efor {\n\t\tselect {\n\t\tcase \u0026lt;-sigChan:\n\t\t\t// exit for  \n\t\t\tbreak\n\t\tdefault:\n\t\t  // do something\n\t\t}\n\t}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e以上break并不能退出for循环，可以使用标签或goto解决：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e// 1 标签\nFOR:\n\tfor {\n\t\tselect {\n\t\tcase \u0026lt;-sigChan:\n\t\t\t// exit for  \n\t\t\tbreak FOR\n\t\tdefault:\n\t\t  // do something\n\t\t}\n\t}\n\n----------------------------\n// 2 goto\n\tfor {\n\t\tselect {\n\t\tcase \u0026lt;-sigChan:\n\t\t\t// exit for  \n\t\t\tgoto ENDFOR\n\t\tdefault:\n\t\t  // do something\n\t\t}\n\t}\nENDFOR:\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003ch2 id=\"读取stdin刷题别再因为stdin踩坑了喂\"\u003e读取stdin(刷题别再因为stdin踩坑了喂)\u003c/h2\u003e\n\u003cp\u003efmt包内 Scan系列 SScan系列 Fscan系列如下：\u003c/p\u003e","title":"Golang Tips"},{"content":" 关于我 我为什么叫duck? duck=大可=奇, 即奇奇怪怪, 也对应这里的内容, 杂七杂八奇奇怪怪啥都写 我从事的工作? 新时代民工, 不杰出的码农; 摸爬滚打(摸鱼)已超七载了, 还是没有找到方向 我的爱好? 好吧你可能也不会想知道我有什么爱好, 而且也没什么拿的出手的爱好 联系我? Email: dianxinztq@126.com 关于这里 本空间内容按 目录=\u0026gt;标签 层级分类\n目录 Category 内容 About 简介 CS 计算机方向内容 Read 读 书/博客/论文/文章 等的笔记 Life-Note 生活相关的杂记 Economics 经济/金融/理财/投资 Anything 杂七杂八的记录 标签 Tag Category 内容 About About 简介 Tag Category 内容 Golang CS go语言专栏 Rust CS rust语言专栏 Python CS python语言专栏 Leetcode CS leetcode刷题记录 Algorithm CS 算法记录\u0026amp;总结 CS-Other CS CS杂七杂八记录 Tag Category 内容 Read-note Read 读书笔记, 一般是短篇内容的精细记录 Read-summary Read 读书思考, 一般是长篇内容的概括总结 Tag Category 内容 Family Life-Note 关于家庭 Car Life-Note 关于车 House Life-Note 关于房 Tag Category 内容 Economics-Note Economics 经济方面杂记 Investment Economics 关于投资 Tag Category 内容 Anything Anything - ","permalink":"https://duck-dd.github.io/about/","summary":"\u003chr\u003e\n\u003ch1 id=\"关于我\"\u003e关于我\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e我为什么叫duck? duck=大可=奇, 即奇奇怪怪, 也对应这里的内容, 杂七杂八奇奇怪怪啥都写\u003c/li\u003e\n\u003cli\u003e我从事的工作? 新时代民工, 不杰出的码农; 摸爬滚打(摸鱼)已超七载了, 还是没有找到方向\u003c/li\u003e\n\u003cli\u003e我的爱好? 好吧你可能也不会想知道我有什么爱好, 而且也没什么拿的出手的爱好\u003c/li\u003e\n\u003cli\u003e联系我? Email: \u003ca href=\"mailto:dianxinztq@126.com\"\u003edianxinztq@126.com\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch1 id=\"关于这里\"\u003e关于这里\u003c/h1\u003e\n\u003cp\u003e本空间内容按 目录=\u0026gt;标签 层级分类\u003c/p\u003e\n\u003ch2 id=\"目录\"\u003e目录\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eCategory\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003e内容\u003c/strong\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eAbout\u003c/td\u003e\n          \u003ctd\u003e简介\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eCS\u003c/td\u003e\n          \u003ctd\u003e计算机方向内容\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eRead\u003c/td\u003e\n          \u003ctd\u003e读 书/博客/论文/文章 等的笔记\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eLife-Note\u003c/td\u003e\n          \u003ctd\u003e生活相关的杂记\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eEconomics\u003c/td\u003e\n          \u003ctd\u003e经济/金融/理财/投资\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eAnything\u003c/td\u003e\n          \u003ctd\u003e杂七杂八的记录\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"标签\"\u003e标签\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eTag\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003eCategory\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003e内容\u003c/strong\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eAbout\u003c/td\u003e\n          \u003ctd\u003eAbout\u003c/td\u003e\n          \u003ctd\u003e简介\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eTag\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003eCategory\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003e内容\u003c/strong\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eGolang\u003c/td\u003e\n          \u003ctd\u003eCS\u003c/td\u003e\n          \u003ctd\u003ego语言专栏\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eRust\u003c/td\u003e\n          \u003ctd\u003eCS\u003c/td\u003e\n          \u003ctd\u003erust语言专栏\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ePython\u003c/td\u003e\n          \u003ctd\u003eCS\u003c/td\u003e\n          \u003ctd\u003epython语言专栏\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eLeetcode\u003c/td\u003e\n          \u003ctd\u003eCS\u003c/td\u003e\n          \u003ctd\u003eleetcode刷题记录\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eAlgorithm\u003c/td\u003e\n          \u003ctd\u003eCS\u003c/td\u003e\n          \u003ctd\u003e算法记录\u0026amp;总结\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eCS-Other\u003c/td\u003e\n          \u003ctd\u003eCS\u003c/td\u003e\n          \u003ctd\u003eCS杂七杂八记录\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eTag\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003eCategory\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003e内容\u003c/strong\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eRead-note\u003c/td\u003e\n          \u003ctd\u003eRead\u003c/td\u003e\n          \u003ctd\u003e读书笔记, 一般是短篇内容的精细记录\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eRead-summary\u003c/td\u003e\n          \u003ctd\u003eRead\u003c/td\u003e\n          \u003ctd\u003e读书思考, 一般是长篇内容的概括总结\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eTag\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003eCategory\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003e内容\u003c/strong\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFamily\u003c/td\u003e\n          \u003ctd\u003eLife-Note\u003c/td\u003e\n          \u003ctd\u003e关于家庭\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eCar\u003c/td\u003e\n          \u003ctd\u003eLife-Note\u003c/td\u003e\n          \u003ctd\u003e关于车\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eHouse\u003c/td\u003e\n          \u003ctd\u003eLife-Note\u003c/td\u003e\n          \u003ctd\u003e关于房\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eTag\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003eCategory\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003e内容\u003c/strong\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eEconomics-Note\u003c/td\u003e\n          \u003ctd\u003eEconomics\u003c/td\u003e\n          \u003ctd\u003e经济方面杂记\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eInvestment\u003c/td\u003e\n          \u003ctd\u003eEconomics\u003c/td\u003e\n          \u003ctd\u003e关于投资\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eTag\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003eCategory\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e\u003cstrong\u003e内容\u003c/strong\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eAnything\u003c/td\u003e\n          \u003ctd\u003eAnything\u003c/td\u003e\n          \u003ctd\u003e-\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e","title":"About"},{"content":"这个行业，是一个没有监管，没有行业标准(有的大部分也是扯淡)，群魔乱舞的行业，这行业人的话，不要相信，不要相信，不要相信\n从我自身经历来说，这件事真的不复杂，完全不值他现在的价钱；一开始这件事很神秘，你觉得付多少钱都是合理的，但真不是这样，到处都是骗钱的；所以装修开始前真正的第一件事，就是你要了解一下背景评估一下工作量，放心大胆的去砍价吧\n本文从自己的亲身经历出发来分析一下装修这件令人头疼的事情，没有展开太多的细节，只以各个阶段的典型选择题为切入点，欢迎指正和交流，预祝你获得你的梦中情屋～\n全包 or 半包 如果你刚开始考虑装修，那你一定是特别开心和兴奋的。你面临的第一个问题大概就是，\u0026ldquo;半包\u0026rdquo; or \u0026ldquo;全包\u0026rdquo;（自己找工人的方式，不太了解就不谈了）；很多声音会告诉你说，全包这种完全黑盒的行为会有太多坑了，给你用的东西都是差的balabala 但是，如果你想省心，或者在装修的这几个月里你没有太多的时间精力能够投入进这件事，那么还是建议你咬咬牙忽略这些有一丢丢危言耸听的说法，果断的选择全包；如果你选择了全包，那么我们对最终效果的确认无非靠两个关键指标\n1 是不是我想要的样子 2 是不是环保 为了第一点，你需要查看素材库确认好自己喜欢的样子，跟设计师做充分的沟通，并在施工过程的关键节点约设计师一起去现场做阶段性的沟通和double check，因为省心，所以你做的功课可能不多，其实这比较依赖设计师的专业性 为了第二点，你需要做的功课是，查一查装修过程中哪些使用到的材料可能会不环保，然后直接在合同里声明好这些材料具体使用哪些品牌的哪些型号，并在这些材料入场时做好检查(其实可以找类似\u0026quot;监工\u0026quot;的角色来帮助你执行，应该总比你完全不去现场要好)\n朋友，如果你选择了半包，那你是真的勇士，对你表示敬佩，以下的讨论咱们就默认你已经做了大量的背景\u0026amp;功课的学习。\n入户门 换！你99%不喜欢开发商的这个，相比换锁，就干脆直接换门吧\n窗户 如果允许，换！拉满配(可能很多地方政策不允许动外立面，那就没办法了)\n隔音 如果你对声音要求很高，考虑做全屋音响，那是肯定得做了 如果你没有考虑做全屋音响，那么我还是强！烈！建！议！做隔音！\n全屋定制 or 成品家具 个人观点，全屋定制真的不咋地，建议祛魅，认真的去逛一逛成品家具市场； 还往下看，你果然还是跟我一样，头铁的选择了全屋定制，那这个子方向发个千八百个论文感觉都泛不起一点水花； 商家贩卖的焦虑点：甲醛，苯系化合物；你要想死磕，得先学化学； 标准：国外国内太多标准，但有一点个人觉得有参考意义，就是 抽检 \u0026amp; 送检 ； 品牌选择：大商场大品牌的品牌溢价确实太高了，而且也确实代加工，所以有判断能力那就果断直接找工厂吧； 细节不展开讲了，说一点注意点，跟电位/管道做配合要提前做规划，这也是为什么把这个问题放得这么靠前\n布局 该砸就砸别犹豫(非承重) 新砌墙时考虑好用途，如果有承重需求(例如挂电视 挂柜子等)，考虑好墙体的材料 砌墙后多晾一晾 否则后期墙上面搞得任何东西都容易剥离 墙的平的问题，从小白视角来看，就是表面是平面，并且这个平面跟其他平面的角度(一般90度)是正常的，这点不管施工方是冲筋 垂平还是啥方法，总之先讲清楚要求并让他们严格执行 坐便or蹲便？多个卫生间可以考虑留一个蹲便，不仅健康，而且后期小孩使用也方便，或者上面再放小马桶也好扩展（这个问题需要提前考虑因为可能影响卫生间地面高度布局）\n水电 水管线管一定选择最好的品牌的好的型号，避免后期出问题太麻烦 至于是按使用长度算，还是一口价模式，自己来衡量对比，是否点对点走线？可以看网上大量的分析 电箱位置挪不挪？如果风水问题(那么你一定是相信这个的)，挪；如果只是为了好看，那后期挺多方法弄好看，可以看看效果自己能不能接受 前置过滤器：空间允许，就安；拉满配，本身没多贵，影响水压就不好了 全屋软水：没考虑清楚，就做 下水：有顾虑该做的位置就做，用不用得上再说 电位：有顾虑就做，总比后期拉插线板强(70个/100平 ？) 开关：一开多控别顾虑，想做就做，方便生活 全屋智能：已经在考虑这个问题了？那就做。。。有点贵，考虑好性价比吧，应了那句话，贵的东西，除了贵，没有其他的毛病；这里不展开讲了，太复杂了，完全可以单开一页的东西；PS:从初中物理来分析全屋智能，既然有智能控制开关，而这个开关本身也是需要供电的，那么如果把开关串联到电路里，他就不是yes or no的开关，关闭状态本身是一个大电阻，也就是还是有微弱的电流通过电路，这一定是不好的，所以还是预留好控制路的零线吧\n有两个容易忽略的点\n1 墙面不能开长的横槽(脑补一下这确实会影响墙的稳定性) 2 强弱电磁场干扰问题，物理已经还给老师了，但是避免干扰这个要保持距离还是符合常识的 接下来让我们一起进入木瓦油环节\n全屋吊顶 or 部分吊顶 如果考虑做无主灯，那么肯定全屋吊顶 如果对层高有要求，那么就别吊顶 如果犹豫，那么就别做(我认为全部吊顶的目的就是做光线的规划，犹豫的话说明没有要求或规划，那就别做算了)\n房间门 没考虑清楚的话，就无脑一门到顶(心情舒畅) 隐藏门看个人需求，有很墙设计感的风格可以考虑，其他不建议\n厨房门 中式饮食，果断放弃开放式厨房； 如果不是影响南北通透，就果断正常用普通的小门\n吊轨门 or 地轨门 如果一定要一个大门，没想清楚的话，我的建议就是吊轨门吧(就无脑冲最新的好看的款式，承重龙骨就拉满配)\n木地板 or 瓷砖 这个是要兼顾装修风格来考虑的，如果有选择空间，那么我建议你选木地板(因为我没选；木地板有N多个顾虑点，但是正常居住感觉是不会有问题的)\n瓷砖的选择: 哑光 or 柔光 or 亮面 如果你选择了瓷砖，那么又要面临五花八门的种类；没想清楚的话，我的建议就是哑光\n美缝 美缝的材料五花八门，迭代又块，总之，聚脲也就那样吧(2023年)\n小砖上墙 or 大砖上墙 如果你纠结的是常规的厨房或卫生间，那么感觉差异不大，因为后期露出来的部分确实不多 如果是为了好看，那就拉满配，3m的岩板嘎嘎好看，当然，如果你是3m的大理石，那更好了@@\n石材 花小钱办大事，一共用不了多少，只要不被宰价格差不了太多，至少用石英石(油漆窗台后期有养花草需求，尽量别用岗石) 厨房台面石材厚度，拉满\u0026hellip;\n洗菜洗碗池 单槽 空间大洗锅方便 台下盆容易打理\n漆 我选择了乳胶漆，其他的不敢妄言； 这里的商家主要是在贩卖焦虑，只要是大品牌官方销售渠道的主流产品，问题感觉都不大 如果真的就高环保要求，那么你的重点应该更多关注底漆 儿童漆？不知道，反正我用了，你可以多跑一些实体店，有些店如果有库存压力，会把库存漆便宜价格给你\n灯 如果不是无主灯，需要买灯的话，一定别去实体店，要贵好几倍 个人建议，买亮不买暗，买大不买小 射灯：慎用(对审美和墙面要求较高) 线条灯: 慎用(对审美和品控要求较高)\n插座 直接拉满配，花小钱办大事的地方；当然也不便宜，预算做好2k以上的打算\n窗帘 如果允许，一定双层(布帘+纱帘)，给所有空间都留下更多的可能吧 电动窗帘？除非宽厅，否则没有太大必要\n马桶 电动？ 加热 冲水自动加清洗剂，这两个有点拯救北方人，其他的感觉都用不上\n沙发 拉满\u0026hellip; 又一个花小钱办大事的地方，预算就按几w去整，皮质的坐着也没有那么不舒服\n电视 or 投影 如果已经做了电视墙，那么自不必说；如果你打游戏，那么果断电视；如果你在犹豫，那么还是电视；总之，如果你没认准投影，那就电视\u0026hellip;\n","permalink":"https://duck-dd.github.io/posts/decoration/","summary":"\u003cp\u003e这个行业，是一个没有监管，没有行业标准(有的大部分也是扯淡)，群魔乱舞的行业，这行业人的话，不要相信，不要相信，不要相信\u003c/p\u003e\n\u003cp\u003e从我自身经历来说，这件事真的不复杂，完全不值他现在的价钱；一开始这件事很神秘，你觉得付多少钱都是合理的，但真不是这样，到处都是骗钱的；所以装修开始前真正的第一件事，就是你要了解一下背景评估一下工作量，放心大胆的去砍价吧\u003c/p\u003e\n\u003cp\u003e本文从自己的亲身经历出发来分析一下装修这件令人头疼的事情，没有展开太多的细节，只以各个阶段的典型选择题为切入点，欢迎指正和交流，预祝你获得你的梦中情屋～\u003c/p\u003e\n\u003ch1 id=\"全包-or-半包\"\u003e全包 or 半包\u003c/h1\u003e\n\u003cp\u003e如果你刚开始考虑装修，那你一定是特别开心和兴奋的。你面临的第一个问题大概就是，\u0026ldquo;半包\u0026rdquo; or \u0026ldquo;全包\u0026rdquo;（自己找工人的方式，不太了解就不谈了）；很多声音会告诉你说，全包这种完全黑盒的行为会有太多坑了，给你用的东西都是差的balabala 但是，如果你想省心，或者在装修的这几个月里你没有太多的时间精力能够投入进这件事，那么还是建议你咬咬牙忽略这些有一丢丢危言耸听的说法，果断的选择全包；如果你选择了全包，那么我们对最终效果的确认无非靠两个关键指标\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e1 是不是我想要的样子\u003c/li\u003e\n\u003cli\u003e2 是不是环保\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了第一点，你需要查看素材库确认好自己喜欢的样子，跟设计师做充分的沟通，并在施工过程的关键节点约设计师一起去现场做阶段性的沟通和double check，因为省心，所以你做的功课可能不多，其实这比较依赖设计师的专业性\n为了第二点，你需要做的功课是，查一查装修过程中哪些使用到的材料可能会不环保，然后直接在合同里声明好这些材料具体使用哪些品牌的哪些型号，并在这些材料入场时做好检查(其实可以找类似\u0026quot;监工\u0026quot;的角色来帮助你执行，应该总比你完全不去现场要好)\u003c/p\u003e\n\u003cp\u003e朋友，如果你选择了半包，那你是真的勇士，对你表示敬佩，以下的讨论咱们就默认你已经做了大量的背景\u0026amp;功课的学习。\u003c/p\u003e\n\u003ch1 id=\"入户门\"\u003e入户门\u003c/h1\u003e\n\u003cp\u003e换！你99%不喜欢开发商的这个，相比换锁，就干脆直接换门吧\u003c/p\u003e\n\u003ch1 id=\"窗户\"\u003e窗户\u003c/h1\u003e\n\u003cp\u003e如果允许，换！拉满配(可能很多地方政策不允许动外立面，那就没办法了)\u003c/p\u003e\n\u003ch1 id=\"隔音\"\u003e隔音\u003c/h1\u003e\n\u003cp\u003e如果你对声音要求很高，考虑做全屋音响，那是肯定得做了\n如果你没有考虑做全屋音响，那么我还是强！烈！建！议！做隔音！\u003c/p\u003e\n\u003ch1 id=\"全屋定制-or-成品家具\"\u003e全屋定制 or 成品家具\u003c/h1\u003e\n\u003cp\u003e个人观点，全屋定制真的不咋地，建议祛魅，认真的去逛一逛成品家具市场；\n还往下看，你果然还是跟我一样，头铁的选择了全屋定制，那这个子方向发个千八百个论文感觉都泛不起一点水花；\n商家贩卖的焦虑点：甲醛，苯系化合物；你要想死磕，得先学化学；\n标准：国外国内太多标准，但有一点个人觉得有参考意义，就是 \u003ccode\u003e抽检\u003c/code\u003e \u0026amp; \u003ccode\u003e送检\u003c/code\u003e ；\n品牌选择：大商场大品牌的品牌溢价确实太高了，而且也确实代加工，所以有判断能力那就果断直接找工厂吧；\n细节不展开讲了，说一点注意点，跟电位/管道做配合要提前做规划，这也是为什么把这个问题放得这么靠前\u003c/p\u003e\n\u003ch1 id=\"布局\"\u003e布局\u003c/h1\u003e\n\u003cp\u003e该砸就砸别犹豫(非承重) 新砌墙时考虑好用途，如果有承重需求(例如挂电视 挂柜子等)，考虑好墙体的材料\n砌墙后多晾一晾 否则后期墙上面搞得任何东西都容易剥离\n墙的\u003cem\u003e\u003cstrong\u003e平\u003c/strong\u003e\u003c/em\u003e的问题，从小白视角来看，就是表面是平面，并且这个平面跟其他平面的角度(一般90度)是正常的，这点不管施工方是冲筋 垂平还是啥方法，总之先讲清楚要求并让他们严格执行\n坐便or蹲便？多个卫生间可以考虑留一个蹲便，不仅健康，而且后期小孩使用也方便，或者上面再放小马桶也好扩展（这个问题需要提前考虑因为可能影响卫生间地面高度布局）\u003c/p\u003e\n\u003ch1 id=\"水电\"\u003e水电\u003c/h1\u003e\n\u003cp\u003e水管线管一定选择最好的品牌的好的型号，避免后期出问题太麻烦\n至于是按使用长度算，还是一口价模式，自己来衡量对比，是否点对点走线？可以看网上大量的分析\n电箱位置挪不挪？如果风水问题(那么你一定是相信这个的)，挪；如果只是为了好看，那后期挺多方法弄好看，可以看看效果自己能不能接受\n前置过滤器：空间允许，就安；拉满配，本身没多贵，影响水压就不好了\n全屋软水：没考虑清楚，就做\n下水：有顾虑该做的位置就做，用不用得上再说\n电位：有顾虑就做，总比后期拉插线板强(70个/100平 ？)\n开关：一开多控别顾虑，想做就做，方便生活\n全屋智能：已经在考虑这个问题了？那就做。。。有点贵，考虑好性价比吧，应了那句话，贵的东西，除了贵，没有其他的毛病；这里不展开讲了，太复杂了，完全可以单开一页的东西；PS:从初中物理来分析全屋智能，既然有智能控制开关，而这个开关本身也是需要供电的，那么如果把开关串联到电路里，他就不是yes or no的开关，关闭状态本身是一个大电阻，也就是还是有微弱的电流通过电路，这一定是不好的，所以还是预留好控制路的零线吧\u003c/p\u003e\n\u003cp\u003e有两个容易忽略的点\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e1 墙面不能开长的横槽(脑补一下这确实会影响墙的稳定性)\u003c/li\u003e\n\u003cli\u003e2 强弱电磁场干扰问题，物理已经还给老师了，但是避免干扰这个要保持距离还是符合常识的\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e接下来让我们一起进入\u003cstrong\u003e木瓦油\u003c/strong\u003e环节\u003c/p\u003e\n\u003ch1 id=\"全屋吊顶-or-部分吊顶\"\u003e全屋吊顶 or 部分吊顶\u003c/h1\u003e\n\u003cp\u003e如果考虑做无主灯，那么肯定全屋吊顶\n如果对层高有要求，那么就别吊顶\n如果犹豫，那么就别做(我认为全部吊顶的目的就是做光线的规划，犹豫的话说明没有要求或规划，那就别做算了)\u003c/p\u003e","title":"装修那些事儿"},{"content":"写在前面 runtime包实现了所有goroutine scheduler、memory allocator、garbage collector细节，理论上可以从runtime包获取一切信息，没有直接怼源码，而是站在巨人的肩膀上（直接吃大佬们吃剩下的）。\n搜集到的材料，大家都是基于不同的go版本做的分析，而go版本迭代调度算法也在持续更新，所以整理的可能有些乱。但是可以保证的是，所有材料都是GM-\u0026gt;GMP演化后的材料。\nGM go1.1版本以前，调度使用GM模型，如下图所示。简单的理解GM模型，就是有一个始终执行的调度函数schedule不停的执行调度计算，当某个M的G执行完成了，调度器就把这个M放回M队列，可绑定执行其他G（如果某个M+G发生了syscall，那么本来并发度是通过M数量控制的，此时并发度就降低了？）；如果G执行过程中创建新的G，会将新的G放入到G全局可执行队列中。G全局可执行队列的操作有一把全局锁，这导致了各个M对G全局队列的操作存在严重的竞争。\n下面这段完全是我的臆测，请别太相信：\n简单概括呢，所以可以认为有：\nG全局可执行队列(以下也可能简称G可执行队列) M可用队列 调度器要做的事就是：\n从G的可执行队列取G并从M的可用队列取M，将二者绑定开始执行G 对于已经执行完的G，销毁G并立即将M释放回M可用队列供后续使用 那么GM模型有哪些问题呢？\n(重点问题)单一的全局mutex(sched.lock)和集中状态管理 mutex需要保护所有与全局goroutine队列相关操作(创建、完成、重排等等)，竞争严重 (重点问题)per-M内存(M.mcache)问题 每个M都需要一个mcache，会导致资源消耗过大(每个mcache可以吸纳到2MB的内存缓存和其他缓存) 举个栗子，一个陷入syscall的M并不需要使用cache，但是在全部的M中，陷入系统调用的M与执行goroutine的M的比例可能是N:1(N\u0026gt;\u0026gt;1)，这就导致了N/(N+1)比例的mcache在闲置 数据局部性差: 举个栗子，M1执行G1，此时创建了G2，G2通常是立刻进入了G全局可执行队列，而此时M1还在执行G1，所以G2通常被其他M执行，但是G1和G2通常强相关，所以G2最好也在M1上执行，因为G2对M1的缓存命中率更高 goroutine传递问题 goroutine(G)交接(G.nextg)，M之间会经常交接可运行的G 再通俗点说，就是G空转，本来能够好好在一个M上执行完，但是由于全局队列的存在，G一旦回全局队列了，下次就不知道被哪个M取走了，所以叫“空转”；M加载G的上下文是有开销的，所以空转会导致性能下降 频繁的线程阻塞/解阻塞 syscalls情况下，线程经常被阻塞和解阻塞，增加了很多额外开销 通俗点说，M+G syscall，M阻塞，syscall完成后，M解阻塞继续执行G（如果是通过M数量控制并发度，这是不是就导致了并发度降低？） GMP 基于以上说的GM的问题，go1.1以后开始使用GMP调度模型。 G、M、P的定义如下(***/src/runtime/runtime2.go)。\ntype g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer m *m // current m; offset known to arm liblink sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.Pointer // passed parameter on wakeup atomicstatus uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid int64 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting preempt bool // preemption signal, duplicates stackguard0 = stackpreempt preemptStop bool // transition to _Gpreempted on preemption; otherwise, just deschedule preemptShrink bool // shrink stack at synchronous safe point // asyncSafePoint is set if g is stopped at an asynchronous // safe point. This means there are frames on the stack // without precise pointer information. asyncSafePoint bool paniconfault bool // panic (instead of crash) on unexpected fault address gcscandone bool // g has scanned stack; protected by _Gscan bit in status throwsplit bool // must not split stack // activeStackChans indicates that there are unlocked channels // pointing into this goroutine\u0026#39;s stack. If true, stack // copying needs to acquire channel locks to protect these // areas of the stack. activeStackChans bool // parkingOnChan indicates that the goroutine is about to // park on a chansend or chanrecv. Used to signal an unsafe point // for stack shrinking. It\u0026#39;s a boolean value, but is updated atomically. parkingOnChan uint8 raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine sysexitticks int64 // cputicks when syscall has returned (for tracing) traceseq uint64 // trace event sequencer tracelastp puintptr // last P emitted an event for this goroutine lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state // gcAssistBytes is this G\u0026#39;s GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 } type m struct { g0 *g // goroutine with scheduling stack morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. procid uint64 // for debuggers, but offset not hard-coded gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask tls [6]uintptr // thread-local storage (for x86 extern register) mstartfn func() curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall id int64 mallocing int32 throwing int32 preemptoff string // if != \u0026#34;\u0026#34;, keep curg running on this m locks int32 dying int32 profilehz int32 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) fastrand [2]uint32 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call park note alllink *m // on allm schedlink muintptr lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 freelink *m // on sched.freem // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call // preemptGen counts the number of completed preemption // signals. This is used to detect when a preemption is // requested, but fails. Accessed atomically. preemptGen uint32 // Whether this is a pending preemption signal on this M. // Accessed atomically. signalPending uint32 dlogPerM mOS // Up to 10 locks held by this m, maintained by the lock ranking code. locksHeldLen int locksHeld [10]heldLockInfo } type p struct { id int32 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call syscalltick uint32 // incremented on every system call sysmontick sysmontick // last tick observed by sysmon m muintptr // back-link to associated m (nil if idle) mcache *mcache pcache pageCache raceprocctx uintptr deferpool [5][]*_defer // pool of available defer structs of different sizes (see panic.go) deferpoolbuf [5][32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 runqtail uint32 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready\u0026#39;d by // the current G and should be run next instead of what\u0026#39;s in // runq if there\u0026#39;s time remaining in the running G\u0026#39;s time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready\u0026#39;d // goroutines to the end of the run queue. runnext guintptr // Available G\u0026#39;s (status == Gdead) gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog // Cache of mspan objects from the heap. mspancache struct { // We need an explicit length here because this field is used // in allocation codepaths where write barriers are not allowed, // and eliminating the write barrier/keeping it eliminated from // slice updates is tricky, moreso than just managing the length // ourselves. len int buf [128]*mspan } tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex _ uint32 // Alignment for atomic fields below // The when field of the first entry on the timer heap. // This is updated using atomic functions. // This is 0 if the timer heap is empty. timer0When uint64 // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) gcBgMarkWorker guintptr // (atomic) gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // gcw is this P\u0026#39;s GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P\u0026#39;s GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point // Lock for timers. We normally access the timers while running // on this P, but the scheduler can also do it from a different P. timersLock mutex // Actions to take at some time. This is used to implement the // standard library\u0026#39;s time package. // Must hold timersLock to access. timers []*timer // Number of timers in P\u0026#39;s heap. // Modified using atomic instructions. numTimers uint32 // Number of timerModifiedEarlier timers on P\u0026#39;s heap. // This should only be modified while holding timersLock, // or while the timer status is in a transient state // such as timerModifying. adjustTimers uint32 // Number of timerDeleted timers in P\u0026#39;s heap. // Modified using atomic instructions. deletedTimers uint32 // Race context used while executing timer functions. timerRaceCtx uintptr // preempt is set to indicate that this P should be enter the // scheduler ASAP (regardless of what G is running on it). preempt bool pad cpu.CacheLinePad } GMP模型的一些概念 上面M中有两个g需要关注下，curg和g0。 curg就是M当前绑定的G。 g0是带有调度栈的goroutine，普通的G的栈是分配在堆上的可增长的栈，而g0的栈是M对应的线程的栈。所有调度相关的代码，会先切换到该goroutine的栈中执行。即，线程的栈也是用的g实现，而不是使用的OS。\n反正上述定义我是没有逐个字段的去理解，还是靠嘴说吧：\nG(Goroutine): goroutine，go func(){...}创建的 G会保存他关联的M G会保存全局队列中下一个G(按链表理解) G默认栈2KB G保存上下文，现场保护\u0026amp;现场恢复的寄存器 M(Machine): 抽象化代表内核线程 M保存了自身的栈信息，当前M上执行的G信息，以及绑定的P信息 M有线程栈，若没有为M的线程栈提供内存，则操作系统会为M提供内存 当指定线程栈，则M.stack-\u0026gt;G.stack，M的PC寄存器指向G提供的函数，然后开始执行 P(Processor): 处理器，一般P的数量默认为机器逻辑核数(go早期版本默认值1)，可以通过GOMAXPROCS修改，P的数量其实就是并发量 P负责调度goroutines，per-P维护一个本地goroutine队列，M从P获取goroutine并执行 per-P维护一个本地mcache TODO：这个点怎么理解？ 综上呢，P是M执行所需要的上下文环境，是处理用户级代码逻辑的处理器，也可以看作是一个局部调度器，使go代码跑在线程上 再说几个相关概念：\nP列表：就是\bGOMAXPROCS这么多个P的列表 M列表：就是操作系统分配到当前go进程的内核线程数，可以通过runtime/debug包SetMaxThreads设置(一般比P多，但别超过10000个，如下) file: ***/src/runtime/proc.go ----------------------------- func schedinit() { ... sched.maxmcount = 10000 ... } 空闲P链表：当P的本地运行队列中的所有G都运行完毕, 又不能从其他地方拿到G时,拥有P的M会释放P并进入休眠状态, 释放的P会变为空闲状态并加到空闲P链表中, 空闲P链表保存在全局变量sched；下次待运行的G入队时如果发现有空闲的P, 但是又没有自旋中的M时会唤醒或者新建一个M, M会拥有这个P, P会重新变为运行中的状态 关于创建M，可以看下面的概念“保证有足够的M运行G” 空闲M链表：当M发现无待运行的G时会进入休眠, 并添加到空闲M链表中, 空闲M链表保存在全局变量sched；进入休眠的M会等待一个信号量(m.park), 唤醒休眠的M会使用这个信号量 P本地队列：P维护runq_，存放等待执行的goroutines，P本地队列是lock-free的，无竞争问题 M执行从P上获取的G时，如果创建了新的G，优先放在P的本地队列，如果P的本地队列满了，才放在全局队列 TODO：关于“如果P的本地队列满了，才放在全局队列”这句话，描述并不精确。真正的动作应该(个人臆测，需要看源码)是P将本地队列一半移动到全局队列(这个移动本地一半的动作不是臆测的)，而且应该是\u0026quot;FIFO\u0026quot;，将较早创建的一些G移动走，这个新建的G应该是放在了本地。首先来看本地队列和全局队列的关系，全局队列应该是一个大的缓冲池，均衡各个P的负载，同时，看起来还有一个作用，就是提高P缓存的命中率，全局队列应该是存储一些“冷G”，而各个P的本地应该是存储一些“热G”，所以本着这个原则，新建的应该尽量留在本地 本地队列容量: 256个 全局队列：全局的等待执行的goroutines队列 TODO：全局队列容量大小？ TODO：应该还有另一个全局的G队列，存放channel blocked goroutines，且也具备全局锁，下图有体现 M获取G： 首先从M关联的P的本地队列获取 若P本地队列空，则从全局队列获取 若全局队列也空，则从其他P的本地队列获取一部分任务放到关联P的本地队列(GMP的一个关键概念: work stealing，通常是偷来一半) 抢占式调度：当有很多goroutine需要执行的时候，P还未创建，在runtime.main中会创建一个额外m运行sysmon函数实现抢占。sysmon会进入一个无限循环, 第一轮休眠20us, 之后每次休眠时间倍增, 最终每一轮都会休眠10ms。 sysmon中有netpool(获取fd事件), retake(抢占), forcegc(按时间强制执行gc), scavenge heap(释放自由列表中多余的项减少内存占用)等处理 保证有足够的M运行G： 入队待运行的G后, 如果当前无自旋的M但是有空闲的P, 就唤醒或者新建一个M 当M离开自旋状态并准备运行出队的G时, 如果当前无自旋的M但是有空闲的P, 就唤醒或者新建一个M 当M离开自旋状态并准备休眠时, 会在离开自旋状态后再次检查所有运行队列, 如果有待运行的G则重新进入自旋状态 因为\u0026quot;入队待运行的G\u0026quot;和\u0026quot;M离开自旋状态\u0026quot;会同时进行, go会使用这样的检查顺序:入队待运行的G =\u0026gt; 内存屏障 =\u0026gt; 检查当前自旋的M数量 =\u0026gt; 唤醒或者新建一个M减少当前自旋的M数量 =\u0026gt; 内存屏障 =\u0026gt; 检查所有运行队列是否有待运行的G =\u0026gt; 休眠，这样可以保证不会出现待运行的G入队了, 也有空闲的资源P, 但无M去执行的情况 状态汇总 G _Gidle：刚刚被分配并且还没有被初始化，值为0，为创建goroutine后的默认值 _Grunnable： 没有执行代码，没有栈的所有权，存储在运行队列中，可能在某个P的本地队列或全局队列中 _Grunning： 正在执行代码的goroutine，拥有栈的所有权 _Gsyscall：正在执行系统调用，拥有栈的所有权，与P脱离，但是与某个M绑定，会在调用结束后被分配到运行队列 _Gwaiting：被阻塞的goroutine，阻塞在某个channel的发送或者接收队列 _Gdead： 当前goroutine未被使用，没有执行代码，可能有分配的栈，分布在空闲列表gFree，可能是一个刚刚初始化的goroutine，也可能是执行了goexit退出的goroutine _Gcopystac：栈正在被拷贝，没有执行代码，不在运行队列上，执行权在 _Gscan ： GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在 P _Pidle ：处理器没有运行用户代码或者调度器，被空闲队列或者改变其状态的结构持有，运行队列为空 _Prunning ：被线程 M 持有，并且正在执行用户代码或者调度器 _Psyscall：没有执行用户代码，当前线程陷入系统调用 _Pgcstop ：被线程 M 持有，当前处理器由于垃圾回收被停止 _Pdead ：当前处理器已经不被使用 M 自旋线程：处于运行状态但是没有可执行goroutine的线程，数量最多为GOMAXPROC，若是数量大于GOMAXPROC就会进入休眠 通俗点说，空闲的M最多跟P的数量一样多，这样任何P已绑定的M陷入syscall都能迅速获得新的空闲M，减少M重新分配带来的开销，但空闲M又不能过多，否则导致内核线程浪费 非自旋线程：处于运行状态有可执行goroutine的线程 休眠 TODO：休眠我理解应该是不自旋但是还没被回收的这个状态？ 关于P和M的创建时间 P一般在程序一开始，runtime确认了GOMAXPROCS后，就创建了相应的P。\n但是对于M，是按需创建的，比如P绑定的M阻塞了，且此时没有休眠的M或自旋的M，就会向内核申请新的M，M最多10000个，但是其实内核一般也不允许创建这么多线程，还是会收到内核的限制。\n有一个特殊的M在P创建之前就创建了，那就是运行sysmon的M。\n调度图解 下图来自Gao Chao的PPT go-runtime-scheduler ：\n我们来画一张通俗易懂的图： 如上图，GOMAXPROCS=3，有三个P，每个P分别绑定了一个M；P1的本地队列满，P2的本地队列空，P3本地队列不满不空；M队列目前有5个M，除了与P绑定的执行go代码的M，M4陷入syscall，M5空闲，M4完成任务后将自旋（自旋M不超过GOMAXPROCS），若此时M1、M2、M3中的某一个阻塞，则M4与P绑定开始执行用户逻辑；若无空闲or睡眠M，M1、M2、M3中的某一个阻塞，则将创建新的M6绑定对应P执行用户逻辑。\n关于G、M的状态流转：\n图中（1）：此时P3本地队列不满不空，新创建的goroutine优先加入本地队列 图中（2）：此时P1本地队列满，新创建的goroutine将加入到全局队列 PS：关于这个动作，上面“P本地队列”概念中有提出疑问 图中（3）：P2本地队列空，无G可执行，将从全局队列获取G TODO：会一次获取多少过来呢？本地容量的一半吗？ 图中（4）：该图未体现，假设全局队列也空，则将执行work stealing，P2从其他P的本地队列“偷”一部分G过来 TODO：一般偷一半，怎么选择跟哪个P偷呢，负载最高的一个吗？ 图中（5）：若P3+M3执行G31时，G31发生channel阻塞，则G31将脱离P3+M3，P3将调度新的G到M3执行 图中（6）：若P1+M1执行G11时，发生syscall，则M1和G11该将脱离P1，执行syscall P1此时寻找到空闲的M5并绑定，继续执行P1的本地队列；若无空闲M，需要创建or唤醒 M1+G11执行完syscall后，若P1仍未找到M(仍然为_Psyscall状态)，则M1继续绑定P1，否则M1自旋or休眠or被回收 执行过程 go func(){}创建G，优先存P本地队列，否则存全局队列(再墨迹一次这个疑问上面提过) P唤醒一个M，M从P的runq_弹出一个G，如果P本地队列空，从全局队列获取(此时应该会从全局队列加载一些G到P的本地队列)，如果全局队列也空，就去其他P偷取G放到自己的P的本地队列 M开始执行 若发生系统调用导致M阻塞，当前P本地队列还有其他G，则runtime会将M\u0026amp;P分离，然后再获取一个M(空闲/唤醒/新建)与P绑定；阻塞调用完成后，M会去找刚才的P，如果刚才的P没有绑定其他M，则与之绑定，否则 自旋/睡眠/被回收 若由于channel阻塞当前G，该G会脱离当前的M和P，P会调度其他的G分配给M执行 TODO：阻塞完成后，G直接进全局队列还是优先刚才的P本地队列？ 销毁G，返回执行结果，M寻找新的G执行 M的执行过程简单概括就是：调用G对象-\u0026gt;执行-\u0026gt;清理线程→继续找新的G执行。 M执行过程中，随时会发生上下文切换。当发生上下文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go调度器M的栈保存在G对象上，只需要将M所需要的寄存器(SP、PC等)保存到G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时G任务还没有执行完，M可以将任务重新丢到P的任务队列，等待下一次被调度执行。当再次被调度执行时，M通过访问G的vdsoSP、vdsoPC寄存器进行现场恢复(从上次中断位置继续执行)。\n调度场景 Channel阻塞：当goroutine读写channel发生阻塞时候，会调用gopark函数，该G会脱离当前的M与P，调度器会执行schedule函数调度新的G到当前M 系统调用：当某个G、M由于系统调用陷入内核态时，该P就会脱离当前的M，此时P会更新自己的状态为Psyscall，M与G互相绑定，进行系统调用。结束以后若该P状态还是Psyscall，则直接关联该M和G，否则使用闲置的处理器处理该G TODO：若无闲置的处理器，该G、M怎么处理？G优先回刚才的P，其次全局，M 自旋/休眠/被回收 ？ 系统监控：当某个G在P上运行的时间超过10ms，或者P处于Psyscall状态过长等情况就会调用retake函数，触发新的调度 主动让出：G运行时间过长，会主动让出当前的P，更新状态为Grunnable，该P会调度队列中的其他G运行 TODO：若本地队列空呢？ GM -\u0026gt; GMP GM演化为GMP一定是在进步的。 之前我们说过，GM两个比较显著的问题\n一个是sched.lock全局队列锁 GMP per-P维护本地队列，减少了全局G队列的锁竞争 一个是per-M本地缓存 GMP是per-P的mcache，避免了大量陷入系统调用M对内存的浪费 对于G空转的问题，GMP的per-P本地队列+workStealing模式，减少了G的空转，且新建G优先入P本地队列，提高缓存命中率。\n此外，GMP还有\u0026quot;hand off\u0026quot;机制，当M1+P1执行G1时进入syscall，则P1与M1解绑(M1执行G1 syscall)，与空闲的M2(空闲的/新申请)绑定并继续工作，M1执行完G1后，进入空闲，后续将被其他P使用或被回收。\n为什么使用GMP取代GM 为什么GM演变到了GMP呢？\n首先M是内核级线程，用户态无法进行调度和修改，借鉴GMP的思路，只能是M本地绑定一个队列。 那么为什么需要一个P层呢？\n如果没有P层，每个M维护本地队列：\n由于M不停创建，本地队列数量同时增多，此时的\u0026quot;work stealing\u0026quot;将极其复杂，甚至可能导致调度性能严重下降 per-M内存问题并没有得到解决 每个M本地队列中其他G会由于M的syscall而被阻塞，若引入\u0026quot;hand off\u0026quot;机制，那么M数量将增长更快 因此，引入P层，由P层维护本地队列，P数量代表并发度，per-P mcache缓存模式，这就完美的解决了上面说的问题(正所谓\u0026quot;遇事不决加一层\u0026quot;)。\nG、M、P数量 G的数量理论上就是受内存的限制，一个G初始创建需2k的栈空间，后续根据需要会弹性连续增长，假设单机内存4G，那么理论上G数量上限约2,000,000，当然不可能内存全部给G，数量大概是这么个概念。\nM的数量按照go默认值最高10000个，也可通过debug.SetMaxThreads来设置，但是其实还受到操作系统的限制，因为每一个M就对应操作系统的一个内核级线程。一个正常的go进程M数量一般比P多(hand off机制，空转M数量最大GOMAXPROCS，sysmon回收时间间隔 等机制导致)。\nP的数量是通过GOMAXPROCS设置，一般使用单机逻辑核数，这是为了能够充分利用单机的多核并发，P的量也不是越多越好，P多了调度的开销也会增加，P的最佳数量一般通过大量的benchmark才能确定\nP数量不多，所以per-P缓存需要的空间不会成为P数量的瓶颈 参考材料 https://mp.weixin.qq.com/s/an7dml9NLOhqOZjEGLdEEw https://cloud.tencent.com/developer/article/1683211 https://blog.csdn.net/diaosssss/article/details/92830782 数据局部性: https://www.zhihu.com/question/25142664 ","permalink":"https://duck-dd.github.io/posts/go-schedule/","summary":"\u003ch2 id=\"写在前面\"\u003e写在前面\u003c/h2\u003e\n\u003cp\u003eruntime包实现了所有\u003ccode\u003egoroutine scheduler\u003c/code\u003e、\u003ccode\u003ememory allocator\u003c/code\u003e、\u003ccode\u003egarbage collector\u003c/code\u003e细节，理论上可以从runtime包获取一切信息，没有直接怼源码，而是站在巨人的肩膀上（直接吃大佬们吃剩下的）。\u003c/p\u003e\n\u003cp\u003e搜集到的材料，大家都是基于不同的go版本做的分析，而go版本迭代调度算法也在持续更新，所以整理的可能有些乱。但是可以保证的是，所有材料都是GM-\u0026gt;GMP演化后的材料。\u003c/p\u003e\n\u003ch2 id=\"gm\"\u003eGM\u003c/h2\u003e\n\u003cp\u003ego1.1版本以前，调度使用GM模型，如下图所示。简单的理解GM模型，就是有一个始终执行的调度函数schedule不停的执行调度计算，当某个M的G执行完成了，调度器就把这个M放回M队列，可绑定执行其他G（如果某个M+G发生了syscall，那么本来并发度是通过M数量控制的，此时并发度就降低了？）；如果G执行过程中创建新的G，会将新的G放入到G全局可执行队列中。G全局可执行队列的操作有一把全局锁，这导致了各个M对G全局队列的操作存在严重的竞争。\u003c/p\u003e\n\u003cp\u003e下面这段完全是我的臆测，请别太相信：\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e简单概括呢，所以可以认为有：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eG全局可执行队列(以下也可能简称G可执行队列)\u003c/li\u003e\n\u003cli\u003eM可用队列\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e调度器要做的事就是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e从G的可执行队列取G并从M的可用队列取M，将二者绑定开始执行G\u003c/li\u003e\n\u003cli\u003e对于已经执行完的G，销毁G并立即将M释放回M可用队列供后续使用\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cimg alt=\"GM-model\" loading=\"lazy\" src=\"/images/go-schedule/gm.png\"\u003e\u003c/p\u003e\n\u003cp\u003e那么GM模型有哪些问题呢？\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e(\u003cstrong\u003e重点问题\u003c/strong\u003e)单一的全局mutex(sched.lock)和集中状态管理\n\u003cul\u003e\n\u003cli\u003emutex需要保护所有与全局goroutine队列相关操作(创建、完成、重排等等)，竞争严重\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e(\u003cstrong\u003e重点问题\u003c/strong\u003e)per-M内存(M.mcache)问题\n\u003cul\u003e\n\u003cli\u003e每个M都需要一个mcache，会导致资源消耗过大(每个mcache可以吸纳到2MB的内存缓存和其他缓存)\n\u003cul\u003e\n\u003cli\u003e举个栗子，一个陷入syscall的M并不需要使用cache，但是在全部的M中，陷入系统调用的M与执行goroutine的M的比例可能是\u003ccode\u003eN:1(N\u0026gt;\u0026gt;1)\u003c/code\u003e，这就导致了\u003ccode\u003eN/(N+1)\u003c/code\u003e比例的mcache在闲置\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数据局部性差\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003e举个栗子，M1执行G1，此时创建了G2，G2通常是立刻进入了G全局可执行队列，而此时M1还在执行G1，所以G2通常被其他M执行，但是G1和G2通常强相关，所以G2最好也在M1上执行，因为G2对M1的缓存命中率更高\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003egoroutine传递问题\n\u003cul\u003e\n\u003cli\u003egoroutine(G)交接(G.nextg)，M之间会经常交接可运行的G\u003c/li\u003e\n\u003cli\u003e再通俗点说，就是G空转，本来能够好好在一个M上执行完，但是由于全局队列的存在，G一旦回全局队列了，下次就不知道被哪个M取走了，所以叫“空转”；M加载G的上下文是有开销的，所以空转会导致性能下降\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e频繁的线程阻塞/解阻塞\n\u003cul\u003e\n\u003cli\u003esyscalls情况下，线程经常被阻塞和解阻塞，增加了很多额外开销\u003c/li\u003e\n\u003cli\u003e通俗点说，M+G syscall，M阻塞，syscall完成后，M解阻塞继续执行G（如果是通过M数量控制并发度，这是不是就导致了并发度降低？）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"gmp\"\u003eGMP\u003c/h2\u003e\n\u003cp\u003e基于以上说的GM的问题，go1.1以后开始使用GMP调度模型。\nG、M、P的定义如下(***/src/runtime/runtime2.go)。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003etype g struct {\n\t// Stack parameters.\n\t// stack describes the actual stack memory: [stack.lo, stack.hi).\n\t// stackguard0 is the stack pointer compared in the Go stack growth prologue.\n\t// It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption.\n\t// stackguard1 is the stack pointer compared in the C stack growth prologue.\n\t// It is stack.lo+StackGuard on g0 and gsignal stacks.\n\t// It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash).\n\tstack       stack   // offset known to runtime/cgo\n\tstackguard0 uintptr // offset known to liblink\n\tstackguard1 uintptr // offset known to liblink\n\n\t_panic       *_panic // innermost panic - offset known to liblink\n\t_defer       *_defer // innermost defer\n\tm            *m      // current m; offset known to arm liblink\n\tsched        gobuf\n\tsyscallsp    uintptr        // if status==Gsyscall, syscallsp = sched.sp to use during gc\n\tsyscallpc    uintptr        // if status==Gsyscall, syscallpc = sched.pc to use during gc\n\tstktopsp     uintptr        // expected sp at top of stack, to check in traceback\n\tparam        unsafe.Pointer // passed parameter on wakeup\n\tatomicstatus uint32\n\tstackLock    uint32 // sigprof/scang lock; TODO: fold in to atomicstatus\n\tgoid         int64\n\tschedlink    guintptr\n\twaitsince    int64      // approx time when the g become blocked\n\twaitreason   waitReason // if status==Gwaiting\n\n\tpreempt       bool // preemption signal, duplicates stackguard0 = stackpreempt\n\tpreemptStop   bool // transition to _Gpreempted on preemption; otherwise, just deschedule\n\tpreemptShrink bool // shrink stack at synchronous safe point\n\n\t// asyncSafePoint is set if g is stopped at an asynchronous\n\t// safe point. This means there are frames on the stack\n\t// without precise pointer information.\n\tasyncSafePoint bool\n\n\tpaniconfault bool // panic (instead of crash) on unexpected fault address\n\tgcscandone   bool // g has scanned stack; protected by _Gscan bit in status\n\tthrowsplit   bool // must not split stack\n\t// activeStackChans indicates that there are unlocked channels\n\t// pointing into this goroutine\u0026#39;s stack. If true, stack\n\t// copying needs to acquire channel locks to protect these\n\t// areas of the stack.\n\tactiveStackChans bool\n\t// parkingOnChan indicates that the goroutine is about to\n\t// park on a chansend or chanrecv. Used to signal an unsafe point\n\t// for stack shrinking. It\u0026#39;s a boolean value, but is updated atomically.\n\tparkingOnChan uint8\n\n\traceignore     int8     // ignore race detection events\n\tsysblocktraced bool     // StartTrace has emitted EvGoInSyscall about this goroutine\n\tsysexitticks   int64    // cputicks when syscall has returned (for tracing)\n\ttraceseq       uint64   // trace event sequencer\n\ttracelastp     puintptr // last P emitted an event for this goroutine\n\tlockedm        muintptr\n\tsig            uint32\n\twritebuf       []byte\n\tsigcode0       uintptr\n\tsigcode1       uintptr\n\tsigpc          uintptr\n\tgopc           uintptr         // pc of go statement that created this goroutine\n\tancestors      *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors)\n\tstartpc        uintptr         // pc of goroutine function\n\tracectx        uintptr\n\twaiting        *sudog         // sudog structures this g is waiting on (that have a valid elem ptr); in lock order\n\tcgoCtxt        []uintptr      // cgo traceback context\n\tlabels         unsafe.Pointer // profiler labels\n\ttimer          *timer         // cached timer for time.Sleep\n\tselectDone     uint32         // are we participating in a select and did someone win the race?\n\n\t// Per-G GC state\n\n\t// gcAssistBytes is this G\u0026#39;s GC assist credit in terms of\n\t// bytes allocated. If this is positive, then the G has credit\n\t// to allocate gcAssistBytes bytes without assisting. If this\n\t// is negative, then the G must correct this by performing\n\t// scan work. We track this in bytes to make it fast to update\n\t// and check for debt in the malloc hot path. The assist ratio\n\t// determines how this corresponds to scan work debt.\n\tgcAssistBytes int64\n}\n\ntype m struct {\n\tg0      *g     // goroutine with scheduling stack\n\tmorebuf gobuf  // gobuf arg to morestack\n\tdivmod  uint32 // div/mod denominator for arm - known to liblink\n\n\t// Fields not known to debuggers.\n\tprocid        uint64       // for debuggers, but offset not hard-coded\n\tgsignal       *g           // signal-handling g\n\tgoSigStack    gsignalStack // Go-allocated signal handling stack\n\tsigmask       sigset       // storage for saved signal mask\n\ttls           [6]uintptr   // thread-local storage (for x86 extern register)\n\tmstartfn      func()\n\tcurg          *g       // current running goroutine\n\tcaughtsig     guintptr // goroutine running during fatal signal\n\tp             puintptr // attached p for executing go code (nil if not executing go code)\n\tnextp         puintptr\n\toldp          puintptr // the p that was attached before executing a syscall\n\tid            int64\n\tmallocing     int32\n\tthrowing      int32\n\tpreemptoff    string // if != \u0026#34;\u0026#34;, keep curg running on this m\n\tlocks         int32\n\tdying         int32\n\tprofilehz     int32\n\tspinning      bool // m is out of work and is actively looking for work\n\tblocked       bool // m is blocked on a note\n\tnewSigstack   bool // minit on C thread called sigaltstack\n\tprintlock     int8\n\tincgo         bool   // m is executing a cgo call\n\tfreeWait      uint32 // if == 0, safe to free g0 and delete m (atomic)\n\tfastrand      [2]uint32\n\tneedextram    bool\n\ttraceback     uint8\n\tncgocall      uint64      // number of cgo calls in total\n\tncgo          int32       // number of cgo calls currently in progress\n\tcgoCallersUse uint32      // if non-zero, cgoCallers in use temporarily\n\tcgoCallers    *cgoCallers // cgo traceback if crashing in cgo call\n\tpark          note\n\talllink       *m // on allm\n\tschedlink     muintptr\n\tlockedg       guintptr\n\tcreatestack   [32]uintptr // stack that created this thread.\n\tlockedExt     uint32      // tracking for external LockOSThread\n\tlockedInt     uint32      // tracking for internal lockOSThread\n\tnextwaitm     muintptr    // next m waiting for lock\n\twaitunlockf   func(*g, unsafe.Pointer) bool\n\twaitlock      unsafe.Pointer\n\twaittraceev   byte\n\twaittraceskip int\n\tstartingtrace bool\n\tsyscalltick   uint32\n\tfreelink      *m // on sched.freem\n\n\t// these are here because they are too large to be on the stack\n\t// of low-level NOSPLIT functions.\n\tlibcall   libcall\n\tlibcallpc uintptr // for cpu profiler\n\tlibcallsp uintptr\n\tlibcallg  guintptr\n\tsyscall   libcall // stores syscall parameters on windows\n\n\tvdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call)\n\tvdsoPC uintptr // PC for traceback while in VDSO call\n\n\t// preemptGen counts the number of completed preemption\n\t// signals. This is used to detect when a preemption is\n\t// requested, but fails. Accessed atomically.\n\tpreemptGen uint32\n\n\t// Whether this is a pending preemption signal on this M.\n\t// Accessed atomically.\n\tsignalPending uint32\n\n\tdlogPerM\n\n\tmOS\n\n\t// Up to 10 locks held by this m, maintained by the lock ranking code.\n\tlocksHeldLen int\n\tlocksHeld    [10]heldLockInfo\n}\n\ntype p struct {\n\tid          int32\n\tstatus      uint32 // one of pidle/prunning/...\n\tlink        puintptr\n\tschedtick   uint32     // incremented on every scheduler call\n\tsyscalltick uint32     // incremented on every system call\n\tsysmontick  sysmontick // last tick observed by sysmon\n\tm           muintptr   // back-link to associated m (nil if idle)\n\tmcache      *mcache\n\tpcache      pageCache\n\traceprocctx uintptr\n\n\tdeferpool    [5][]*_defer // pool of available defer structs of different sizes (see panic.go)\n\tdeferpoolbuf [5][32]*_defer\n\n\t// Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen.\n\tgoidcache    uint64\n\tgoidcacheend uint64\n\n\t// Queue of runnable goroutines. Accessed without lock.\n\trunqhead uint32\n\trunqtail uint32\n\trunq     [256]guintptr\n\t// runnext, if non-nil, is a runnable G that was ready\u0026#39;d by\n\t// the current G and should be run next instead of what\u0026#39;s in\n\t// runq if there\u0026#39;s time remaining in the running G\u0026#39;s time\n\t// slice. It will inherit the time left in the current time\n\t// slice. If a set of goroutines is locked in a\n\t// communicate-and-wait pattern, this schedules that set as a\n\t// unit and eliminates the (potentially large) scheduling\n\t// latency that otherwise arises from adding the ready\u0026#39;d\n\t// goroutines to the end of the run queue.\n\trunnext guintptr\n\n\t// Available G\u0026#39;s (status == Gdead)\n\tgFree struct {\n\t\tgList\n\t\tn int32\n\t}\n\n\tsudogcache []*sudog\n\tsudogbuf   [128]*sudog\n\n\t// Cache of mspan objects from the heap.\n\tmspancache struct {\n\t\t// We need an explicit length here because this field is used\n\t\t// in allocation codepaths where write barriers are not allowed,\n\t\t// and eliminating the write barrier/keeping it eliminated from\n\t\t// slice updates is tricky, moreso than just managing the length\n\t\t// ourselves.\n\t\tlen int\n\t\tbuf [128]*mspan\n\t}\n\n\ttracebuf traceBufPtr\n\n\t// traceSweep indicates the sweep events should be traced.\n\t// This is used to defer the sweep start event until a span\n\t// has actually been swept.\n\ttraceSweep bool\n\t// traceSwept and traceReclaimed track the number of bytes\n\t// swept and reclaimed by sweeping in the current sweep loop.\n\ttraceSwept, traceReclaimed uintptr\n\n\tpalloc persistentAlloc // per-P to avoid mutex\n\n\t_ uint32 // Alignment for atomic fields below\n\n\t// The when field of the first entry on the timer heap.\n\t// This is updated using atomic functions.\n\t// This is 0 if the timer heap is empty.\n\ttimer0When uint64\n\n\t// Per-P GC state\n\tgcAssistTime         int64    // Nanoseconds in assistAlloc\n\tgcFractionalMarkTime int64    // Nanoseconds in fractional mark worker (atomic)\n\tgcBgMarkWorker       guintptr // (atomic)\n\tgcMarkWorkerMode     gcMarkWorkerMode\n\n\t// gcMarkWorkerStartTime is the nanotime() at which this mark\n\t// worker started.\n\tgcMarkWorkerStartTime int64\n\n\t// gcw is this P\u0026#39;s GC work buffer cache. The work buffer is\n\t// filled by write barriers, drained by mutator assists, and\n\t// disposed on certain GC state transitions.\n\tgcw gcWork\n\n\t// wbBuf is this P\u0026#39;s GC write barrier buffer.\n\t//\n\t// TODO: Consider caching this in the running G.\n\twbBuf wbBuf\n\n\trunSafePointFn uint32 // if 1, run sched.safePointFn at next safe point\n\n\t// Lock for timers. We normally access the timers while running\n\t// on this P, but the scheduler can also do it from a different P.\n\ttimersLock mutex\n\n\t// Actions to take at some time. This is used to implement the\n\t// standard library\u0026#39;s time package.\n\t// Must hold timersLock to access.\n\ttimers []*timer\n\n\t// Number of timers in P\u0026#39;s heap.\n\t// Modified using atomic instructions.\n\tnumTimers uint32\n\n\t// Number of timerModifiedEarlier timers on P\u0026#39;s heap.\n\t// This should only be modified while holding timersLock,\n\t// or while the timer status is in a transient state\n\t// such as timerModifying.\n\tadjustTimers uint32\n\n\t// Number of timerDeleted timers in P\u0026#39;s heap.\n\t// Modified using atomic instructions.\n\tdeletedTimers uint32\n\n\t// Race context used while executing timer functions.\n\ttimerRaceCtx uintptr\n\n\t// preempt is set to indicate that this P should be enter the\n\t// scheduler ASAP (regardless of what G is running on it).\n\tpreempt bool\n\n\tpad cpu.CacheLinePad\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"gmp模型的一些概念\"\u003eGMP模型的一些概念\u003c/h3\u003e\n\u003cp\u003e上面M中有两个g需要关注下，curg和g0。\ncurg就是M当前绑定的G。\ng0是带有调度栈的goroutine，普通的G的栈是分配在堆上的可增长的栈，而g0的栈是M对应的线程的栈。所有调度相关的代码，会先切换到该goroutine的栈中执行。即，线程的栈也是用的g实现，而不是使用的OS。\u003c/p\u003e","title":"Golang schedule"},{"content":"DNS，挺好，啥是DNS？ 一些概念 FQDN: Fully Qualified Domain Name，全限定域名，同时带有主机名和域名的名称（通过符号“.”），例如一个FQDN是www.baidu.com，www是主机名，baidu.com是域名。再举例，我是海淀吴彦祖，你是**吴彦祖，但是我们还知道，有个人就叫吴彦祖，这么多吴彦祖我们都没有混淆，因为名字前面加上了地域，也就是域名。从逻辑上看FQDN，就是主机名的完整表达，类似绝对路径，通过一个FQDN我们可以在全网内锁定主机位置。 cache only DNS server : 有.的zone file的DNS服务器，本身没有任何解析数据，完全靠查询来获取数据源 forwarding DNS server : 连.的zone file都没有，完全靠向上层查询获取数据；当使用forwarding功能时，即使本身有.的zone file，也不会向.查询，该DNS server还是会将查询完全委托给上层。 CIDR:Classless Inter-Domain Routing, 无类域间路由，不按固定的字节来划分网络编号，可以使用IP地址中任何相邻位的数字作为网络编号，例如某机构需要2个B类网络大小的空间，那么可以使用前15位作为网络编号，例如127.127.0.0/15 A类,B类,C类网络：A类网络以IP地址的第一个字节(前8位)作为网络编号,剩下的24位为主机;B类网络前两个字节为网络编号;C类网络前三个字节为网络编号 DNS做什么 ipv4 32bit，ipv6 128bit，即使转成10/16进制也没人记得住，但是人类的头脑善于记录名字，所以可以搞一个名字跟IP对应，名字跟IP的对应关系解析，就是DNS提供的服务。\n主机名的解析有一个发展的过程。\n最初没有DNS人们如何记住各个服务名字跟IP的对应关系呢？就是写在/etc/hosts文件里，自己写麻烦，那就统一写到中心，使用的时候从中心拉取。\n这个中心就是internic，主机名IP对应关系修改时，注册到internic中；用户准备上网之前先去internic把最新的文件拉下来，放在自己的/etc/hosts。\n这种方式问题很多：\n例如internic拉取的文件会很大，每次打开电脑先拉个100G的文件然后再开始上网，就算你磁盘扛得住，你的网络不够好也很难受（因为你不能明确说明自己上网需要的主机名，只能拉全量，互联网业务增长该文件会越来越大） 例如这种方式是静态的，需要用户主动触发更新行为（你总不能让一个人开机默认就去下载100G的文件，他不可能给你授权的）；试想一下，一个网瘾少年下午6点睡眼惺忪的起床，打开电脑先从internic下载了半个小时文件，期间去洗漱吃了早饭，然后开开心心开始打游戏，突然，游戏掉线了，上贴吧一查，大家都说快去重新拉取internic的hosts文件呀，游戏域名被友商攻击换域名了，这还好，少年骂骂咧咧下载个文件就完事了，要是贴吧都上不去就更让人懵逼了 时代的进步总是聪明人推动的。Berkeley一个同学就觉得这种方式不太行，于是他就搞出一套BIND系统提供DNS服务。\nBIND，Berkeley Internet Name Domain BIND管理方式 BIND是一套阶层式的管理主机名与IP对应关系的系统。\n阶层式？可以简单理解为树状结构的不同层级，下面来简单分析下阶层式。\n以www.baidu.com为例，最上层根服务器，domain name是\u0026quot;.\u0026quot;，然后有三个hostname \u0026ldquo;net com cn\u0026rdquo;，再到第三层，hostname分别是pdd baidu tencent，此时domain name为.com. ，以此类推。。。需要注意的是，不是每一个\u0026quot;.\u0026ldquo;都拆分domain name\u0026amp;hostname，例如上图 video.www.baidu.com ，其中domain name为baidu.com.，hostname为video.www。按照上述方式分层，每一个服务节点（权威）只负责自己的一小撮域名，这就避免了大量数据集中的问题。\nDNS阶层系统的最上方是一个\u0026rdquo;.\u0026quot;，root，是根服务器，本质上讲，这里的\u0026quot;.\u0026ldquo;后面其实是空标签，这是为root保留的；根服务器下一层管理的是Top Level Domains(TLD)，例如com. net. org.等等。\n每个上一层的DNS服务器，所记录的信息，只有下一层的主机名；再下一层，授权给再再下层某个主机管理，这就是分层管理；DNS分层最多到127层(实际上不会用到这么多)，每一层最多63个字符(不包括\u0026rdquo;.\u0026quot;)；同一层内不允许同名，确保唯一性。\nBIND查询流程 当浏览器输入 https://www.baidu.com ，先查浏览器缓存，再查/etc/hosts文件，都找不到www.baidu.com的解析时，会根据/etc/resolv.conf文件内配置的DNS服务器地址，去进行DNS解析，询问www.baidu.com的A记录 client第一步找到的DNS服务器通常为运营商提供的local DNS服务器，local DNS作为名称服务器，接收client端的递归查询请求，若local DNS服务器自身没有www.baidu.com的解析结果，则向.DNS服务器发起解析请求，询问www.baidu.com是啥A记录呢？ 其实递归查询实际过程中，local DNS若未命中缓存，并不是直接查询根服务器，他会寻找已知最近的名称服务器(待实验确认) .并不知道www.baidu.com的IP，它会告诉你我只知道.com，IP给你，你去问它吧 然后local DNS获取到了.com的信息后，开始向.com询问www.baidu.com的解析结果 .com也不知道www.baidu.com的IP地址，它会说，我只认识baidu.com，你去问它吧 .com返回的一般是baidu.com的多个NS域名(及其IP,胶水记录)，如下例图，那么如何选择权威呢？BIND名称服务器使用RTT(roundtrip time)的度量方式来选择对同一区域中的名称服务器进行选择，即选择RTT最小的那个名称服务器(dig +trace抓包并没看到对RTT的探测，现象上看是从ns*.baidu.com里面随机选择的？) local DNS向baidu.com询问www.baidu.com的解析结果，baidu.com说，对了，这个归我管，我是权威，www.baidu.com的IP地址是****(这里其实应该是CNAME而不是A) local DNS得到权威服务器baidu.com的响应后，会缓存www.baidu.com的解析结果并响应用户的DNS解析请求 名称服务器(local DNS)收到递归查询请求并迭代出结果后，会对结果进行缓存，甚至会包括“否定缓存”，即权威返回的结果是域名或数据类型不存在，也会进行缓存，同样的，TTL也适用于否定缓存；大部分情况下，名称服务器处理递归请求，即使所查询的实际内容(域名)不在缓存中，但是其对应的权威服务器地址应该是已经在缓存中的 PS：上述的解析查询一般是通过UDP协议，DNS端口53，但是不排除客户端有时会通过TCP来进行DNS解析，通常UDP解析失败客户端可能采用TCP重试，或者当客户端能预期到解析结果较大(个人理解单次解析网络请求包较多)时可能主动使用TCP进行解析。\n关于NS记录，当上层记录的NS A记录与下层的不同时，以下层为准；例如baidu.com记录了NS记录test.baidu.com NS 1.1.1.1,当去1.1.1.1服务器时发现该服务器记录了test.baidu.com NS 2.2.2.2,那么将以2.2.2.2为准，即后续解析服务器缓存的是test.baidu.com NS 2.2.2.2。\nDNS针对一个需要解析的领域(domain)称之为一个zone（区域）；记录主机名-\u0026gt;IP称之为正解，记录IP-\u0026gt;主机名称之为反解；正解zone主要记录的内容一般包括：SOA(Start Of Authority),NS(NameServer，DNS服务器),A(Address，地址，IP)；反解zone主要记录的内容除了SOA NS外，还包括PTR（PoinTeR，记录的是反解到的主机名）。\u0026quot;.\u0026ldquo;这个根服务器是所有DNS服务器都必须认识的，.的zone的类型称之为hint类型。\n客户端主机内DNS相关的配置文件：\n/etc/hosts:hostname与IP的对应关系文档 /etc/resolv.conf:DNS服务器IP地址（通常是local DNS）；可以填写多个，一般使用第一个，当前面的服务器故障时，按顺序使用后面的服务器；使用DHCP时，系统会主动使用DHCP服务器返回的数据修正系统/etc/resolv.conf文件，可在 /etc/sysconfig/network-scripts/ifcfg-eth0内增加一行PEERDNS=no来关闭 /etc/nsswitch.conf:该文档决定先试用/etc/hosts还是/etc/resolv.conf DNS查询命令：\nhost host [FQDN] [server] host -a [FQDN] [server]: host -a www.baidu.com 114.114.114.114 host -l ***:需要授权，读取DNS服务器设置 nslookup nslookup [FQDN] [server] dig dig [options] [FQDN] [@server]: dig AAAA www.baidu.com @114.114.114.114 QUESTION: 要查询的内容 ANSWER:查询结果 AUTHORITY:由哪台DNS服务器提供的答案（权威服务器） dig -x [IP]: 查反解 +trace: dig *** +trace，可以实际抓包看下，+trace的过程其实是从root开始迭代 whois：查询zone的管理者 BIND部署 BIND部署一般采用主从结构，master接受变更，slave同步master数据对外提供解析服务;master和slave都是权威;master又叫primary master，slave又叫secondary master, slave需要同步master的zone数据，该过程称为zone transfer；slave通常会配置为备份从master获取到的zone datafile数据，当slave冷启动时，会先加载本地zone datafile数据，并检查更新。\nBIND核心数据有两部分：\nBIND本身的配置文件： /etc/named.conf ，规范主机的设定，zone file位置，权限设定 zone file: /var/named/ ,记录主机名于IP等关系 其他文件： /etc/sysconfig/named ：是否启动chroot及额外的参数，当BIND被change root时，所有的文件都是在新root下，例如ROOTDIR=/var/named/chroot , 那么named.conf文件的位置实际为 /var/named/chroot/etc/named.conf /var/run/named ：named进程pid文件 DNS通常起53端口的TCP\u0026amp;UDP监听，同时还会监听本机953端口的TCP，作为rndc(remote name daemon control，远程名称解析服务控制)服务。\n正解RR 常见的正解文件RR(resource record)相关信息:\ndomain ttl class RR type RR data serial 主机名 60 IN A IPv4 addr * 主机名 60 IN AAAA IPv6 addr * 主机名 60 IN NS 管理该域的主机名 * 7个参数 60 IN SOA 管理该域的7个参数 * 主机名 60 IN MX 邮件服务器 * 主机别名 60 IN CNAME 该主机别名到其他主机 * PS:class取值（refer to RFC1035 3.2.4）：\nIN: the Internet CS: the CSNET class (Obsolete - used only for examples in some obsolete RFCs) CH: the CHAOS class HS: Hesiod [Dyer 87] PS，SOA的七个参数：\nMNAME: master服务器主机名 UPDATE requests should be forwarded toward the primary master NOTIFY requests propagate outward from the primary master RNAME: 管理员email, email地址中@用.进行了提换, 例如test@gmail.com，实际记录值为test.gmail.com SERIAL: YYYYMMDDNU格式，2021041500，代表2021年4月15日00次更新，slave会对比该serial以确认master数据是否比自身数据更新；该序列号\u0026lt;=232,即4294967296 REFRESH: 更新频率，slave向master请求更新的频率（仅适用于slave主动拉？不适用master notify?）；一般refresh\u0026gt;retry*2 RETRY: slave与master通信的失败重试时间间隔 EXPIRE: 失效时间，slave一直retry直到expire后将不再继续重试获取相应的zone file;一般 refresh+retry \u0026lt; expire, expire \u0026gt;= retry*10, expire \u0026gt;= 7days TTL, a.k.a. MINIMUM: Time to live for purposes of negative caching. Recommendation for small and stable zones: 3600 seconds (1 hour). Originally this field had the meaning of a minimum TTL value for resource records in this zone; it was changed to its current meaning by RFC 2308. PLS refer to RFC2308 (BIND8.2以前的版本，用SOA最后的TTL表示区域默认TTL；BIND8.2以后，RFC2308发布，该字段的含义变成了“否定缓存TTL, negative caching TTL”,指的是远程名称服务器将区域的否定响应缓存的时间，否定响应指所查询的特定域名或域名是数据类型不存在时的应答) 那么默认TTL如何设置呢？区域数据文件中最上面的$TTL就是在设置默认TTL（仅适用BIND8.2以后的版本） PS：\n无论是name部分还是data部分，如果未使用FQDN(.结尾)，那么就会认为与本文件同域 name: zone file内第一个字段，名称的描述 data: zone file内第四个字段，值的描述 @表示与当前文件描述域同名 若某个资源记录的名称使用了空格(space)或制表符(tab),那么他就会沿用上一条资源记录的名称 e.g. zone[test.com] file如下:\n; Default TTL $TTL 3h ; ; Origin added to names not ending in a dot: test.com ; @ IN SOA main main ( 1 ; serial 3h ; refresh after 3 hours 1h ; retry after 1 hour 1w ; expire after 1 week 1h) ; negative caching TTL of 1 hour ; ; Name servers(The name \u0026#39;@\u0026#39; is implied) ; IN NS test1 IN NS test2.testt.com. ; ; Address for the canonical names ; localhost IN A 127.0.0.1 test IN A 10.10.1.1 IN A 10.10.1.2 ; ; Alias ; heihei IN CNAME haha MX的dig返回结果如下(以baidu.com为例)，可见返回了多条数据，前面带数字，一般选择数值较小的那一台\n***$ dig mx baidu.com ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.6 \u0026lt;\u0026lt;\u0026gt;\u0026gt; mx baidu.com ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 34808 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 5, ADDITIONAL: 10 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;baidu.com.\tIN\tMX ;; ANSWER SECTION: baidu.com.\t7200\tIN\tMX\t15 mx.n.shifen.com. baidu.com.\t7200\tIN\tMX\t20 mx1.baidu.com. baidu.com.\t7200\tIN\tMX\t20 jpmx.baidu.com. baidu.com.\t7200\tIN\tMX\t20 mx50.baidu.com. baidu.com.\t7200\tIN\tMX\t10 mx.maillb.baidu.com. *** ----------------------------------------------------------- MX算法： 上述MX的dig结果中的数字代表该记录的优先级，该优先级是个无符号的16位数字（0-65535），数字越小优先级越高。MX转发为避免环路，转发处理时只会向更高的优先级服务器进行转发，转到最高还不行。。。会咋办忘了，具体可参考RFC2308：https://datatracker.ietf.org/doc/html/rfc2308 zone file内的特殊符号：\n@ : 代表该zone的意思，例如zone为baidu.com. ， 则 @ 代表baidu.com. . : 加上了 . 表示这是个完整的主机名 (FQDN)，亦即是 \u0026ldquo;hostname + domain name\u0026rdquo; , 如果没有加上 . 的话，表示该名称仅为 \u0026ldquo;hostname\u0026rdquo; ,若zone file内主机名不以.结尾，则代表主机名.@ , 例如 baidu.com. zone 内 www.baidu.com. www.baidu.com 两条记录分别对应 www.baidu.com. www.baidu.com.baidu.com. 反解RR 常见的反解文件RR(resource record)相关信息，无A/AAAA，取而代之是PTR类型，其他同正解:\ndomain ttl class RR type RR data serial *** 60 IN PTR FQDN * DNS分层搜索都是从大范围找到小范围最终定位，正解是根据域名寻找IP，根据域名从后向前搜索；那么反解是根据IP寻找域名，而IP越靠前代表网段范围越大，所以反解搜索时需要根据IP从前向后搜索，例如寻找11.12.13.14的主机名，一般是将IP倒序，再拼接.in-addr.arpa.(in-addr,inverse address; arpa is a TLD, refer to wikipedia for arpa)的后缀，如下：\nipv4: ***$ dig -x 11.12.13.14 ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.6 \u0026lt;\u0026lt;\u0026gt;\u0026gt; -x 11.12.13.14 ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NXDOMAIN, id: 61795 ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;14.13.12.11.in-addr.arpa.\tIN PTR *** ipv6: ***$ dig -x 2408:871a:2100:2:0:ff:b09f:237 ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.6 \u0026lt;\u0026lt;\u0026gt;\u0026gt; -x 2408:871a:2100:2:0:ff:b09f:237 ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NXDOMAIN, id: 49330 ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;7.3.2.0.f.9.0.b.f.f.0.0.0.0.0.0.2.0.0.0.0.0.1.2.a.1.7.8.8.0.4.2.ip6.arpa. IN PTR *** RNDC(remote named control) BIND9以后，会在953启动rndc进程；使用rndc需要rndc key\nrndc命令：\nrndc status: 查看DNS服务器状态 rndc stats: 记录DNS服务器当前统计数据，保存至/var/named/data/named_stats.txt rndc dumpdb: 将cache数据写入文件，通常写到/var/named/data/cache_dump.db 远程更新DNS服务器数据 nsupdate可远程更新DNS server数据。前提是，server端给出密钥，且指定zone支持修改。 客户端更新方式：\n***$ nsupdate -k somekey \u0026gt; server 1.1.1.1 // 指定server地址 \u0026gt; update delete www.baidu.com // 删 \u0026gt; update add www.baidu.com 600 A 1.1.1.1 // 增 \u0026gt; send DNS解析器 DNS解析器配置，通常在/etc/resolv.conf，其包含以下指令的配置：\ndomain\ndomain test.com # domain指令用来设定本地域名，domain空白字符后跟域名，域名最后没有. # 其他设定本地域名的方法： # 1 本机hostname去除第一个.前面的数据，例如本机hostname为ztq.test.com,则根据hostname可推算本地域名为test.com # 2 domain指令 # 3 环境变量LOCALDOMAIN search\nsearch a.com b.com c.com # search指令与domain指令互斥，用来指定搜索列表 nameserver\nnameserver 1.1.1.1 nameserver 2.2.2.2 # nameserver指令告诉解析器，要查询的名称服务器的地址 # nameserver最多支持3条，解析器会按顺序查询 # 小tips: 全零地址(0.0.0.0)和loopback地址(127.0.0.1)一般都用来指“本机” sortlist\nsortlist 128.32.42.0/255.255.255.0 15.0.0.0 # 当解析器获取到多个结果时，会按顺序匹配sortlist中的地址，以此来获取多地址的使用优先级 # sortlist可以跟多地址 # 128.32.42.0/255.255.255.0，/后面是子网掩码 # 15.0.0.0，也可以使用这种不带子网掩码的，含义是15/32整个网段 options\noptions debug options ndots:2 options attempts:4 options timeout:2 options rotate options ndots:2 attempts:4 timeout:2 # 解析器一些乱七八糟的配置 ","permalink":"https://duck-dd.github.io/posts/dns/","summary":"\u003ch1 id=\"dns挺好啥是dns\"\u003eDNS，挺好，啥是DNS？\u003c/h1\u003e\n\u003ch2 id=\"一些概念\"\u003e一些概念\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eFQDN: Fully Qualified Domain Name，全限定域名，同时带有主机名和域名的名称（通过符号“.”），例如一个FQDN是www.baidu.com，www是主机名，baidu.com是域名。再举例，我是海淀吴彦祖，你是**吴彦祖，但是我们还知道，有个人就叫吴彦祖，这么多吴彦祖我们都没有混淆，因为名字前面加上了地域，也就是域名。从逻辑上看FQDN，就是主机名的完整表达，类似绝对路径，通过一个FQDN我们可以在全网内锁定主机位置。\u003c/li\u003e\n\u003cli\u003ecache only DNS server : 有.的zone file的DNS服务器，本身没有任何解析数据，完全靠查询来获取数据源\u003c/li\u003e\n\u003cli\u003eforwarding DNS server : 连.的zone file都没有，完全靠向上层查询获取数据；当使用forwarding功能时，即使本身有.的zone file，也不会向.查询，该DNS server还是会将查询完全委托给上层。\u003c/li\u003e\n\u003cli\u003eCIDR:Classless Inter-Domain Routing, 无类域间路由，不按固定的字节来划分网络编号，可以使用IP地址中任何相邻位的数字作为网络编号，例如某机构需要2个B类网络大小的空间，那么可以使用前15位作为网络编号，例如127.127.0.0/15\n\u003cul\u003e\n\u003cli\u003eA类,B类,C类网络：A类网络以IP地址的第一个字节(前8位)作为网络编号,剩下的24位为主机;B类网络前两个字节为网络编号;C类网络前三个字节为网络编号\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dns做什么\"\u003eDNS做什么\u003c/h2\u003e\n\u003cp\u003eipv4 32bit，ipv6 128bit，即使转成10/16进制也没人记得住，但是人类的头脑善于记录名字，所以可以搞一个名字跟IP对应，名字跟IP的对应关系解析，就是DNS提供的服务。\u003c/p\u003e\n\u003cp\u003e主机名的解析有一个发展的过程。\u003c/p\u003e\n\u003cp\u003e最初没有DNS人们如何记住各个服务名字跟IP的对应关系呢？就是写在/etc/hosts文件里，自己写麻烦，那就统一写到中心，使用的时候从中心拉取。\u003c/p\u003e\n\u003cp\u003e这个中心就是internic，主机名IP对应关系修改时，注册到internic中；用户准备上网之前先去internic把最新的文件拉下来，放在自己的/etc/hosts。\u003c/p\u003e\n\u003cp\u003e这种方式问题很多：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e例如internic拉取的文件会很大，每次打开电脑先拉个100G的文件然后再开始上网，就算你磁盘扛得住，你的网络不够好也很难受（因为你不能明确说明自己上网需要的主机名，只能拉全量，互联网业务增长该文件会越来越大）\u003c/li\u003e\n\u003cli\u003e例如这种方式是静态的，需要用户主动触发更新行为（你总不能让一个人开机默认就去下载100G的文件，他不可能给你授权的）；试想一下，一个网瘾少年下午6点睡眼惺忪的起床，打开电脑先从internic下载了半个小时文件，期间去洗漱吃了早饭，然后开开心心开始打游戏，突然，游戏掉线了，上贴吧一查，大家都说快去重新拉取internic的hosts文件呀，游戏域名被友商攻击换域名了，这还好，少年骂骂咧咧下载个文件就完事了，要是贴吧都上不去就更让人懵逼了\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e时代的进步总是聪明人推动的。Berkeley一个同学就觉得这种方式不太行，于是他就搞出一套BIND系统提供DNS服务。\u003c/p\u003e\n\u003ch2 id=\"bindberkeley-internet-name-domain\"\u003eBIND，Berkeley Internet Name Domain\u003c/h2\u003e\n\u003ch3 id=\"bind管理方式\"\u003eBIND管理方式\u003c/h3\u003e\n\u003cp\u003eBIND是一套阶层式的管理主机名与IP对应关系的系统。\u003c/p\u003e\n\u003cp\u003e阶层式？可以简单理解为树状结构的不同层级，下面来简单分析下阶层式。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/dns/1.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e以www.baidu.com为例，最上层根服务器，domain name是\u0026quot;.\u0026quot;，然后有三个hostname \u0026ldquo;net com cn\u0026rdquo;，再到第三层，hostname分别是pdd baidu tencent，此时domain name为.com. ，以此类推。。。需要注意的是，不是每一个\u0026quot;.\u0026ldquo;都拆分domain name\u0026amp;hostname，例如上图  video.www.baidu.com ，其中domain name为baidu.com.，hostname为video.www。按照上述方式分层，每一个服务节点（权威）只负责自己的一小撮域名，这就避免了大量数据集中的问题。\u003c/p\u003e\n\u003cp\u003eDNS阶层系统的最上方是一个\u0026rdquo;.\u0026quot;，root，是根服务器，本质上讲，这里的\u0026quot;.\u0026ldquo;后面其实是空标签，这是为root保留的；根服务器下一层管理的是Top Level Domains(TLD)，例如com. net. org.等等。\u003c/p\u003e\n\u003cp\u003e每个上一层的DNS服务器，所记录的信息，只有下一层的主机名；再下一层，授权给再再下层某个主机管理，这就是分层管理；DNS分层最多到127层(实际上不会用到这么多)，每一层最多63个字符(不包括\u0026rdquo;.\u0026quot;)；同一层内不允许同名，确保唯一性。\u003c/p\u003e\n\u003ch3 id=\"bind查询流程\"\u003eBIND查询流程\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e当浏览器输入 \u003ca href=\"https://www.baidu.com\"\u003ehttps://www.baidu.com\u003c/a\u003e ，先查浏览器缓存，再查/etc/hosts文件，都找不到www.baidu.com的解析时，会根据/etc/resolv.conf文件内配置的DNS服务器地址，去进行DNS解析，询问www.baidu.com的A记录\u003c/li\u003e\n\u003cli\u003eclient第一步找到的DNS服务器通常为运营商提供的local DNS服务器，local DNS作为名称服务器，接收client端的递归查询请求，若local DNS服务器自身没有www.baidu.com的解析结果，则向.DNS服务器发起解析请求，询问www.baidu.com是啥A记录呢？\n\u003cul\u003e\n\u003cli\u003e其实递归查询实际过程中，local DNS若未命中缓存，并不是直接查询根服务器，他会寻找已知最近的名称服务器(待实验确认)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e.并不知道www.baidu.com的IP，它会告诉你我只知道.com，IP给你，你去问它吧\u003c/li\u003e\n\u003cli\u003e然后local DNS获取到了.com的信息后，开始向.com询问www.baidu.com的解析结果\u003c/li\u003e\n\u003cli\u003e.com也不知道www.baidu.com的IP地址，它会说，我只认识baidu.com，你去问它吧\n\u003cul\u003e\n\u003cli\u003e.com返回的一般是baidu.com的多个NS域名(及其IP,胶水记录)，如下例图，那么如何选择权威呢？BIND名称服务器使用RTT(roundtrip time)的度量方式来选择对同一区域中的名称服务器进行选择，即选择RTT最小的那个名称服务器(dig +trace抓包并没看到对RTT的探测，现象上看是从ns*.baidu.com里面随机选择的？)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/dns/2.jpg\"\u003e\u003c/p\u003e","title":"DNS"}]