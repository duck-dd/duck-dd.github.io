<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Duck</title><meta name=keywords content><meta name=description content="Posts - Duck"><meta name=author content><link rel=canonical href=https://duck-dd.github.io/posts/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2a8ef18cccda149eb1cd8ec968ba463447d72022979e5c5cae43dcf5d7358750.css integrity="sha256-Ko7xjMzaFJ6xzY7JaLpGNEfXICKXnlxcrkPc9dc1h1A=" rel="preload stylesheet" as=style><link rel=icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://duck-dd.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://duck-dd.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><meta property="og:url" content="https://duck-dd.github.io/posts/"><meta property="og:site_name" content="Duck"><meta property="og:title" content="Posts"><meta property="og:description" content="ExampleSite description"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://duck-dd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://duck-dd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Posts"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://duck-dd.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://duck-dd.github.io/ accesskey=h title="首页 (Alt + H)"><img src=https://duck-dd.github.io/apple-touch-icon.png alt aria-label=logo height=35>首页</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://duck-dd.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://duck-dd.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://duck-dd.github.io/about_me title=关于我><span>关于我</span></a></li><li><a href=https://duck-dd.github.io/about_space title=关于这里><span>关于这里</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://duck-dd.github.io/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>装修那些事儿</h2></header><div class=entry-content><p>这个行业，是一个没有监管，没有行业标准(有的大部分也是扯淡)，群魔乱舞的行业，这行业人的话，不要相信，不要相信，不要相信
从我自身经历来说，这件事真的不复杂，完全不值他现在的价钱；一开始这件事很神秘，你觉得付多少钱都是合理的，但真不是这样，到处都是骗钱的；所以装修开始前真正的第一件事，就是你要了解一下背景评估一下工作量，放心大胆的去砍价吧
本文从自己的亲身经历出发来分析一下装修这件令人头疼的事情，没有展开太多的细节，只以各个阶段的典型选择题为切入点，欢迎指正和交流，预祝你获得你的梦中情屋～
全包 or 半包 如果你刚开始考虑装修，那你一定是特别开心和兴奋的。
你面临的第一个问题大概就是，“半包” or “全包”（自己找工人的方式，不太了解就不谈了）；很多声音会告诉你说，全包这种完全黑盒的行为会有太多坑了，给你用的东西都是差的balabala
但是，如果你想省心，或者在装修的这几个月里你没有太多的时间精力能够投入进这件事，那么还是建议你咬咬牙忽略这些有一丢丢危言耸听的说法，果断的选择全包
如果你选择了全包，那么我们对最终效果的确认无非靠两个关键指标
1 是不是我想要的样子 2 是不是环保 为了第一点，你需要查看素材库确认好自己喜欢的样子，跟设计师做充分的沟通，并在施工过程的关键节点约设计师一起去现场做阶段性的沟通和double check，因为省心，所以你做的功课可能不多，其实这比较依赖设计师的专业性
为了第二点，你需要做的功课是，查一查装修过程中哪些使用到的材料可能会不环保，然后直接在合同里声明好这些材料具体使用哪些品牌的哪些型号，并在这些材料入场时做好检查(其实可以找类似"监工"的角色来帮助你执行，应该总比你完全不去现场要好)
朋友，如果你选择了半包，那你是真的勇士，对你表示敬佩，以下的讨论咱们就默认你已经做了大量的背景&功课的学习。
入户门 换！你99%不喜欢开发商的这个，相比换锁，就干脆直接换门吧
窗户 如果允许，换！拉满配(可能很多地方政策不允许动外立面，那就没办法了)
隔音 如果你对声音要求很高，考虑做全屋音响，那是肯定得做了
如果你没有考虑做全屋音响，那么我还是强！烈！建！议！做！隔！音！
全屋定制 or 成品家具 个人观点，全屋定制真的不咋地，建议祛魅，认真的去逛一逛成品家具市场
还往下看，你果然还是跟我一样，头铁的选择了全屋定制，那这个子方向发个千八百个论文感觉都泛不起一点水花； 商家贩卖的焦虑点：甲醛，苯系化合物；你要想死磕，得先学化学
标准：国外国内太多标准，但有一点个人觉得有参考意义，就是 抽检 & 送检
品牌选择：大商场大品牌的品牌溢价确实太高了，而且也确实代加工，所以有判断能力那就果断直接找工厂吧
细节不展开讲了，说一点注意点，跟电位/管道做配合要提前做规划，这也是为什么把这个问题放得这么靠前
布局 该砸就砸别犹豫(非承重) 新砌墙时考虑好用途，如果有承重需求(例如挂电视 挂柜子等)，考虑好墙体的材料 砌墙后多晾一晾 否则后期墙上面搞得任何东西都容易剥离
墙的平的问题，从小白视角来看，就是表面是平面，并且这个平面跟其他平面的角度(一般90度)是正常的，这点不管施工方是冲筋 垂平还是啥方法，总之先讲清楚要求并让他们严格执行
坐便or蹲便？多个卫生间可以考虑留一个蹲便，不仅健康，而且后期小孩使用也好扩展（这个问题需要提前考虑因为可能影响卫生间地面高度布局）
水电 水管线管一定选择最好的品牌的好的型号，避免后期出问题太麻烦
至于是按使用长度算，还是一口价模式，自己来衡量对比，是否点对点走线？可以看网上大量的分析
电箱位置挪不挪？如果风水问题(那么你一定是相信这个的)，挪；如果只是为了好看，那后期挺多方法弄好看，可以看看效果自己能不能接受
前置过滤器：空间允许，就安；拉满配，本身没多贵，影响水压就不好了
全屋软水：没考虑清楚，就做
下水：有顾虑该做的位置就做，用不用得上再说
电位：有顾虑就做，总比后期拉插线板强(70个/100平 ？)
开关：一开多控别顾虑，想做就做，方便生活
全屋智能：已经在考虑这个问题了？那就做。。。有点贵，但应了那句话，贵的东西，除了贵，没有其他的毛病
智能开关记得留零线
这里不展开讲了，太复杂了，完全可以单开一页的东西，有两个容易忽略的点
1 墙面别开长横槽(脑补一下这确实会影响墙的稳定性) 2 强弱电磁场干扰隔离（物理已经还给老师了，但是避免干扰这个要保持距离还是符合常识的） 接下来让我们一起进入木瓦油环节
全屋吊顶 or 部分吊顶 如果考虑做无主灯，那么肯定全屋吊顶
...</p></div><footer class=entry-footer><span title='2023-06-24 00:00:00 +0000 UTC'>2023-06-24</span>&nbsp;·&nbsp;创建于:&nbsp;2023-06-24&nbsp;·&nbsp;1 min&nbsp;·&nbsp;132 words</footer><a class=entry-link aria-label="post link to 装修那些事儿" href=https://duck-dd.github.io/posts/%E8%A3%85%E4%BF%AE/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>软件架构设计原则</h2></header><div class=entry-content><p>每次接手一些老旧系统，总是很头疼，最近想，会不会别人接手了我的系统以后也是一样的感受，想到可能有人每天都在吐槽(骂)我头皮发麻啊…
知易行难，其实怎么做好一个后端服务大家都是门清的，只是受限于 排期 业务价值 协作 等太多因素，往往事与愿违。只能说但行好事莫问前程吧，下面再把这些原则列一下，时刻提醒自己吧；以下原则从个人角度分先后，不是说有重要性区别，而是有些原则很高频，或者很容易被忽略，需要时刻牢记。
一 职责/逻辑 清晰 单一职责原则（Single Responsibility Principle, SRP） 每个单元只负责一件事。 从总体架构上讲，这个单元是一个子系统，例如订单系统，日志系统；从系统架构上讲，这个单元是一个模块，例如文章管理模块，评论管理模块等；从代码模块内部讲，这个单元是一个组件，一个类，一个struct等。再往下看，一个类还有N多个方法… 就像分子，原子，质子/电子，夸克…从宏观到微观的过程，就是我们把一套复杂的系统一点一点拆解开的过程，而每次向下拆解一层的时候，这一层的个体，尽量做到每个都负责一件事
迪米特法则（Law of Demeter, LoD） 一个模块应尽可能少地了解其他模块的内部细节。 反过来看，一个模块向外不暴露细节，别人就没法了解细节了；所以还是在讲控制耦合。
高内聚，低耦合（High Cohesion, Low Coupling） 模块内部的功能紧密相关(高内聚)，模块间通过明确接口交互，依赖关系简单(低耦合)。 明牌了，直接再提醒你一下，控制耦合控制耦合控制耦合…
接口隔离原则（Interface Segregation Principle, ISP） 客户端不应被迫依赖它不需要的接口，应将大接口拆分为多个专用小接口。 这里不是对使用者的要求，而是对接口提供(设计)者提出要求，在设计对外暴露接口时，要尽可能小，单一，独立，这样使用起来更灵活。 对外是这样的，但是内部接口，说实话我做不到尽可能小。
二 破坏性(侵入性)控制 开闭原则（Open-Closed Principle, OCP） 对扩展开放，对修改关闭。 从我的理解，这条原则更多还是在指导代码层面的设计；世界是动态发展的，没有一成不变的东西，那么对于代码，可扩展是必然的需求，那为什么对修改关闭呢？可能更多还是对原系统的侵入吧，你不知道你的使用方对你做出了怎么样的假设，总之目前为止世界和平，但当你修改了你的行为，假设被打破，世界就崩塌了
里氏替换原则（Liskov Substitution Principle, LSP） 子类必须能无缝替换父类，且不破坏原有系统的正确性。即父类出现的地方，子类可替代，且行为一致。
三 依赖管理 分层架构原则（Layered Architecture Principle） 将系统按职责划分为清晰的层次，层间单向依赖，禁止跨层调用。
依赖倒置原则（Dependency Inversion Principle, DIP） 高层模块不应依赖低层模块，两者都应依赖抽象；抽象不应依赖细节，细节应依赖抽象。
四 可扩展性 演进式架构原则（Evolutionary Architecture） 架构设计应预留扩展空间，支持系统随业务需求逐步演进，而非追求 “一步到位” 的完美设计。
五 安全(代码安全，服务安全，业务安全等) 安全性原则（Security by Design） 将安全性嵌入架构设计的每个环节，而非事后补丁。
...</p></div><footer class=entry-footer><span title='2023-04-16 00:00:00 +0000 UTC'>2023-04-16</span>&nbsp;·&nbsp;创建于:&nbsp;2023-04-16&nbsp;·&nbsp;1 min&nbsp;·&nbsp;71 words</footer><a class=entry-link aria-label="post link to 软件架构设计原则" href=https://duck-dd.github.io/posts/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>golang select case机会均等</h2></header><div class=entry-content><p>验证 我们每天都在使用下面这样的用法，对于这种多条件分支判定，我们从来不会指定权重，按固有思维，多条件间应该是机会均等的，那么golang如何做的呢？
select { case &lt;-ch1: do sth case &lt;-ch2: do sth case &lt;-ch3: do sth } 我们先来看看到底是不是机会均等的。
package main import("fmt") func main() { sum1, sum2, sum3 := 0, 0, 0 for loop:=0; loop&lt;8 ; loop++ { count1, count2, count3 := 0, 0, 0 ch1, ch2, ch3 := make(chan int), make(chan int), make(chan int) go func(){for { ch1&lt;-1 }}() go func(){for { ch2&lt;-1 }}() go func(){for { ch3&lt;-1 }}() for i := 0; i &lt; 10000; i++ { select { case &lt;-ch1: count1++ sum1++ case &lt;-ch2: count2++ sum2++ case &lt;-ch3: count3++ sum3++ } } fmt.Println("loop ", loop+1, ": ", count1, count2, count3) } fmt.Println("sum: ", sum1, sum2, sum3) } 结果: loop 1 : 1535 5446 3019 loop 2 : 1607 5004 3389 loop 3 : 1146 3549 5305 loop 4 : 4100 2601 3299 loop 5 : 5938 2260 1802 loop 6 : 923 1268 7809 loop 7 : 4958 2273 2769 loop 8 : 3162 3432 3406 sum: 23369 25833 30798 诶，好像不太对啊，尤其loop 7，偏差到飞起了啊…总量的偏差也大的离谱…
...</p></div><footer class=entry-footer><span title='2022-04-13 00:00:00 +0000 UTC'>2022-04-13</span>&nbsp;·&nbsp;创建于:&nbsp;2022-04-13&nbsp;·&nbsp;4 min&nbsp;·&nbsp;712 words</footer><a class=entry-link aria-label="post link to golang select case机会均等" href=https://duck-dd.github.io/posts/golang-select-case%E6%9C%BA%E4%BC%9A%E5%9D%87%E7%AD%89/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Golang schedule</h2></header><div class=entry-content><p>写在前面 runtime包实现了所有goroutine scheduler、memory allocator、garbage collector细节，理论上可以从runtime包获取一切信息，没有直接怼源码，而是站在巨人的肩膀上（直接吃大佬们吃剩下的）。
搜集到的材料，大家都是基于不同的go版本做的分析，而go版本迭代调度算法也在持续更新，所以整理的可能有些乱。但是可以保证的是，所有材料都是GM->GMP演化后的材料。
GM go1.1版本以前，调度使用GM模型，如下图所示。简单的理解GM模型，就是有一个始终执行的调度函数schedule不停的执行调度计算，当某个M的G执行完成了，调度器就把这个M放回M队列，可绑定执行其他G（如果某个M+G发生了syscall，那么本来并发度是通过M数量控制的，此时并发度就降低了？）；如果G执行过程中创建新的G，会将新的G放入到G全局可执行队列中。G全局可执行队列的操作有一把全局锁，这导致了各个M对G全局队列的操作存在严重的竞争。
下面这段完全是我的臆测，请别太相信：
简单概括呢，所以可以认为有：
G全局可执行队列(以下也可能简称G可执行队列) M可用队列 调度器要做的事就是：
从G的可执行队列取G并从M的可用队列取M，将二者绑定开始执行G 对于已经执行完的G，销毁G并立即将M释放回M可用队列供后续使用 那么GM模型有哪些问题呢？
(重点问题)单一的全局mutex(sched.lock)和集中状态管理 mutex需要保护所有与全局goroutine队列相关操作(创建、完成、重排等等)，竞争严重 (重点问题)per-M内存(M.mcache)问题 每个M都需要一个mcache，会导致资源消耗过大(每个mcache可以吸纳到2MB的内存缓存和其他缓存) 举个栗子，一个陷入syscall的M并不需要使用cache，但是在全部的M中，陷入系统调用的M与执行goroutine的M的比例可能是N:1(N>>1)，这就导致了N/(N+1)比例的mcache在闲置 数据局部性差: 举个栗子，M1执行G1，此时创建了G2，G2通常是立刻进入了G全局可执行队列，而此时M1还在执行G1，所以G2通常被其他M执行，但是G1和G2通常强相关，所以G2最好也在M1上执行，因为G2对M1的缓存命中率更高 goroutine传递问题 goroutine(G)交接(G.nextg)，M之间会经常交接可运行的G 再通俗点说，就是G空转，本来能够好好在一个M上执行完，但是由于全局队列的存在，G一旦回全局队列了，下次就不知道被哪个M取走了，所以叫“空转”；M加载G的上下文是有开销的，所以空转会导致性能下降 频繁的线程阻塞/解阻塞 syscalls情况下，线程经常被阻塞和解阻塞，增加了很多额外开销 通俗点说，M+G syscall，M阻塞，syscall完成后，M解阻塞继续执行G（如果是通过M数量控制并发度，这是不是就导致了并发度降低？） GMP 基于以上说的GM的问题，go1.1以后开始使用GMP调度模型。 G、M、P的定义如下(***/src/runtime/runtime2.go)。
type g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer m *m // current m; offset known to arm liblink sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.Pointer // passed parameter on wakeup atomicstatus uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid int64 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting preempt bool // preemption signal, duplicates stackguard0 = stackpreempt preemptStop bool // transition to _Gpreempted on preemption; otherwise, just deschedule preemptShrink bool // shrink stack at synchronous safe point // asyncSafePoint is set if g is stopped at an asynchronous // safe point. This means there are frames on the stack // without precise pointer information. asyncSafePoint bool paniconfault bool // panic (instead of crash) on unexpected fault address gcscandone bool // g has scanned stack; protected by _Gscan bit in status throwsplit bool // must not split stack // activeStackChans indicates that there are unlocked channels // pointing into this goroutine's stack. If true, stack // copying needs to acquire channel locks to protect these // areas of the stack. activeStackChans bool // parkingOnChan indicates that the goroutine is about to // park on a chansend or chanrecv. Used to signal an unsafe point // for stack shrinking. It's a boolean value, but is updated atomically. parkingOnChan uint8 raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine sysexitticks int64 // cputicks when syscall has returned (for tracing) traceseq uint64 // trace event sequencer tracelastp puintptr // last P emitted an event for this goroutine lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state // gcAssistBytes is this G's GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 } type m struct { g0 *g // goroutine with scheduling stack morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. procid uint64 // for debuggers, but offset not hard-coded gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask tls [6]uintptr // thread-local storage (for x86 extern register) mstartfn func() curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall id int64 mallocing int32 throwing int32 preemptoff string // if != "", keep curg running on this m locks int32 dying int32 profilehz int32 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) fastrand [2]uint32 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call park note alllink *m // on allm schedlink muintptr lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 freelink *m // on sched.freem // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call // preemptGen counts the number of completed preemption // signals. This is used to detect when a preemption is // requested, but fails. Accessed atomically. preemptGen uint32 // Whether this is a pending preemption signal on this M. // Accessed atomically. signalPending uint32 dlogPerM mOS // Up to 10 locks held by this m, maintained by the lock ranking code. locksHeldLen int locksHeld [10]heldLockInfo } type p struct { id int32 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call syscalltick uint32 // incremented on every system call sysmontick sysmontick // last tick observed by sysmon m muintptr // back-link to associated m (nil if idle) mcache *mcache pcache pageCache raceprocctx uintptr deferpool [5][]*_defer // pool of available defer structs of different sizes (see panic.go) deferpoolbuf [5][32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 runqtail uint32 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready'd by // the current G and should be run next instead of what's in // runq if there's time remaining in the running G's time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready'd // goroutines to the end of the run queue. runnext guintptr // Available G's (status == Gdead) gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog // Cache of mspan objects from the heap. mspancache struct { // We need an explicit length here because this field is used // in allocation codepaths where write barriers are not allowed, // and eliminating the write barrier/keeping it eliminated from // slice updates is tricky, moreso than just managing the length // ourselves. len int buf [128]*mspan } tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex _ uint32 // Alignment for atomic fields below // The when field of the first entry on the timer heap. // This is updated using atomic functions. // This is 0 if the timer heap is empty. timer0When uint64 // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) gcBgMarkWorker guintptr // (atomic) gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // gcw is this P's GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P's GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point // Lock for timers. We normally access the timers while running // on this P, but the scheduler can also do it from a different P. timersLock mutex // Actions to take at some time. This is used to implement the // standard library's time package. // Must hold timersLock to access. timers []*timer // Number of timers in P's heap. // Modified using atomic instructions. numTimers uint32 // Number of timerModifiedEarlier timers on P's heap. // This should only be modified while holding timersLock, // or while the timer status is in a transient state // such as timerModifying. adjustTimers uint32 // Number of timerDeleted timers in P's heap. // Modified using atomic instructions. deletedTimers uint32 // Race context used while executing timer functions. timerRaceCtx uintptr // preempt is set to indicate that this P should be enter the // scheduler ASAP (regardless of what G is running on it). preempt bool pad cpu.CacheLinePad } GMP模型的一些概念 上面M中有两个g需要关注下，curg和g0。 curg就是M当前绑定的G。 g0是带有调度栈的goroutine，普通的G的栈是分配在堆上的可增长的栈，而g0的栈是M对应的线程的栈。所有调度相关的代码，会先切换到该goroutine的栈中执行。即，线程的栈也是用的g实现，而不是使用的OS。
...</p></div><footer class=entry-footer><span title='2021-08-21 00:00:00 +0000 UTC'>2021-08-21</span>&nbsp;·&nbsp;创建于:&nbsp;2021-08-21&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1904 words</footer><a class=entry-link aria-label="post link to Golang schedule" href=https://duck-dd.github.io/posts/go-schedule/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>happens-before</h2></header><div class=entry-content><p>在并发系统中，用于描述事件执行顺序关系；若事件A “happens-before” 事件B，则A的执行结果对B可见，且A在逻辑上先于B执行(并不要求在物理时间上A必须先于B执行)。
所以这其实是一种逻辑关系，在并发系统中，P1 P2 两个过程在逻辑上"同时"在执行，P2过程中的事件B依赖P1过程中的事件A的结果，那么就需要逻辑上的 “happens-before” 来确保A&amp;B间的依赖关系。
常见的并发模型 共享内存 和 消息传递，都遵循 “happens-before"逻辑，消息传递中的happens-before好理解，消息的传入肯定是在消息的接收之前的，在共享内存模型的并发中，happens-before就是帮助我们在逻辑上自洽，理清楚不同并发单元(线程 协程 等)对某一个共享内存变量的操作顺序。</p></div><footer class=entry-footer><span title='2021-08-19 00:00:00 +0000 UTC'>2021-08-19</span>&nbsp;·&nbsp;创建于:&nbsp;2021-08-19&nbsp;·&nbsp;1 min&nbsp;·&nbsp;15 words</footer><a class=entry-link aria-label="post link to happens-before" href=https://duck-dd.github.io/posts/happens-before/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>离职人生体验 2021-07-08日记</h2></header><div class=entry-content><p>2018年7月4日，星期三，天气晴。
早晨7点半，太阳已经很大，收拾好材料，出发，今天是上班的第一天，也是第一天上班。浑浑噩噩的流程，脑子里什么都没进，然后晕头转向的上了班车，从大厦到了科技园。找工位，认识同事，熟悉环境，然后第一天就心大的开始午睡，睡了2小时，爬起来，心想，坏了，睡过了，然后，发现并没有人关注我，呼～，长出一口气，心想社畜生活貌似还挺轻松。
leader下午快到晚饭才开完会（以至于后面很长一段时间我觉得自己菜的评判标准就是没会开，太年轻啊），找到我，“走，一块吃个晚饭”，我怀着无比的尴尬，回，“哥，我吃完了。。。（心想完了第一天就摸鱼还被发现了）”，leader说，那走吧，随便找个空会议室聊两句。“别叫哥，我们这里都不这样叫，直接叫我名字就行”，我心想，业界都传的XX有着最好的氛围，看来是真的，跟学校没什么两样哈。leader说，“BFE听过吧”，我理直气壮的回，“没啊” （冷场大概有两秒钟吧，这里可能原本应该有十分钟左右的技术交谈，然后大概是临时取消了吧） “我是你的导师，但是平时时间不太充裕，你有问题多问问我们组的人吧，其中还有一个是你的师兄”，“好的”。本次谈话就此结束，我开始回去看材料学习，第一天到底学会了啥，完全不记得了，可能甚至大概都没搞懂BFE全称到底是啥吧。
对于这一天只记得这么多，但是三年了，能对一天记得这么多，于我也是难得。直到后来，我才知道，团队有几十人，有N多个方向，leader甚至是身边每一个同事，都是大佬。
反而是接下来的三年，此时此刻回想起来，感觉只是恍惚间。唯一记得就只是18年底，接到了春晚项目，一个月没休息，回家过年下飞机的第一件事，就是开机看一眼**备战群（唉，总是这样，一有事就各种备战，搞得人很紧张）。2018，把春晚从头看到尾，红包没抢到几块钱，但是第一次从工作中获得一点成就感。那些加过的班，熬过的夜，回头看，都不记得了。同时，不记得的，还有这三年学会的知识，真是悲哀。
上百万封邮件(收)，几万行代码，几千条SQL，几百张图，几十周值班，几个case（呸，我没case @_@ 真的没一个线上有损case，难道应了老话，干的少错的少？）。
没学到东西当然是玩笑话，从心底里感谢XX教给我的一身本领，不大，但是贵在积累。也希望我的工作，没有让任何人感到过失望。
来公司的第一天，就看到了“离职申请”这个页面，从第一天就在好奇点开到底长什么样子，担心有log，所以没点。。。唉，其实点开了，没什么，也是一个普通的页面而已。
交接过程中，每天还是会零星接到几个客官老爷，但是渐渐的，大家注意到签名了。“诶，你要走啦”。越来越多的人前来告别，大部分人，都没有见过面。告别语中，祝福偏多，偶尔也会得到几句赞许，所幸没有挨一句骂（是不是有点幸存者偏差了@-@）。就觉得，回报应该真的与付出成正比，延迟满足带来的幸福感甚至可能是指数级的。也觉得，与人为善总是好的（也可以理解为我大部分时间都很怂@_@）。
最后的工作月，迟到的次数反而比平时更少了，真是怪哉。小伙伴们总是开我的玩笑，工作3年，工作经验6年。我觉得吧，夸张了，工作3年工作经验顶多4年吧，还是得算上划水时间。
遗憾的是，没有打破自己的人生魔咒，“在一个地方超过三年”。
感谢一起共事过的所有伙伴，你们教会我的知识和道理，我还会继续学习。
如果未来还能有机会发声，会提一条建议，离职窗口的工作人员，能不能多一项培训，“减少冷漠”。要走的人，总是感性的，一个善意的微笑，可能比文化部门铺天盖地的宣传更有效果。再多一条建议，离职窗口旁边收集下即将离开的伙伴的建议和意见，或者就随便写几句，这里可能才是最真实的声音。感谢，感恩，祝福XX越来越好。
再多的感触，就留在心里了。
爱过。</p></div><footer class=entry-footer><span title='2021-07-08 00:00:00 +0000 UTC'>2021-07-08</span>&nbsp;·&nbsp;创建于:&nbsp;2021-07-08&nbsp;·&nbsp;1 min&nbsp;·&nbsp;19 words</footer><a class=entry-link aria-label="post link to 离职人生体验 2021-07-08日记" href=https://duck-dd.github.io/posts/%E7%A6%BB%E8%81%8C%E4%BA%BA%E7%94%9F%E4%BD%93%E9%AA%8C-2021-07-08%E6%97%A5%E8%AE%B0/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DNS</h2></header><div class=entry-content><p>DNS，挺好，啥是DNS？ 一些概念 FQDN: Fully Qualified Domain Name，全限定域名，同时带有主机名和域名的名称（通过符号“.”），例如一个FQDN是www.baidu.com，www是主机名，baidu.com是域名。再举例，我是海淀吴彦祖，你是**吴彦祖，但是我们还知道，有个人就叫吴彦祖，这么多吴彦祖我们都没有混淆，因为名字前面加上了地域，也就是域名。从逻辑上看FQDN，就是主机名的完整表达，类似绝对路径，通过一个FQDN我们可以在全网内锁定主机位置。 cache only DNS server : 有.的zone file的DNS服务器，本身没有任何解析数据，完全靠查询来获取数据源 forwarding DNS server : 连.的zone file都没有，完全靠向上层查询获取数据；当使用forwarding功能时，即使本身有.的zone file，也不会向.查询，该DNS server还是会将查询完全委托给上层。 CIDR:Classless Inter-Domain Routing, 无类域间路由，不按固定的字节来划分网络编号，可以使用IP地址中任何相邻位的数字作为网络编号，例如某机构需要2个B类网络大小的空间，那么可以使用前15位作为网络编号，例如127.127.0.0/15 A类,B类,C类网络：A类网络以IP地址的第一个字节(前8位)作为网络编号,剩下的24位为主机;B类网络前两个字节为网络编号;C类网络前三个字节为网络编号 DNS做什么 ipv4 32bit，ipv6 128bit，即使转成10/16进制也没人记得住，但是人类的头脑善于记录名字，所以可以搞一个名字跟IP对应，名字跟IP的对应关系解析，就是DNS提供的服务。
主机名的解析有一个发展的过程。
最初没有DNS人们如何记住各个服务名字跟IP的对应关系呢？就是写在/etc/hosts文件里，自己写麻烦，那就统一写到中心，使用的时候从中心拉取。
这个中心就是internic，主机名IP对应关系修改时，注册到internic中；用户准备上网之前先去internic把最新的文件拉下来，放在自己的/etc/hosts。
这种方式问题很多：
例如internic拉取的文件会很大，每次打开电脑先拉个100G的文件然后再开始上网，就算你磁盘扛得住，你的网络不够好也很难受（因为你不能明确说明自己上网需要的主机名，只能拉全量，互联网业务增长该文件会越来越大） 例如这种方式是静态的，需要用户主动触发更新行为（你总不能让一个人开机默认就去下载100G的文件，他不可能给你授权的）；试想一下，一个网瘾少年下午6点睡眼惺忪的起床，打开电脑先从internic下载了半个小时文件，期间去洗漱吃了早饭，然后开开心心开始打游戏，突然，游戏掉线了，上贴吧一查，大家都说快去重新拉取internic的hosts文件呀，游戏域名被友商攻击换域名了，这还好，少年骂骂咧咧下载个文件就完事了，要是贴吧都上不去就更让人懵逼了 时代的进步总是聪明人推动的。Berkeley一个同学就觉得这种方式不太行，于是他就搞出一套BIND系统提供DNS服务。
BIND，Berkeley Internet Name Domain BIND管理方式 BIND是一套阶层式的管理主机名与IP对应关系的系统。
阶层式？可以简单理解为树状结构的不同层级，下面来简单分析下阶层式。
以www.baidu.com为例，最上层根服务器，domain name是"."，然后有三个hostname “net com cn”，再到第三层，hostname分别是pdd baidu tencent，此时domain name为.com. ，以此类推。。。需要注意的是，不是每一个".“都拆分domain name&amp;hostname，例如上图 video.www.baidu.com ，其中domain name为baidu.com.，hostname为video.www。按照上述方式分层，每一个服务节点（权威）只负责自己的一小撮域名，这就避免了大量数据集中的问题。
DNS阶层系统的最上方是一个”."，root，是根服务器，本质上讲，这里的".“后面其实是空标签，这是为root保留的；根服务器下一层管理的是Top Level Domains(TLD)，例如com. net. org.等等。
每个上一层的DNS服务器，所记录的信息，只有下一层的主机名；再下一层，授权给再再下层某个主机管理，这就是分层管理；DNS分层最多到127层(实际上不会用到这么多)，每一层最多63个字符(不包括”.")；同一层内不允许同名，确保唯一性。
BIND查询流程 当浏览器输入 https://www.baidu.com ，先查浏览器缓存，再查/etc/hosts文件，都找不到www.baidu.com的解析时，会根据/etc/resolv.conf文件内配置的DNS服务器地址，去进行DNS解析，询问www.baidu.com的A记录 client第一步找到的DNS服务器通常为运营商提供的local DNS服务器，local DNS作为名称服务器，接收client端的递归查询请求，若local DNS服务器自身没有www.baidu.com的解析结果，则向.DNS服务器发起解析请求，询问www.baidu.com是啥A记录呢？ 其实递归查询实际过程中，local DNS若未命中缓存，并不是直接查询根服务器，他会寻找已知最近的名称服务器(待实验确认) .并不知道www.baidu.com的IP，它会告诉你我只知道.com，IP给你，你去问它吧 然后local DNS获取到了.com的信息后，开始向.com询问www.baidu.com的解析结果 .com也不知道www.baidu.com的IP地址，它会说，我只认识baidu.com，你去问它吧 .com返回的一般是baidu.com的多个NS域名(及其IP,胶水记录)，如下例图，那么如何选择权威呢？BIND名称服务器使用RTT(roundtrip time)的度量方式来选择对同一区域中的名称服务器进行选择，即选择RTT最小的那个名称服务器(dig +trace抓包并没看到对RTT的探测，现象上看是从ns*.baidu.com里面随机选择的？) ...</p></div><footer class=entry-footer><span title='2021-05-13 00:00:00 +0000 UTC'>2021-05-13</span>&nbsp;·&nbsp;创建于:&nbsp;2021-05-13&nbsp;·&nbsp;4 min&nbsp;·&nbsp;847 words</footer><a class=entry-link aria-label="post link to DNS" href=https://duck-dd.github.io/posts/dns/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://duck-dd.github.io/posts/>«&nbsp;Prev&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://duck-dd.github.io/>Duck</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>