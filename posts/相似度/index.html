<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>相似度 | Duck</title><meta name=keywords content="CS-Other"><meta name=description content="相似度算法用于衡量多个对象（如文本、数值向量、图像、序列等）之间相似程度的数学方法。
在计算机领域，通常将 “相似性” 转化为可计算的数值（例如 0~1 表示，1代表完全相似，0代表完全不相似）。
相似度算法的应用十分广泛，例如推荐系统（如商品/内容推荐）、数据挖掘（如聚类、分类）、NLP（如文本查重、语义匹配）、图像识别等。
文本相似度
基于字符/词频
不依赖语义理解，仅从文本的字符或词语出现频率出发计算相似性，适合简单的短文本内容的场景。
Jaccard 系数（杰卡德相似度）
思路：将文本视为 “词语集合”（忽略词频和顺序），相似性 = 两个集合的交集大小 / 两个集合的并集大小
举个例子，sim(“小明球技很棒” & “小明球技真好”) = len(&ldquo;小明&rdquo; &ldquo;球技&rdquo;)/len(&ldquo;小明&rdquo; &ldquo;球技&rdquo; &ldquo;很棒&rdquo; &ldquo;真好&rdquo;) = 0.5
优点

简单

缺点

词频没有统计
语义不做理解，&ldquo;真好&rdquo; &ldquo;很棒&rdquo; 其实语义接近

余弦相似度（Cosine Similarity）
思路：将文本转换为词频向量，相似性 = 两个向量夹角余弦值
举个例子，(“小明球技很棒啊，小明不错” & “小明球技真好”)，构建词袋=[&ldquo;小明&rdquo; &ldquo;球技&rdquo; &ldquo;很棒&rdquo; &ldquo;真好&rdquo; &ldquo;不错&rdquo;]，对于词袋，计算向量值，“小明球技很棒”的词频向量A = [2,1,1,0,1]，“小明球技真好”的词频向量B = [1,1,0,1,0]，则 相似性 = cos(A,B) = (A*B)/(||A||*||B||) = (2+1+0+0+0)/(√7*√3) = 3/√21 = 0.66
优点

简单
考虑了词频，长文本理解更准确

缺点

语义还是没有理解
高频无意义词，如“的” “地”等影响较大，需过滤

PS： 常用的相似性判定方法主要通过 向量夹角余弦值(向量点积/向量模乘积)



cos
θ
=



∑

i
=
1

n


A
i


B
i





∑

i
=
1

n



A
i

2


×


∑

i
=
1

n



B
i

2





\cos\theta = \frac{\sum_{i=1}^n A_iB_i}{\sqrt{\sum_{i=1}^n A_i^2} \times \sqrt{\sum_{i=1}^n B_i^2}}


or 向量间欧式距离



d
=



∑

i
=
1

n



(

x

2
i


-

x

1
i


)

2




d = \sqrt{\sum_{i=1}^n (x_{2i} - x_{1i})^2}


计算获得"><meta name=author content><link rel=canonical href=https://duck-dd.github.io/posts/%E7%9B%B8%E4%BC%BC%E5%BA%A6/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2a8ef18cccda149eb1cd8ec968ba463447d72022979e5c5cae43dcf5d7358750.css integrity="sha256-Ko7xjMzaFJ6xzY7JaLpGNEfXICKXnlxcrkPc9dc1h1A=" rel="preload stylesheet" as=style><link rel=icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://duck-dd.github.io/posts/%E7%9B%B8%E4%BC%BC%E5%BA%A6/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><meta property="og:url" content="https://duck-dd.github.io/posts/%E7%9B%B8%E4%BC%BC%E5%BA%A6/"><meta property="og:site_name" content="Duck"><meta property="og:title" content="相似度"><meta property="og:description" content="相似度算法用于衡量多个对象（如文本、数值向量、图像、序列等）之间相似程度的数学方法。
在计算机领域，通常将 “相似性” 转化为可计算的数值（例如 0~1 表示，1代表完全相似，0代表完全不相似）。
相似度算法的应用十分广泛，例如推荐系统（如商品/内容推荐）、数据挖掘（如聚类、分类）、NLP（如文本查重、语义匹配）、图像识别等。
文本相似度 基于字符/词频 不依赖语义理解，仅从文本的字符或词语出现频率出发计算相似性，适合简单的短文本内容的场景。
Jaccard 系数（杰卡德相似度） 思路：将文本视为 “词语集合”（忽略词频和顺序），相似性 = 两个集合的交集大小 / 两个集合的并集大小
举个例子，sim(“小明球技很棒” & “小明球技真好”) = len(“小明” “球技”)/len(“小明” “球技” “很棒” “真好”) = 0.5
优点
简单 缺点
词频没有统计 语义不做理解，“真好” “很棒” 其实语义接近 余弦相似度（Cosine Similarity） 思路：将文本转换为词频向量，相似性 = 两个向量夹角余弦值
举个例子，(“小明球技很棒啊，小明不错” & “小明球技真好”)，构建词袋=[“小明” “球技” “很棒” “真好” “不错”]，对于词袋，计算向量值，“小明球技很棒”的词频向量A = [2,1,1,0,1]，“小明球技真好”的词频向量B = [1,1,0,1,0]，则 相似性 = cos(A,B) = (A*B)/(||A||*||B||) = (2+1+0+0+0)/(√7*√3) = 3/√21 = 0.66
优点
简单 考虑了词频，长文本理解更准确 缺点
语义还是没有理解 高频无意义词，如“的” “地”等影响较大，需过滤 PS： 常用的相似性判定方法主要通过 向量夹角余弦值(向量点积/向量模乘积) cos θ = ∑ i = 1 n A i B i ∑ i = 1 n A i 2 × ∑ i = 1 n B i 2 \cos\theta = \frac{\sum_{i=1}^n A_iB_i}{\sqrt{\sum_{i=1}^n A_i^2} \times \sqrt{\sum_{i=1}^n B_i^2}} or 向量间欧式距离 d = ∑ i = 1 n ( x 2 i - x 1 i ) 2 d = \sqrt{\sum_{i=1}^n (x_{2i} - x_{1i})^2} 计算获得"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-03T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-03T00:00:00+00:00"><meta property="article:tag" content="CS-Other"><meta property="og:image" content="https://duck-dd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://duck-dd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="相似度"><meta name=twitter:description content="相似度算法用于衡量多个对象（如文本、数值向量、图像、序列等）之间相似程度的数学方法。
在计算机领域，通常将 “相似性” 转化为可计算的数值（例如 0~1 表示，1代表完全相似，0代表完全不相似）。
相似度算法的应用十分广泛，例如推荐系统（如商品/内容推荐）、数据挖掘（如聚类、分类）、NLP（如文本查重、语义匹配）、图像识别等。
文本相似度
基于字符/词频
不依赖语义理解，仅从文本的字符或词语出现频率出发计算相似性，适合简单的短文本内容的场景。
Jaccard 系数（杰卡德相似度）
思路：将文本视为 “词语集合”（忽略词频和顺序），相似性 = 两个集合的交集大小 / 两个集合的并集大小
举个例子，sim(“小明球技很棒” & “小明球技真好”) = len(&ldquo;小明&rdquo; &ldquo;球技&rdquo;)/len(&ldquo;小明&rdquo; &ldquo;球技&rdquo; &ldquo;很棒&rdquo; &ldquo;真好&rdquo;) = 0.5
优点

简单

缺点

词频没有统计
语义不做理解，&ldquo;真好&rdquo; &ldquo;很棒&rdquo; 其实语义接近

余弦相似度（Cosine Similarity）
思路：将文本转换为词频向量，相似性 = 两个向量夹角余弦值
举个例子，(“小明球技很棒啊，小明不错” & “小明球技真好”)，构建词袋=[&ldquo;小明&rdquo; &ldquo;球技&rdquo; &ldquo;很棒&rdquo; &ldquo;真好&rdquo; &ldquo;不错&rdquo;]，对于词袋，计算向量值，“小明球技很棒”的词频向量A = [2,1,1,0,1]，“小明球技真好”的词频向量B = [1,1,0,1,0]，则 相似性 = cos(A,B) = (A*B)/(||A||*||B||) = (2+1+0+0+0)/(√7*√3) = 3/√21 = 0.66
优点

简单
考虑了词频，长文本理解更准确

缺点

语义还是没有理解
高频无意义词，如“的” “地”等影响较大，需过滤

PS： 常用的相似性判定方法主要通过 向量夹角余弦值(向量点积/向量模乘积)



cos
θ
=



∑

i
=
1

n


A
i


B
i





∑

i
=
1

n



A
i

2


×


∑

i
=
1

n



B
i

2





\cos\theta = \frac{\sum_{i=1}^n A_iB_i}{\sqrt{\sum_{i=1}^n A_i^2} \times \sqrt{\sum_{i=1}^n B_i^2}}


or 向量间欧式距离



d
=



∑

i
=
1

n



(

x

2
i


-

x

1
i


)

2




d = \sqrt{\sum_{i=1}^n (x_{2i} - x_{1i})^2}


计算获得"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://duck-dd.github.io/posts/"},{"@type":"ListItem","position":2,"name":"相似度","item":"https://duck-dd.github.io/posts/%E7%9B%B8%E4%BC%BC%E5%BA%A6/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"相似度","name":"相似度","description":"相似度算法用于衡量多个对象（如文本、数值向量、图像、序列等）之间相似程度的数学方法。\n在计算机领域，通常将 “相似性” 转化为可计算的数值（例如 0~1 表示，1代表完全相似，0代表完全不相似）。\n相似度算法的应用十分广泛，例如推荐系统（如商品/内容推荐）、数据挖掘（如聚类、分类）、NLP（如文本查重、语义匹配）、图像识别等。\n文本相似度 基于字符/词频 不依赖语义理解，仅从文本的字符或词语出现频率出发计算相似性，适合简单的短文本内容的场景。\nJaccard 系数（杰卡德相似度） 思路：将文本视为 “词语集合”（忽略词频和顺序），相似性 = 两个集合的交集大小 / 两个集合的并集大小\n举个例子，sim(“小明球技很棒” \u0026amp; “小明球技真好”) = len(\u0026ldquo;小明\u0026rdquo; \u0026ldquo;球技\u0026rdquo;)/len(\u0026ldquo;小明\u0026rdquo; \u0026ldquo;球技\u0026rdquo; \u0026ldquo;很棒\u0026rdquo; \u0026ldquo;真好\u0026rdquo;) = 0.5\n优点\n简单 缺点\n词频没有统计 语义不做理解，\u0026ldquo;真好\u0026rdquo; \u0026ldquo;很棒\u0026rdquo; 其实语义接近 余弦相似度（Cosine Similarity） 思路：将文本转换为词频向量，相似性 = 两个向量夹角余弦值\n举个例子，(“小明球技很棒啊，小明不错” \u0026amp; “小明球技真好”)，构建词袋=[\u0026ldquo;小明\u0026rdquo; \u0026ldquo;球技\u0026rdquo; \u0026ldquo;很棒\u0026rdquo; \u0026ldquo;真好\u0026rdquo; \u0026ldquo;不错\u0026rdquo;]，对于词袋，计算向量值，“小明球技很棒”的词频向量A = [2,1,1,0,1]，“小明球技真好”的词频向量B = [1,1,0,1,0]，则 相似性 = cos(A,B) = (A*B)/(||A||*||B||) = (2+1+0+0+0)/(√7*√3) = 3/√21 = 0.66\n优点\n简单 考虑了词频，长文本理解更准确 缺点\n语义还是没有理解 高频无意义词，如“的” “地”等影响较大，需过滤 PS： 常用的相似性判定方法主要通过 向量夹角余弦值(向量点积/向量模乘积) cos θ = ∑ i = 1 n A i B i ∑ i = 1 n A i 2 × ∑ i = 1 n B i 2 \\cos\\theta = \\frac{\\sum_{i=1}^n A_iB_i}{\\sqrt{\\sum_{i=1}^n A_i^2} \\times \\sqrt{\\sum_{i=1}^n B_i^2}} or 向量间欧式距离 d = ∑ i = 1 n ( x 2 i - x 1 i ) 2 d = \\sqrt{\\sum_{i=1}^n (x_{2i} - x_{1i})^2} 计算获得\n","keywords":["CS-Other"],"articleBody":"相似度算法用于衡量多个对象（如文本、数值向量、图像、序列等）之间相似程度的数学方法。\n在计算机领域，通常将 “相似性” 转化为可计算的数值（例如 0~1 表示，1代表完全相似，0代表完全不相似）。\n相似度算法的应用十分广泛，例如推荐系统（如商品/内容推荐）、数据挖掘（如聚类、分类）、NLP（如文本查重、语义匹配）、图像识别等。\n文本相似度 基于字符/词频 不依赖语义理解，仅从文本的字符或词语出现频率出发计算相似性，适合简单的短文本内容的场景。\nJaccard 系数（杰卡德相似度） 思路：将文本视为 “词语集合”（忽略词频和顺序），相似性 = 两个集合的交集大小 / 两个集合的并集大小\n举个例子，sim(“小明球技很棒” \u0026 “小明球技真好”) = len(“小明” “球技”)/len(“小明” “球技” “很棒” “真好”) = 0.5\n优点\n简单 缺点\n词频没有统计 语义不做理解，“真好” “很棒” 其实语义接近 余弦相似度（Cosine Similarity） 思路：将文本转换为词频向量，相似性 = 两个向量夹角余弦值\n举个例子，(“小明球技很棒啊，小明不错” \u0026 “小明球技真好”)，构建词袋=[“小明” “球技” “很棒” “真好” “不错”]，对于词袋，计算向量值，“小明球技很棒”的词频向量A = [2,1,1,0,1]，“小明球技真好”的词频向量B = [1,1,0,1,0]，则 相似性 = cos(A,B) = (A*B)/(||A||*||B||) = (2+1+0+0+0)/(√7*√3) = 3/√21 = 0.66\n优点\n简单 考虑了词频，长文本理解更准确 缺点\n语义还是没有理解 高频无意义词，如“的” “地”等影响较大，需过滤 PS： 常用的相似性判定方法主要通过 向量夹角余弦值(向量点积/向量模乘积) cos θ = ∑ i = 1 n A i B i ∑ i = 1 n A i 2 × ∑ i = 1 n B i 2 \\cos\\theta = \\frac{\\sum_{i=1}^n A_iB_i}{\\sqrt{\\sum_{i=1}^n A_i^2} \\times \\sqrt{\\sum_{i=1}^n B_i^2}} or 向量间欧式距离 d = ∑ i = 1 n ( x 2 i - x 1 i ) 2 d = \\sqrt{\\sum_{i=1}^n (x_{2i} - x_{1i})^2} 计算获得\n基于语义的相似度 通过模型捕捉文本的深层语义而非表面字符，适合需要理解“语义相似”的场景(例如“好” “棒” 语义接近)\nWord2Vec/GloVe + 余弦相似度 思路：先通过Word2Vec或GloVe模型将每个词转化为低维稠密向量(如100维)，再将文本中所有词的向量取平均(或加权平均)得到 “句向量”，最后用余弦相似度计算句向量的相似性\n适用场景：短文本语义匹配（例如聊天机器人意图识别、问答系统等）\nBERT 等预训练模型相似度 思路：BERT(双向Transformer)等预训练模型能直接输出包含上下文信息的句向量(如通过 [CLS] token 的向量)，再用余弦相似度或欧氏距离衡量相似性\n适用场景：复杂语义匹配（例如文章摘要相似度、文档检索等）\n数值向量相似度 当对象以数值向量形式存在时，例如用户特征向量[年龄, 性别, 浏览次数, 消费金额]，商品特征向量[价格, 评分, 销量]等，适合采用向量计算方式来评估相似度。\n多用于数据挖掘、推荐系统等场景。\n欧式距离 计算方式不再赘述\n缺点\n受个别维度极端值影响大 曼哈顿距离 计算向量在n维空间中各维度差值的绝对值之和。\n适用场景：高维稀疏数据（如用户点击行为向量，大部分维度为0）、不需要精确直线距离的场景（如物流路径相似性）等\n优点\n计算简单 对个别维度异常值更鲁棒 缺点\n判定准确度差 皮尔逊相关系数 思路：衡量两个向量的“线性相关程度”，取值范围 [-1,1]，1表示完全正相关(高度相似)，0表示无相关，-1表示完全负相关\n计算：先计算两个向量的均值，再通过协方差与标准差的比值计算相关系数，本质是“中心化后的余弦相似度”\n适用场景：需要排除量级影响的线性相似性场景（例如用户评分偏好相似性：A用户给电影评分普遍偏高，B用户普遍偏低，但评分趋势一致，皮尔逊系数能捕捉这种趋势相似性）\n图像相似度(简述) 计算机视觉领域，衡量两张图像的视觉相似性，一般是将图像转化为特征向量后再计算相似性。\n适用场景：图像质量评估（如压缩前后图像相似度）、图像去重（如重复图片检测）\n结构相似性（SSIM）（还是像素层面，加了结构考量） 从亮度、对比度、结构三个维度衡量图像相似性，避免传统像素级距离（如欧氏距离）忽略视觉结构的问题（如两张图像像素略有差异，但人眼看起来完全相同）\n基于特征提取的相似度（SIFT/SURF/ORB + 匹配）（特征层面） 先通过 SIFT（尺度不变特征变换）、ORB（快速特征点提取）等算法提取图像的局部特征点（如边缘、角点），再计算特征点的匹配度（如最近邻匹配），匹配比例越高，图像越相似\n适用场景：图像检索（如以图搜图）、目标识别（如相似物体匹配）、图像拼接\n基于深度学习的相似度（CNN/ViT + 特征向量）（内容层面，能避免“猫” “狗”混淆问题） 通过 CNN（卷积神经网络，如 ResNet）或 ViT（视觉 Transformer）提取图像的全局特征向量，再用余弦相似度或欧氏距离计算相似性，能捕捉图像的高层语义（如 “猫” 和 “狗” 的特征向量差异显著，而 “两只不同的猫” 差异小）\n适用场景：复杂图像相似性场景（如风格迁移相似性、商品图像检索、人脸识别）\n序列相似度(简述) 文本字符序列相似度 编辑距离：计算将序列 A 转化为序列 B 所需的 “最少操作数”（插入、删除、替换），操作数越少越相似；适用场景：拼写纠错、短字符串匹配（如用户名、关键词） 最长公共子序列：找到两个序列中 “最长的、无需连续但顺序一致的子序列”，子序列越长越相似；适用场景：文本相似性初步判断、代码剽窃检测等 生物序列相似度（例如DNS比对） 所有生物序列相似度计算的基础是“序列比对”—— 通过插入 “空位（Gap）” 或标记 “替换（Substitution）”，让两个序列中“同源（来自共同祖先）”的单元尽可能对齐，再基于对齐结果计算相似度\n全局比对：Needleman-Wunsch算法，强制覆盖两个序列的所有单元，允许在两端插入空位；适用场景：序列长度接近、需完整对齐（如同一基因的不同物种序列 局部比对：Smith-Waterman 算法，只对齐相似度最高的局部片段，忽略两端差异大的区域；适用场景：序列长度差异大、仅需找局部相似片段（如寻找基因中的保守区域） 时间序列相似度 动态时间规整（DTW） 思路：允许“时间轴弹性伸缩”（解决序列长度不同或时间偏移问题），计算最优对齐后的累积距离，距离越小越相似\n计算：例如对比[1 3 5 7] [2 4 6 8]两个序列，DTW会作对齐“1→2、3→4、5→6、7→8”，使得累积距离变小(疑问：主要包括平移，任意固定点伸缩变换这些方法？)\n适用场景：语音识别（同一人不同语速的语音序列）、传感器数据匹配（不同设备采集的同一过程数据\n皮尔逊相关系数 不再赘述。\n总结 相似度的计算，一般都会回归到余弦/向量计算问题上，向量计算可能针对不同的场景采用不同的距离计算方式，还会结合方差标准差/协方差等因素协助评估。对于复杂场景，更难的是向量抽象的过程，这里的特征提取、特征变换等过程后续再慢慢写。\n","wordCount":"240","inLanguage":"en","image":"https://duck-dd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-06-03T00:00:00Z","dateModified":"2025-06-03T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://duck-dd.github.io/posts/%E7%9B%B8%E4%BC%BC%E5%BA%A6/"},"publisher":{"@type":"Organization","name":"Duck","logo":{"@type":"ImageObject","url":"https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://duck-dd.github.io/ accesskey=h title="首页 (Alt + H)"><img src=https://duck-dd.github.io/apple-touch-icon.png alt aria-label=logo height=35>首页</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://duck-dd.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://duck-dd.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://duck-dd.github.io/about_me title=关于我><span>关于我</span></a></li><li><a href=https://duck-dd.github.io/about_space title=关于这里><span>关于这里</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://duck-dd.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://duck-dd.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">相似度</h1><div class=post-meta><span title='2025-06-03 00:00:00 +0000 UTC'>2025-06-03</span>&nbsp;·&nbsp;创建于:&nbsp;2025-06-03&nbsp;·&nbsp;2 min&nbsp;·&nbsp;240 words<div class=meta-item>&nbsp·&nbsp
<a href=https://duck-dd.github.io/categories/cs/>CS</a></div><div class=meta-item>&nbsp·&nbsp
<a href=https://duck-dd.github.io/tags/cs-other/>CS-Other</a></div></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e6%96%87%e6%9c%ac%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label=文本相似度>文本相似度</a><ul><li><a href=#%e5%9f%ba%e4%ba%8e%e5%ad%97%e7%ac%a6%e8%af%8d%e9%a2%91 aria-label=基于字符/词频>基于字符/词频</a><ul><li><a href=#jaccard-%e7%b3%bb%e6%95%b0%e6%9d%b0%e5%8d%a1%e5%be%b7%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label="Jaccard 系数（杰卡德相似度）">Jaccard 系数（杰卡德相似度）</a></li><li><a href=#%e4%bd%99%e5%bc%a6%e7%9b%b8%e4%bc%bc%e5%ba%a6cosine-similarity aria-label="余弦相似度（Cosine Similarity）">余弦相似度（Cosine Similarity）</a></li></ul></li><li><a href=#%e5%9f%ba%e4%ba%8e%e8%af%ad%e4%b9%89%e7%9a%84%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label=基于语义的相似度>基于语义的相似度</a><ul><li><a href=#word2vecglove--%e4%bd%99%e5%bc%a6%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label="Word2Vec/GloVe + 余弦相似度">Word2Vec/GloVe + 余弦相似度</a></li><li><a href=#bert-%e7%ad%89%e9%a2%84%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label="BERT 等预训练模型相似度">BERT 等预训练模型相似度</a></li></ul></li></ul></li><li><a href=#%e6%95%b0%e5%80%bc%e5%90%91%e9%87%8f%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label=数值向量相似度>数值向量相似度</a><ul><li><a href=#%e6%ac%a7%e5%bc%8f%e8%b7%9d%e7%a6%bb aria-label=欧式距离>欧式距离</a></li><li><a href=#%e6%9b%bc%e5%93%88%e9%a1%bf%e8%b7%9d%e7%a6%bb aria-label=曼哈顿距离>曼哈顿距离</a></li><li><a href=#%e7%9a%ae%e5%b0%94%e9%80%8a%e7%9b%b8%e5%85%b3%e7%b3%bb%e6%95%b0 aria-label=皮尔逊相关系数>皮尔逊相关系数</a></li></ul></li><li><a href=#%e5%9b%be%e5%83%8f%e7%9b%b8%e4%bc%bc%e5%ba%a6%e7%ae%80%e8%bf%b0 aria-label=图像相似度(简述)>图像相似度(简述)</a><ul><li><a href=#%e7%bb%93%e6%9e%84%e7%9b%b8%e4%bc%bc%e6%80%a7ssim%e8%bf%98%e6%98%af%e5%83%8f%e7%b4%a0%e5%b1%82%e9%9d%a2%e5%8a%a0%e4%ba%86%e7%bb%93%e6%9e%84%e8%80%83%e9%87%8f aria-label=结构相似性（SSIM）（还是像素层面，加了结构考量）>结构相似性（SSIM）（还是像素层面，加了结构考量）</a></li><li><a href=#%e5%9f%ba%e4%ba%8e%e7%89%b9%e5%be%81%e6%8f%90%e5%8f%96%e7%9a%84%e7%9b%b8%e4%bc%bc%e5%ba%a6siftsurforb--%e5%8c%b9%e9%85%8d%e7%89%b9%e5%be%81%e5%b1%82%e9%9d%a2 aria-label="基于特征提取的相似度（SIFT/SURF/ORB + 匹配）（特征层面）">基于特征提取的相似度（SIFT/SURF/ORB + 匹配）（特征层面）</a></li><li><a href=#%e5%9f%ba%e4%ba%8e%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e7%9a%84%e7%9b%b8%e4%bc%bc%e5%ba%a6cnnvit--%e7%89%b9%e5%be%81%e5%90%91%e9%87%8f%e5%86%85%e5%ae%b9%e5%b1%82%e9%9d%a2%e8%83%bd%e9%81%bf%e5%85%8d%e7%8c%ab-%e7%8b%97%e6%b7%b7%e6%b7%86%e9%97%ae%e9%a2%98 aria-label="基于深度学习的相似度（CNN/ViT + 特征向量）（内容层面，能避免“猫” “狗”混淆问题）">基于深度学习的相似度（CNN/ViT + 特征向量）（内容层面，能避免“猫” “狗”混淆问题）</a></li></ul></li><li><a href=#%e5%ba%8f%e5%88%97%e7%9b%b8%e4%bc%bc%e5%ba%a6%e7%ae%80%e8%bf%b0 aria-label=序列相似度(简述)>序列相似度(简述)</a><ul><li><a href=#%e6%96%87%e6%9c%ac%e5%ad%97%e7%ac%a6%e5%ba%8f%e5%88%97%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label=文本字符序列相似度>文本字符序列相似度</a></li><li><a href=#%e7%94%9f%e7%89%a9%e5%ba%8f%e5%88%97%e7%9b%b8%e4%bc%bc%e5%ba%a6%e4%be%8b%e5%a6%82dns%e6%af%94%e5%af%b9 aria-label=生物序列相似度（例如DNS比对）>生物序列相似度（例如DNS比对）</a></li><li><a href=#%e6%97%b6%e9%97%b4%e5%ba%8f%e5%88%97%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label=时间序列相似度>时间序列相似度</a><ul><li><a href=#%e5%8a%a8%e6%80%81%e6%97%b6%e9%97%b4%e8%a7%84%e6%95%b4dtw aria-label=动态时间规整（DTW）>动态时间规整（DTW）</a></li><li><a href=#%e7%9a%ae%e5%b0%94%e9%80%8a%e7%9b%b8%e5%85%b3%e7%b3%bb%e6%95%b0-1 aria-label=皮尔逊相关系数>皮尔逊相关系数</a></li></ul></li></ul></li><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结>总结</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p><code>相似度算法</code>用于衡量多个对象（如文本、数值向量、图像、序列等）之间相似程度的数学方法。</p><p>在计算机领域，通常将 “相似性” 转化为可计算的数值（例如 0~1 表示，1代表完全相似，0代表完全不相似）。</p><p><code>相似度算法</code>的应用十分广泛，例如推荐系统（如商品/内容推荐）、数据挖掘（如聚类、分类）、NLP（如文本查重、语义匹配）、图像识别等。</p><h1 id=文本相似度>文本相似度<a hidden class=anchor aria-hidden=true href=#文本相似度>#</a></h1><h2 id=基于字符词频>基于字符/词频<a hidden class=anchor aria-hidden=true href=#基于字符词频>#</a></h2><p>不依赖语义理解，仅从文本的字符或词语出现频率出发计算相似性，适合简单的短文本内容的场景。</p><h3 id=jaccard-系数杰卡德相似度>Jaccard 系数（杰卡德相似度）<a hidden class=anchor aria-hidden=true href=#jaccard-系数杰卡德相似度>#</a></h3><p>思路：将文本视为 “词语集合”（忽略词频和顺序），<code>相似性 = 两个集合的交集大小 / 两个集合的并集大小</code></p><p>举个例子，sim(“小明球技很棒” & “小明球技真好”) = len(&ldquo;小明&rdquo; &ldquo;球技&rdquo;)/len(&ldquo;小明&rdquo; &ldquo;球技&rdquo; &ldquo;很棒&rdquo; &ldquo;真好&rdquo;) = 0.5</p><p>优点</p><ul><li>简单</li></ul><p>缺点</p><ul><li>词频没有统计</li><li>语义不做理解，&ldquo;真好&rdquo; &ldquo;很棒&rdquo; 其实语义接近</li></ul><h3 id=余弦相似度cosine-similarity>余弦相似度（Cosine Similarity）<a hidden class=anchor aria-hidden=true href=#余弦相似度cosine-similarity>#</a></h3><p>思路：将文本转换为词频向量，<code>相似性 = 两个向量夹角余弦值</code></p><p>举个例子，(“小明球技很棒啊，小明不错” & “小明球技真好”)，构建<code>词袋</code>=[&ldquo;小明&rdquo; &ldquo;球技&rdquo; &ldquo;很棒&rdquo; &ldquo;真好&rdquo; &ldquo;不错&rdquo;]，对于词袋，计算向量值，“小明球技很棒”的词频向量A = [2,1,1,0,1]，“小明球技真好”的词频向量B = [1,1,0,1,0]，则 <code>相似性 = cos(A,B) = (A*B)/(||A||*||B||) = (2+1+0+0+0)/(√7*√3) = 3/√21 = 0.66</code></p><p>优点</p><ul><li>简单</li><li>考虑了词频，长文本理解更准确</li></ul><p>缺点</p><ul><li>语义还是没有理解</li><li>高频无意义词，如“的” “地”等影响较大，需过滤</li></ul><p><strong>PS：</strong> 常用的相似性判定方法主要通过 向量夹角余弦值(<code>向量点积/向量模乘积</code>)
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi>cos</mi>
<mi>θ</mi>
<mo>=</mo>
<mfrac>
<mrow>
<munderover>
<mo>∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<msub>
<mi>A</mi>
<mi>i</mi>
</msub>
<msub>
<mi>B</mi>
<mi>i</mi>
</msub>
</mrow>
<mrow>
<msqrt>
<munderover>
<mo>∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<msup>
<msub>
<mi>A</mi>
<mi>i</mi>
</msub>
<mn>2</mn>
</msup>
</msqrt>
<mo>×</mo>
<msqrt>
<munderover>
<mo>∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<msup>
<msub>
<mi>B</mi>
<mi>i</mi>
</msub>
<mn>2</mn>
</msup>
</msqrt>
</mrow>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">\cos\theta = \frac{\sum_{i=1}^n A_iB_i}{\sqrt{\sum_{i=1}^n A_i^2} \times \sqrt{\sum_{i=1}^n B_i^2}}</annotation>
</semantics>
</math>
or 向量间欧式距离
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi>d</mi>
<mo>=</mo>
<msqrt>
<mrow>
<munderover>
<mo>∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<msup>
<mrow>
<mi>(</mi>
<msub>
<mi>x</mi>
<mrow>
<mn>2</mn>
<mi>i</mi>
</mrow>
</msub>
<mo>-</mo>
<msub>
<mi>x</mi>
<mrow>
<mn>1</mn>
<mi>i</mi>
</mrow>
</msub>
<mi>)</mi>
</mrow>
<mn>2</mn>
</msup>
</mrow>
</msqrt>
</mrow>
<annotation encoding="application/x-tex">d = \sqrt{\sum_{i=1}^n (x_{2i} - x_{1i})^2}</annotation>
</semantics>
</math>
计算获得</p><h2 id=基于语义的相似度>基于语义的相似度<a hidden class=anchor aria-hidden=true href=#基于语义的相似度>#</a></h2><p>通过模型捕捉文本的深层语义而非表面字符，适合需要理解“语义相似”的场景(例如“好” “棒” 语义接近)</p><h3 id=word2vecglove--余弦相似度>Word2Vec/GloVe + 余弦相似度<a hidden class=anchor aria-hidden=true href=#word2vecglove--余弦相似度>#</a></h3><p>思路：先通过<code>Word2Vec</code>或<code>GloVe</code>模型将每个词转化为低维稠密向量(如100维)，再将文本中所有词的向量取平均(或加权平均)得到 “句向量”，最后用余弦相似度计算句向量的相似性</p><p>适用场景：短文本语义匹配（例如聊天机器人意图识别、问答系统等）</p><h3 id=bert-等预训练模型相似度>BERT 等预训练模型相似度<a hidden class=anchor aria-hidden=true href=#bert-等预训练模型相似度>#</a></h3><p>思路：<code>BERT(双向Transformer)</code>等预训练模型能直接输出包含上下文信息的句向量(如通过 <code>[CLS] token</code> 的向量)，再用余弦相似度或欧氏距离衡量相似性</p><p>适用场景：复杂语义匹配（例如文章摘要相似度、文档检索等）</p><h1 id=数值向量相似度>数值向量相似度<a hidden class=anchor aria-hidden=true href=#数值向量相似度>#</a></h1><p>当对象以数值向量形式存在时，例如用户特征向量<code>[年龄, 性别, 浏览次数, 消费金额]</code>，商品特征向量<code>[价格, 评分, 销量]</code>等，适合采用向量计算方式来评估相似度。</p><p>多用于数据挖掘、推荐系统等场景。</p><h2 id=欧式距离>欧式距离<a hidden class=anchor aria-hidden=true href=#欧式距离>#</a></h2><p>计算方式不再赘述</p><p>缺点</p><ul><li>受个别维度极端值影响大</li></ul><h2 id=曼哈顿距离>曼哈顿距离<a hidden class=anchor aria-hidden=true href=#曼哈顿距离>#</a></h2><p>计算向量在n维空间中各维度差值的绝对值之和。</p><p>适用场景：高维稀疏数据（如用户点击行为向量，大部分维度为0）、不需要精确直线距离的场景（如物流路径相似性）等</p><p>优点</p><ul><li>计算简单</li><li>对个别维度异常值更鲁棒</li></ul><p>缺点</p><ul><li>判定准确度差</li></ul><h2 id=皮尔逊相关系数>皮尔逊相关系数<a hidden class=anchor aria-hidden=true href=#皮尔逊相关系数>#</a></h2><p>思路：衡量两个向量的“线性相关程度”，取值范围 [-1,1]，1表示完全正相关(高度相似)，0表示无相关，-1表示完全负相关</p><p>计算：先计算两个向量的均值，再通过协方差与标准差的比值计算相关系数，本质是“中心化后的余弦相似度”</p><p>适用场景：需要排除量级影响的线性相似性场景（例如用户评分偏好相似性：A用户给电影评分普遍偏高，B用户普遍偏低，但评分趋势一致，皮尔逊系数能捕捉这种趋势相似性）</p><h1 id=图像相似度简述>图像相似度(简述)<a hidden class=anchor aria-hidden=true href=#图像相似度简述>#</a></h1><p>计算机视觉领域，衡量两张图像的视觉相似性，一般是将图像转化为特征向量后再计算相似性。</p><p>适用场景：图像质量评估（如压缩前后图像相似度）、图像去重（如重复图片检测）</p><h2 id=结构相似性ssim还是像素层面加了结构考量>结构相似性（SSIM）（还是像素层面，加了结构考量）<a hidden class=anchor aria-hidden=true href=#结构相似性ssim还是像素层面加了结构考量>#</a></h2><p>从亮度、对比度、结构三个维度衡量图像相似性，避免传统像素级距离（如欧氏距离）忽略视觉结构的问题（如两张图像像素略有差异，但人眼看起来完全相同）</p><h2 id=基于特征提取的相似度siftsurforb--匹配特征层面>基于特征提取的相似度（SIFT/SURF/ORB + 匹配）（特征层面）<a hidden class=anchor aria-hidden=true href=#基于特征提取的相似度siftsurforb--匹配特征层面>#</a></h2><p>先通过 SIFT（尺度不变特征变换）、ORB（快速特征点提取）等算法提取图像的局部特征点（如边缘、角点），再计算特征点的匹配度（如最近邻匹配），匹配比例越高，图像越相似</p><p>适用场景：图像检索（如以图搜图）、目标识别（如相似物体匹配）、图像拼接</p><h2 id=基于深度学习的相似度cnnvit--特征向量内容层面能避免猫-狗混淆问题>基于深度学习的相似度（CNN/ViT + 特征向量）（内容层面，能避免“猫” “狗”混淆问题）<a hidden class=anchor aria-hidden=true href=#基于深度学习的相似度cnnvit--特征向量内容层面能避免猫-狗混淆问题>#</a></h2><p>通过 CNN（卷积神经网络，如 ResNet）或 ViT（视觉 Transformer）提取图像的全局特征向量，再用余弦相似度或欧氏距离计算相似性，能捕捉图像的高层语义（如 “猫” 和 “狗” 的特征向量差异显著，而 “两只不同的猫” 差异小）</p><p>适用场景：复杂图像相似性场景（如风格迁移相似性、商品图像检索、人脸识别）</p><h1 id=序列相似度简述>序列相似度(简述)<a hidden class=anchor aria-hidden=true href=#序列相似度简述>#</a></h1><h2 id=文本字符序列相似度>文本字符序列相似度<a hidden class=anchor aria-hidden=true href=#文本字符序列相似度>#</a></h2><ul><li>编辑距离：计算将序列 A 转化为序列 B 所需的 “最少操作数”（插入、删除、替换），操作数越少越相似；适用场景：拼写纠错、短字符串匹配（如用户名、关键词）</li><li>最长公共子序列：找到两个序列中 “最长的、无需连续但顺序一致的子序列”，子序列越长越相似；适用场景：文本相似性初步判断、代码剽窃检测等</li></ul><h2 id=生物序列相似度例如dns比对>生物序列相似度（例如DNS比对）<a hidden class=anchor aria-hidden=true href=#生物序列相似度例如dns比对>#</a></h2><p>所有生物序列相似度计算的基础是“序列比对”—— 通过插入 “空位（Gap）” 或标记 “替换（Substitution）”，让两个序列中“同源（来自共同祖先）”的单元尽可能对齐，再基于对齐结果计算相似度</p><ul><li>全局比对：Needleman-Wunsch算法，强制覆盖两个序列的所有单元，允许在两端插入空位；适用场景：序列长度接近、需完整对齐（如同一基因的不同物种序列</li><li>局部比对：Smith-Waterman 算法，只对齐相似度最高的局部片段，忽略两端差异大的区域；适用场景：序列长度差异大、仅需找局部相似片段（如寻找基因中的保守区域）</li></ul><h2 id=时间序列相似度>时间序列相似度<a hidden class=anchor aria-hidden=true href=#时间序列相似度>#</a></h2><h3 id=动态时间规整dtw>动态时间规整（DTW）<a hidden class=anchor aria-hidden=true href=#动态时间规整dtw>#</a></h3><p>思路：允许“时间轴弹性伸缩”（解决序列长度不同或时间偏移问题），计算最优对齐后的累积距离，距离越小越相似</p><p>计算：例如对比<code>[1 3 5 7] [2 4 6 8]</code>两个序列，DTW会作对齐“1→2、3→4、5→6、7→8”，使得累积距离变小(疑问：主要包括平移，任意固定点伸缩变换这些方法？)</p><p>适用场景：语音识别（同一人不同语速的语音序列）、传感器数据匹配（不同设备采集的同一过程数据</p><h3 id=皮尔逊相关系数-1>皮尔逊相关系数<a hidden class=anchor aria-hidden=true href=#皮尔逊相关系数-1>#</a></h3><p>不再赘述。</p><h1 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h1><p>相似度的计算，一般都会回归到<code>余弦/向量计算</code>问题上，向量计算可能针对不同的场景采用不同的距离计算方式，还会结合<code>方差标准差/协方差</code>等因素协助评估。对于复杂场景，更难的是<code>向量</code>抽象的过程，这里的特征提取、特征变换等过程后续再慢慢写。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://duck-dd.github.io/tags/cs-other/>CS-Other</a></li></ul><nav class=paginav><a class=prev href=https://duck-dd.github.io/posts/go-tips/><span class=title>« Prev</span><br><span>Golang Tips</span>
</a><a class=next href=https://duck-dd.github.io/posts/%E8%AE%A4%E6%B8%85%E8%87%AA%E5%B7%B1-2025-05-26%E6%97%A5%E8%AE%B0/><span class=title>Next »</span><br><span>认清自己 2025-05-28日记</span></a></nav></footer><script src=https://utteranc.es/client.js repo=duck-dd/blog-comment issue-term=pathname label='💬 Comments' theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://duck-dd.github.io/>Duck</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$",right:"$",display:!1},{left:"$$",right:"$$",display:!0}],throwOnError:!1})})</script></body></html>